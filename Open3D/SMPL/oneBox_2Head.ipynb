{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/commaai-03/Data/workdata/baodi/weighter/rs07/oneBox_twoHead/'\n",
    "alls = os.listdir(root_dir)\n",
    "\n",
    "allimgs = [img for img in alls \n",
    "            if img.split('.')[-1].lower() in ['jpg', 'jpeg', 'png']]\n",
    "\n",
    "alljsons = [file for file in alls\n",
    "             if file.split('.')[-1].lower() in ['json']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter, gaussian_filter\n",
    "def ssim(X, Y, win_size=None, gradient=False,\n",
    "         data_range=None, multichannel=False, gaussian_weights=False,\n",
    "         full=False, dynamic_range=None, **kwargs):\n",
    "    \"\"\"Compute the mean structural similarity index between two images.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X, Y : ndarray\n",
    "        Image.  Any dimensionality.\n",
    "    win_size : int or None\n",
    "        The side-length of the sliding window used in comparison.  Must be an\n",
    "        odd value.  If `gaussian_weights` is True, this is ignored and the\n",
    "        window size will depend on `sigma`.\n",
    "    gradient : bool, optional\n",
    "        If True, also return the gradient.\n",
    "    data_range : int, optional\n",
    "        The data range of the input image (distance between minimum and\n",
    "        maximum possible values).  By default, this is estimated from the image\n",
    "        data-type.\n",
    "    multichannel : bool, optional\n",
    "        If True, treat the last dimension of the array as channels. Similarity\n",
    "        calculations are done independently for each channel then averaged.\n",
    "    gaussian_weights : bool, optional\n",
    "        If True, each patch has its mean and variance spatially weighted by a\n",
    "        normalized Gaussian kernel of width sigma=1.5.\n",
    "    full : bool, optional\n",
    "        If True, return the full structural similarity image instead of the\n",
    "        mean value.\n",
    "    Other Parameters\n",
    "    ----------------\n",
    "    use_sample_covariance : bool\n",
    "        if True, normalize covariances by N-1 rather than, N where N is the\n",
    "        number of pixels within the sliding window.\n",
    "    K1 : float\n",
    "        algorithm parameter, K1 (small constant, see [1]_)\n",
    "    K2 : float\n",
    "        algorithm parameter, K2 (small constant, see [1]_)\n",
    "    sigma : float\n",
    "        sigma for the Gaussian when `gaussian_weights` is True.\n",
    "    Returns\n",
    "    -------\n",
    "    mssim : float\n",
    "        The mean structural similarity over the image.\n",
    "    grad : ndarray\n",
    "        The gradient of the structural similarity index between X and Y [2]_.\n",
    "        This is only returned if `gradient` is set to True.\n",
    "    S : ndarray\n",
    "        The full SSIM image.  This is only returned if `full` is set to True.\n",
    "    Notes\n",
    "    -----\n",
    "    To match the implementation of Wang et. al. [1]_, set `gaussian_weights`\n",
    "    to True, `sigma` to 1.5, and `use_sample_covariance` to False.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P.\n",
    "       (2004). Image quality assessment: From error visibility to\n",
    "       structural similarity. IEEE Transactions on Image Processing,\n",
    "       13, 600-612.\n",
    "       https://ece.uwaterloo.ca/~z70wang/publications/ssim.pdf,\n",
    "       DOI:10.1.1.11.2477\n",
    "    .. [2] Avanaki, A. N. (2009). Exact global histogram specification\n",
    "       optimized for structural similarity. Optical Review, 16, 613-621.\n",
    "       http://arxiv.org/abs/0901.0065,\n",
    "       DOI:10.1007/s10043-009-0119-z\n",
    "    \"\"\"\n",
    "    _integer_types = (np.byte, np.ubyte,          # 8 bits\n",
    "                      np.short, np.ushort,        # 16 bits\n",
    "                      np.intc, np.uintc,          # 16 or 32 or 64 bits\n",
    "                      np.int_, np.uint,           # 32 or 64 bits\n",
    "                      np.longlong, np.ulonglong)  # 64 bits\n",
    "    _integer_ranges = {t: (np.iinfo(t).min, np.iinfo(t).max)\n",
    "                       for t in _integer_types}\n",
    "    dtype_range = {np.bool_: (False, True),\n",
    "                   np.bool8: (False, True),\n",
    "                   np.float16: (-1, 1),\n",
    "                   np.float32: (-1, 1),\n",
    "                   np.float64: (-1, 1)}\n",
    "    dtype_range.update(_integer_ranges)\n",
    "    \n",
    "    if not X.dtype == Y.dtype:\n",
    "        raise ValueError('Input images must have the same dtype.')\n",
    "\n",
    "    if not X.shape == Y.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "\n",
    "    if dynamic_range is not None:\n",
    "        warn('`dynamic_range` has been deprecated in favor of '\n",
    "             '`data_range`. The `dynamic_range` keyword argument '\n",
    "             'will be removed in v0.14', skimage_deprecation)\n",
    "        data_range = dynamic_range\n",
    "\n",
    "    if multichannel:\n",
    "        # loop over channels\n",
    "        args = dict(win_size=win_size,\n",
    "                    gradient=gradient,\n",
    "                    data_range=data_range,\n",
    "                    multichannel=False,\n",
    "                    gaussian_weights=gaussian_weights,\n",
    "                    full=full)\n",
    "        args.update(kwargs)\n",
    "        nch = X.shape[-1]\n",
    "        mssim = np.empty(nch)\n",
    "        if gradient:\n",
    "            G = np.empty(X.shape)\n",
    "        if full:\n",
    "            S = np.empty(X.shape)\n",
    "        for ch in range(nch):\n",
    "            ch_result = compare_ssim(X[..., ch], Y[..., ch], **args)\n",
    "            if gradient and full:\n",
    "                mssim[..., ch], G[..., ch], S[..., ch] = ch_result\n",
    "            elif gradient:\n",
    "                mssim[..., ch], G[..., ch] = ch_result\n",
    "            elif full:\n",
    "                mssim[..., ch], S[..., ch] = ch_result\n",
    "            else:\n",
    "                mssim[..., ch] = ch_result\n",
    "        mssim = mssim.mean()\n",
    "        if gradient and full:\n",
    "            return mssim, G, S\n",
    "        elif gradient:\n",
    "            return mssim, G\n",
    "        elif full:\n",
    "            return mssim, S\n",
    "        else:\n",
    "            return mssim\n",
    "\n",
    "    K1 = kwargs.pop('K1', 0.01)\n",
    "    K2 = kwargs.pop('K2', 0.03)\n",
    "    sigma = kwargs.pop('sigma', 1.5)\n",
    "    if K1 < 0:\n",
    "        raise ValueError(\"K1 must be positive\")\n",
    "    if K2 < 0:\n",
    "        raise ValueError(\"K2 must be positive\")\n",
    "    if sigma < 0:\n",
    "        raise ValueError(\"sigma must be positive\")\n",
    "    use_sample_covariance = kwargs.pop('use_sample_covariance', True)\n",
    "\n",
    "    if win_size is None:\n",
    "        if gaussian_weights:\n",
    "            win_size = 11  # 11 to match Wang et. al. 2004\n",
    "        else:\n",
    "            win_size = 7   # backwards compatibility\n",
    "\n",
    "    if np.any((np.asarray(X.shape) - win_size) < 0):\n",
    "        raise ValueError(\n",
    "            \"win_size exceeds image extent.  If the input is a multichannel \"\n",
    "            \"(color) image, set multichannel=True.\")\n",
    "\n",
    "    if not (win_size % 2 == 1):\n",
    "        raise ValueError('Window size must be odd.')\n",
    "\n",
    "    if data_range is None:\n",
    "        dmin, dmax = dtype_range[X.dtype.type]\n",
    "        data_range = dmax - dmin\n",
    "\n",
    "    ndim = X.ndim\n",
    "\n",
    "    if gaussian_weights:\n",
    "        # sigma = 1.5 to approximately match filter in Wang et. al. 2004\n",
    "        # this ends up giving a 13-tap rather than 11-tap Gaussian\n",
    "        filter_func = gaussian_filter\n",
    "        filter_args = {'sigma': sigma}\n",
    "\n",
    "    else:\n",
    "        filter_func = uniform_filter\n",
    "        filter_args = {'size': win_size}\n",
    "\n",
    "    # ndimage filters need floating point data\n",
    "    X = X.astype(np.float64)\n",
    "    Y = Y.astype(np.float64)\n",
    "\n",
    "    NP = win_size ** ndim\n",
    "\n",
    "    # filter has already normalized by NP\n",
    "    if use_sample_covariance:\n",
    "        cov_norm = NP / (NP - 1)  # sample covariance\n",
    "    else:\n",
    "        cov_norm = 1.0  # population covariance to match Wang et. al. 2004\n",
    "\n",
    "    # compute (weighted) means\n",
    "    ux = filter_func(X, **filter_args)\n",
    "    uy = filter_func(Y, **filter_args)\n",
    "\n",
    "    # compute (weighted) variances and covariances\n",
    "    uxx = filter_func(X * X, **filter_args)\n",
    "    uyy = filter_func(Y * Y, **filter_args)\n",
    "    uxy = filter_func(X * Y, **filter_args)\n",
    "    vx = cov_norm * (uxx - ux * ux)\n",
    "    vy = cov_norm * (uyy - uy * uy)\n",
    "    vxy = cov_norm * (uxy - ux * uy)\n",
    "\n",
    "    R = data_range\n",
    "    C1 = (K1 * R) ** 2\n",
    "    C2 = (K2 * R) ** 2\n",
    "\n",
    "    A1, A2, B1, B2 = ((2 * ux * uy + C1,\n",
    "                       2 * vxy + C2,\n",
    "                       ux ** 2 + uy ** 2 + C1,\n",
    "                       vx + vy + C2))\n",
    "    D = B1 * B2\n",
    "    S = (A1 * A2) / D\n",
    "\n",
    "    # to avoid edge effects will ignore filter radius strip around edges\n",
    "    pad = (win_size - 1) // 2\n",
    "\n",
    "    # compute (weighted) mean of ssim\n",
    "    from numpy.lib.arraypad import _as_pairs\n",
    "    ar = np.array(S, copy=False)\n",
    "    crops = _as_pairs(pad, ar.ndim, as_index=True)\n",
    "    slices = tuple(slice(a, ar.shape[i] - b) for i, (a, b) in enumerate(crops))\n",
    "    cropped = ar[slices]\n",
    "    # mssim = crop(S, pad).mean()\n",
    "    mssim = cropped.mean()\n",
    "\n",
    "    if gradient:\n",
    "        # The following is Eqs. 7-8 of Avanaki 2009.\n",
    "        grad = filter_func(A1 / D, **filter_args) * X\n",
    "        grad += filter_func(-S / B2, **filter_args) * Y\n",
    "        grad += filter_func((ux * (A2 - A1) - uy * (B2 - B1) * S) / D,\n",
    "                            **filter_args)\n",
    "        grad *= (2 / X.size)\n",
    "\n",
    "        if full:\n",
    "            return mssim, grad, S\n",
    "        else:\n",
    "            return mssim, grad\n",
    "    else:\n",
    "        if full:\n",
    "            return mssim, S\n",
    "        else:\n",
    "            return mssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_contours(cnts):\n",
    "    # if the length the contours tuple returned by cv2.findContours\n",
    "    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n",
    "    # v4-official\n",
    "    if len(cnts) == 2:\n",
    "        cnts = cnts[0]\n",
    "\n",
    "    # if the length of the contours tuple is '3' then we are using\n",
    "    # either OpenCV v3, v4-pre, or v4-alpha\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "\n",
    "    # otherwise OpenCV has changed their cv2.findContours return\n",
    "    # signature yet again and I have no idea WTH is going on\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or 3, \"\n",
    "            \"otherwise OpenCV changed their cv2.findContours return \"\n",
    "            \"signature yet again. Refer to OpenCV's documentation \"\n",
    "            \"in that case\"))\n",
    "\n",
    "    # return the actual contours array\n",
    "    return cnts\n",
    "\n",
    "def ssim_2Dict(img_path, bg_path):\n",
    "    \n",
    "    ssim_dict = {'cnts_need': None, \n",
    "                 'boxes': [],\n",
    "                 'points': {}\n",
    "                }\n",
    "    \n",
    "    img_filename = os.path.basename(img_path)\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    img_bg = cv2.imread(bg_path)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_bg = cv2.cvtColor(img_bg, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    (score, diff) = ssim(gray, gray_bg, full=True)\n",
    "    diff = (diff * 255).astype('uint8')\n",
    "    \n",
    "    blur = cv2.GaussianBlur(diff, (43, 77), 0)\n",
    "    \n",
    "    thresh = cv2.threshold(blur, 0, 255,\n",
    "                       cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "                        cv2.CHAIN_APPROX_NONE)\n",
    "    cnts = grab_contours(cnts)\n",
    "    cnts_need = []\n",
    "    for cnt in cnts:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        # gray1.size = gray1.width * gray1.height * gray1.channel\n",
    "        # gray has only 1 channel, So area is equal with gray1.size.\n",
    "        if area > gray.size * 0.03:\n",
    "            cnts_need.append(cnt)\n",
    "    \n",
    "    ssim_dict['cnts_need'] = [i.tolist() for i in cnts_need]\n",
    "    \n",
    "    # Draw Boxes\n",
    "    for cnt in cnts_need:\n",
    "        (x, y, w, h) = cv2.boundingRect(cnt)\n",
    "        ssim_dict['boxes'].append({'x': x, 'y': y,\n",
    "                                   'w': w, 'h': h})\n",
    "        \n",
    "    # Edge\n",
    "    i = 0\n",
    "    for cnt in cnts_need:\n",
    "        ssim_dict['points']['box_%d' % i] = []\n",
    "        for point in cnt:\n",
    "            ssim_dict['points']['box_%d' % i].append(point[0].tolist())\n",
    "        i += 1\n",
    "    \n",
    "    return ssim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_path = '/media/commaai-03/Data/workdata/baodi/background/rs07/1583477062.357019287.png'\n",
    "test = allimgs[0]\n",
    "img = os.path.join(root_dir, test)\n",
    "ssim_dict = ssim_2Dict(img, bg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['box_0', 'box_1'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim_dict['points'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_path = '/media/commaai-03/Data/workdata/baodi/background/rs07/1583477062.357019287.png'\n",
    "\n",
    "for img in allimgs:\n",
    "    basename = os.path.splitext(img)[0]\n",
    "    img = os.path.join(root_dir, img)\n",
    "    json_file = os.path.join(root_dir, basename + '.json')\n",
    "    ssim_dict = ssim_2Dict(img, bg_path)\n",
    "    ssim_dict['filename'] = img\n",
    "    \n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        points = []\n",
    "        for point in data['shapes']:\n",
    "            points.append(point['points'][0])\n",
    "            \n",
    "        ssim_dict['head'] = points\n",
    "    \n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(ssim_dict, f, indent=2)\n",
    "    print('[Info]: Finished %s.' % basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/media/commaai-03/Data/workdata/baodi/weighter/rs07/oneBox_twoHead/result'\n",
    "\n",
    "for file in allimgs:\n",
    "    basename = os.path.splitext(file)[0]\n",
    "    img = os.path.join(root_dir, file)\n",
    "    json_file = os.path.join(root_dir, basename + '.json')\n",
    "    \n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    heads = data['head']\n",
    "    boxes = data['boxes']\n",
    "    if len(boxes) > 1:\n",
    "        continue\n",
    "        \n",
    "    box, k, b, x, y = get_midleLine(heads, boxes)\n",
    "    img = cv2.imread(img)\n",
    "    drawed_img = draw_midLine(img, box, k, b, x, y)\n",
    "    cv2.imshow('Result', drawed_img)\n",
    "    k = cv2.waitKey(1000000)\n",
    "    if k == 27 or k == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    if k == ord(' '):\n",
    "        continue\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/media/commaai-03/Data/workdata/baodi/weighter/rs07/oneBox_twoHead/result'\n",
    "json_file = '/media/commaai-03/Data/workdata/baodi/weighter/rs07/oneBox_twoHead/2020-03-10 17:11:52.108586-304a2653b06d-1-7.json'\n",
    "img = '/media/commaai-03/Data/workdata/baodi/weighter/rs07/oneBox_twoHead/2020-03-10 17:11:52.108586-304a2653b06d-1-7.jpg'\n",
    "\n",
    "with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "heads = data['head']\n",
    "boxes = data['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_in_box(point, box):\n",
    "    '''\n",
    "    point: (x, y)\n",
    "    box: [x, y, w, h]\n",
    "    '''\n",
    "    x_p, y_p = point\n",
    "    x, y, w, h = box\n",
    "    x_min, y_min, x_max, y_max = x, y, x+w, y+h\n",
    "\n",
    "    if x_min > x_max:\n",
    "        x_min, x_max = x_max, x_min\n",
    "    elif x_min == x_max:\n",
    "        raise Exception('[Error]: x_min == x_max, it is not a box.')\n",
    "\n",
    "    if y_min > y_max:\n",
    "        y_min, y_max = y_max, y_min\n",
    "    elif y_min == y_max:\n",
    "        raise Exception('[Error]: y_min == y_max, it is not a box.')\n",
    "\n",
    "    x_v = (x_p >= x_min and x_p <= x_max)\n",
    "    y_v = (y_p >= y_min and y_p <= y_max)\n",
    "    if (x_v and y_v):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_midleLine(heads, boxes):\n",
    "        \n",
    "    x1, y1 = heads[0]\n",
    "    x2, y2 = heads[1]\n",
    "    box = boxes[0]\n",
    "    bx, by, bw, bh = box['x'], box['y'], box['w'], box['h']\n",
    "    box = [bx, by, bw, bh]\n",
    "    \n",
    "    # midleLine: y = kx + b\n",
    "    k, b, x, y = [None] * 4\n",
    "    \n",
    "    if (x1 - x2) == 0 and (y1 - y2) != 0:\n",
    "        y = (y1 + y2) / 2\n",
    "        return box, k, b, x, y\n",
    "    elif (y1 - y2) == 0 and (x1 - x2) != 0:\n",
    "        x = (x1 + x2) / 2\n",
    "        return box, k, b, x, y\n",
    "    \n",
    "    if (x1 - x2) == 0 and (y1 - y2) == 0:\n",
    "        raise Exception('[Error]: x1 - x2 = 0 and y1 - y2 = 0!')\n",
    "    \n",
    "    # x1 - x2 != 0 and y1 - y2 != 0\n",
    "    k = - (x1 - x2) / (y1 - y2)\n",
    "    x_midpoint, y_midpoint = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "    b = y_midpoint - (k * x_midpoint)\n",
    "    \n",
    "    return box, k, b, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_by_midLine(img, box, k, b, x=None, y=None):\n",
    "\n",
    "    bx, by, bw, bh = box\n",
    "    if x:\n",
    "        crop_img_1 = img[by:by+bh, bx:bx+(w/2)]\n",
    "        crop_img_2 = img[by:by+bh, bx+(w/2):bx+w]\n",
    "    if y:\n",
    "        crop_img_1 = img[by:by+(bh/2), bx:bx+w]\n",
    "        crop_img_2 = img[by+(bh/2):by+bh, bx:bx+w]\n",
    "    if x and y:\n",
    "        raise Exception('[Error]: crop only nead x or y or neither, not both.')\n",
    "    \n",
    "    if not x and not y:\n",
    "        def filter_line(x, y, k, b):\n",
    "            return (k*x + b) <= y\n",
    "\n",
    "        crop_img_1 = np.zeros((bh, bw, 3), dtype=np.uint8)\n",
    "        crop_img_2 = np.zeros((bh, bw, 3), dtype=np.uint8)\n",
    "\n",
    "        for _w in range(bw):\n",
    "            for _h in range(bh):\n",
    "                x, y = bx + _w, by + _h\n",
    "                if filter_line(x, y, k, b):\n",
    "                    crop_img_1[_h, _w] = img[y, x]\n",
    "                else:\n",
    "                    crop_img_2[_h, _w] = img[y, x]\n",
    "    return crop_img_1, crop_img_2\n",
    "\n",
    "\n",
    "def draw_midLine(img, box, k, b, x=None, y=None):\n",
    "    bx, by, bw, bh = box\n",
    "    if x:\n",
    "        p1 = [x, by]\n",
    "        p2 = [x, by+bh]\n",
    "    if y:\n",
    "        p1 = [bx, y]\n",
    "        p2 = [bx+bw, y]\n",
    "    if x and y:\n",
    "        raise Exception('[Error]: crop only nead x or y or neither, not both.')\n",
    "        \n",
    "    if not x and not y:\n",
    "        # Dangerous: num * num != num^2\n",
    "        _y1 = k * bx + b\n",
    "        _p1 = [bx, _y1]\n",
    "        _y2 = k * (bx + bw) + b\n",
    "        _p2 = [bx+bw, _y2]\n",
    "        _x1 = (by - b) / k\n",
    "        _p3 = [_x1, by]\n",
    "        _x2 = (by + bh - b) / k\n",
    "        _p4 = [_x2, by+bh]\n",
    "        all_points = [_p1, _p2, _p3, _p4]\n",
    "        result = []\n",
    "        for point in all_points:\n",
    "            if point_in_box(point, box):\n",
    "                result.append(point)       \n",
    "        assert len(result) == 2, '[Error]: Midline error, one line not two points.'\n",
    "        p1, p2 = result\n",
    "        \n",
    "    p1 = [int(i) for i in p1]\n",
    "    p2 = [int(i) for i in p2]\n",
    "    # box\n",
    "    drawed_img = cv2.rectangle(img, (bx, by), (bx+bw, by+bh), (0, 0, 255), 2)\n",
    "    # line\n",
    "    drawed_img = cv2.line(drawed_img, tuple(p1), tuple(p2), (255,0,0), thickness=3)\n",
    "    return drawed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box, k, b, x, y = get_midleLine(heads, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('box:', box)\n",
    "print('k:', k)\n",
    "print('b:', b)\n",
    "print('x:', x)\n",
    "print('y:', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img)\n",
    "drawed_img = draw_midLine(img, box, k, b, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    cv2.imshow('drawed', drawed_img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27 or k == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibration_kabsch import cal_transformation_kabsch, Transformation\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import dt_apriltags\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ros\n",
    "import rospy\n",
    "import message_filters\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "class Image_Converter(object):\n",
    "    \n",
    "    def __init__(self, color_topic, depth_topic=None):\n",
    "        self.bridge = CvBridge()\n",
    "\n",
    "        image_sub = message_filters.Subscriber(color_topic, Image)\n",
    "        depth_sub = message_filters.Subscriber(depth_topic, Image)\n",
    "\n",
    "        self.timeSync = message_filters.ApproximateTimeSynchronizer(\n",
    "                        [image_sub, depth_sub], 10, 0.5)\n",
    "        self.timeSync.registerCallback(self.callback)\n",
    "        \n",
    "    def callback(self, image_msg, depth_msg):\n",
    "        header = image_msg.header\n",
    "        secs = header.stamp.secs\n",
    "        nsecs = header.stamp.nsecs\n",
    "        try:\n",
    "            image_data = self.bridge.imgmsg_to_cv2(image_msg, \"bgr8\")\n",
    "            depth_data = self.bridge.imgmsg_to_cv2(depth_msg, \"passthrough\")\n",
    "        except CvBridgeError as e:\n",
    "            print(e)\n",
    "            \n",
    "        depth_data = np.array(depth_data, dtype=np.uint16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_depth_frame(depth_frame, decimation_magnitude=1.0, spatial_magnitude=2.0, spatial_smooth_alpha=0.5,\n",
    "                             spatial_smooth_delta=20, temporal_smooth_alpha=0.4, temporal_smooth_delta=20):\n",
    "    \"\"\"\n",
    "    Filter the depth frame acquired using the Intel RealSense device\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    depth_frame          : rs.frame()\n",
    "                           The depth frame to be post-processed\n",
    "    decimation_magnitude : double\n",
    "                           The magnitude of the decimation filter\n",
    "    spatial_magnitude    : double\n",
    "                           The magnitude of the spatial filter\n",
    "    spatial_smooth_alpha : double\n",
    "                           The alpha value for spatial filter based smoothening\n",
    "    spatial_smooth_delta : double\n",
    "                           The delta value for spatial filter based smoothening\n",
    "    temporal_smooth_alpha: double\n",
    "                           The alpha value for temporal filter based smoothening\n",
    "    temporal_smooth_delta: double\n",
    "                           The delta value for temporal filter based smoothening\n",
    "\n",
    "    Return:\n",
    "    ----------\n",
    "    filtered_frame : rs.frame()\n",
    "                     The post-processed depth frame\n",
    "    \"\"\"\n",
    "\n",
    "    # Post processing possible only on the depth_frame\n",
    "    assert (depth_frame.is_depth_frame())\n",
    "\n",
    "    # Available filters and control options for the filters\n",
    "    decimation_filter = rs.decimation_filter()\n",
    "    spatial_filter = rs.spatial_filter()\n",
    "    temporal_filter = rs.temporal_filter()\n",
    "\n",
    "    filter_magnitude = rs.option.filter_magnitude\n",
    "    filter_smooth_alpha = rs.option.filter_smooth_alpha\n",
    "    filter_smooth_delta = rs.option.filter_smooth_delta\n",
    "\n",
    "    # Apply the control parameters for the filter\n",
    "    decimation_filter.set_option(filter_magnitude, decimation_magnitude)\n",
    "    spatial_filter.set_option(filter_magnitude, spatial_magnitude)\n",
    "    spatial_filter.set_option(filter_smooth_alpha, spatial_smooth_alpha)\n",
    "    spatial_filter.set_option(filter_smooth_delta, spatial_smooth_delta)\n",
    "    temporal_filter.set_option(filter_smooth_alpha, temporal_smooth_alpha)\n",
    "    temporal_filter.set_option(filter_smooth_delta, temporal_smooth_delta)\n",
    "\n",
    "    # Apply the filters\n",
    "    filtered_frame = decimation_filter.process(depth_frame)\n",
    "    filtered_frame = spatial_filter.process(filtered_frame)\n",
    "    filtered_frame = temporal_filter.process(filtered_frame)\n",
    "\n",
    "    return filtered_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSCalibration:\n",
    "    \n",
    "    def __init__(self, intrinsic=None, tag_family='tagStandard41h12', tag_size=None):\n",
    "\n",
    "        self.at_detector = dt_apriltags.Detector(searchpath=['apriltags'],\n",
    "                               families=tag_family,\n",
    "                               nthreads=1,\n",
    "                               quad_decimate=1.0,\n",
    "                               quad_sigma=0.0,\n",
    "                               refine_edges=1,\n",
    "                               decode_sharpening=0.25,\n",
    "                               debug=0)\n",
    "        self.intrinsic = intrinsic\n",
    "        self.tag_size = tag_size\n",
    "        \n",
    "    def convert_depth_pixel_to_metric_coordinate(self, depth, pixel_x, pixel_y):\n",
    "        X = (pixel_x - self.intrinsic.ppx) / self.intrinsic.fx * depth\n",
    "        Y = (pixel_y - self.intrinsic.ppy) / self.intrinsic.fy * depth\n",
    "        return X, Y, depth\n",
    "        \n",
    "    def get_3d_corners(self, img, depth):\n",
    "        '''\n",
    "        Args:\n",
    "        ------\n",
    "        img: (H, W, C) ndarray, 1 for gray or 3 for color.\n",
    "        depth: (H, W) ndarray.\n",
    "        '''\n",
    "        assert img.shape[:2] == depth.shape[:2]\n",
    "        if img.shape[-1] == 3:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        elif img.shape[-1] == 1:\n",
    "            gray = img\n",
    "        else:\n",
    "            raise Exception('Only support gray or color.')\n",
    "        detections = self.at_detector.detect(gray)\n",
    "        if detections:\n",
    "            corners2D = {}\n",
    "            for each in detections:\n",
    "                corners, center = each.corners.tolist(), each.center.tolist()\n",
    "                corners.append(center)\n",
    "                corners2D[each.tag_id] = corners\n",
    "                \n",
    "            corners3D = {}\n",
    "            for k, v in corners2D.items():\n",
    "                corners3D[k] = []\n",
    "                for point in v:\n",
    "                    X = int(round(point[0]))\n",
    "                    Y = int(round(point[1]))\n",
    "                    Z = 3.1 # depth[Y, X]\n",
    "                    if Z == 0 or Z is None:\n",
    "                        Z = None\n",
    "                    # Convert\n",
    "                    else:\n",
    "                        X, Y, Z = self.convert_depth_pixel_to_metric_coordinate(Z, X, Y)\n",
    "                    corners3D[k].append([X, Y, Z])\n",
    "            return corners3D\n",
    "        else:\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "def perform_RT(src3D, dst3D):\n",
    "    \n",
    "    srcPoints = []\n",
    "    dstPoints = []\n",
    "    \n",
    "    for k in src3D.keys():\n",
    "        if not k in dst3D.keys():\n",
    "            continue\n",
    "        for i in range(len(src3D[k])):\n",
    "            src_point = src3D[k][i]\n",
    "            dst_point = dst3D[k][i]\n",
    "            # Check Z value is ok.\n",
    "            \n",
    "            if src_point[2] and dst_point[2]:\n",
    "                srcPoints.append(src_point)\n",
    "                dstPoints.append(dst_point)\n",
    "    if len(srcPoints) < 5:\n",
    "        return None, None\n",
    "\n",
    "    srcPoints = np.asarray(srcPoints)\n",
    "    dstPoints = np.asarray(dstPoints)\n",
    "    R, T, rmsd_value = cal_transformation_kabsch(srcPoints, dstPoints)\n",
    "    print(rmsd_value)\n",
    "    return R, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS15 = RSCalibration(intrinsic=rs15_camera_intrinsics)\n",
    "RS16 = RSCalibration(intrinsic=rs16_camera_intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_detector = dt_apriltags.Detector(searchpath=['apriltags'],\n",
    "                               families='tagStandard41h12',\n",
    "                               nthreads=1,\n",
    "                               quad_decimate=1.0,\n",
    "                               quad_sigma=0.0,\n",
    "                               refine_edges=1,\n",
    "                               decode_sharpening=0.25,\n",
    "                               debug=0)\n",
    "\n",
    "gray = cv2.cvtColor(color, cv2.COLOR_BGR2GRAY)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(gray)\n",
    "detections = at_detector.detect(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections[0].corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections[0].center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [[604.20355225, 320.29168701],\n",
    "       [587.84625244, 319.8927002 ],\n",
    "       [587.66259766, 335.98678589],\n",
    "       [604.03594971, 336.80117798],\n",
    "       [595.83307789, 328.23411996]]\n",
    "for point in points:\n",
    "    x = round(point[0])\n",
    "    y = round(point[1])\n",
    "    cv2.circle(gray, (x,y), 1,(0,0,0), 0)\n",
    "cv2.imshow('gray', gray)\n",
    "k = cv2.waitKey()\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/commaai-03/Data/color/apriltags/test'\n",
    "color = '/home/commaai-03/Data/color/apriltags/rs15_0.jpg'\n",
    "depth = '/home/commaai-03/Data/color/apriltags/rs15_0.png'\n",
    "\n",
    "color = cv2.imread(color)\n",
    "depth = cv2.imread(depth, cv2.IMREAD_ANYDEPTH) / 1000.\n",
    "\n",
    "corners3D1 = RS15.get_3d_corners(color, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: [[1.074002480766813, 0.46997833622140717, 3.1],\n",
       "  [0.9883162115302764, 0.46997833622140717, 3.1],\n",
       "  [0.9933565803088962, 0.5556567150420272, 3.1],\n",
       "  [1.074002480766813, 0.5556567150420272, 3.1],\n",
       "  [1.0336795305378546, 0.5153374779499708, 3.1]],\n",
       " 11: [[0.8018225667213438, 0.4800581454944213, 3.1],\n",
       "  [0.7211766662634271, 0.4800581454944213, 3.1],\n",
       "  [0.7211766662634271, 0.5606966196785342, 3.1],\n",
       "  [0.8068629354999637, 0.5606966196785342, 3.1],\n",
       "  [0.7665399852710053, 0.5203773825864777, 3.1]],\n",
       " 21: [[1.0689621119881931, 0.1827037719405048, 3.1],\n",
       "  [0.9883162115302764, 0.1827037719405048, 3.1],\n",
       "  [0.9883162115302764, 0.26334224612461776, 3.1],\n",
       "  [1.074002480766813, 0.2683821507611248, 3.1],\n",
       "  [1.0286391617592348, 0.22302300903256125, 3.1]],\n",
       " 99: [[0.8018225667213438, 0.17766386730399775, 3.1],\n",
       "  [0.7211766662634271, 0.17262396266749067, 3.1],\n",
       "  [0.7211766662634271, 0.2583023414881107, 3.1],\n",
       "  [0.8018225667213438, 0.2583023414881107, 3.1],\n",
       "  [0.7614996164923855, 0.2179831043960542, 3.1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/commaai-03/Data/color/apriltags/test'\n",
    "color = '/home/commaai-03/Data/color/apriltags/rs16_0.jpg'\n",
    "depth = '/home/commaai-03/Data/color/apriltags/rs16_0.png'\n",
    "\n",
    "color = cv2.imread(color)\n",
    "depth = cv2.imread(depth, cv2.IMREAD_ANYDEPTH) / 1000.\n",
    "\n",
    "corners3D2 = RS16.get_3d_corners(color, depth) \n",
    "corners3D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: [[1.339393940605284, -0.3822363663571299, 3.1],\n",
       "  [1.2480298032901305, -0.3822363663571299, 3.1],\n",
       "  [1.2480298032901305, -0.29598367432195777, 3.1],\n",
       "  [1.3343181551988865, -0.29598367432195777, 3.1],\n",
       "  [1.2937118719477072, -0.3416468642229313, 3.1]],\n",
       " 11: [[1.060225743253426, -0.3822363663571299, 3.1],\n",
       "  [0.9739373913446698, -0.3873100541239047, 3.1],\n",
       "  [0.9688616059382724, -0.3010573620887326, 3.1],\n",
       "  [1.0551499578470287, -0.29598367432195777, 3.1],\n",
       "  [1.0145436745958492, -0.3416468642229313, 3.1]],\n",
       " 21: [[1.3546212968244762, -0.6714365690632951, 3.1],\n",
       "  [1.2632571595093227, -0.67651025683007, 3.1],\n",
       "  [1.2632571595093227, -0.5902575647948979, 3.1],\n",
       "  [1.3495455114180788, -0.5902575647948979, 3.1],\n",
       "  [1.3089392281668994, -0.6308470669290965, 3.1]],\n",
       " 99: [[1.0754530994726181, -0.6917313201303945, 3.1],\n",
       "  [0.989164747563862, -0.6968050078971693, 3.1],\n",
       "  [0.989164747563862, -0.6105523158619972, 3.1],\n",
       "  [1.0754530994726181, -0.6054786280952225, 3.1],\n",
       "  [1.0297710308150414, -0.6511418179961959, 3.1]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners3D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = depth[273:350, 572:642]\n",
    "clip.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = depth > 0\n",
    "c = depth * b\n",
    "d = c.ravel()[np.flatnonzero(c)]\n",
    "np.sort(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00695752950406751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 9.98724374e-01,  5.04938024e-02,  1.84182523e-29],\n",
       "        [-5.04938024e-02,  9.98724374e-01, -1.79300218e-27],\n",
       "        [-1.08930255e-28,  1.78978497e-27,  1.00000000e+00]]),\n",
       " array([-0.23863015,  0.91777755,  0.        ]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_RT(corners3D1, corners3D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "\n",
    "rs15_camera_intrinsics = EasyDict()\n",
    "rs15_camera_intrinsics.ppx = 424.120849609375\n",
    "rs15_camera_intrinsics.ppy = 241.3369903564453\n",
    "rs15_camera_intrinsics.fx = 610.742919921875\n",
    "rs15_camera_intrinsics.fy = 610.9954223632812\n",
    "\n",
    "rs16_camera_intrinsics = EasyDict()\n",
    "rs16_camera_intrinsics.ppx = 428.91986083984375\n",
    "rs16_camera_intrinsics.ppy = 238.74856567382812\n",
    "rs16_camera_intrinsics.fx = 615.0343627929688\n",
    "rs16_camera_intrinsics.fy = 615.0910034179688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store image\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import rospy\n",
    "import message_filters\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from sensor_msgs.msg import Image\n",
    "\n",
    "\n",
    "class SaveImage(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rsidlist = ['rs15', 'rs16', 'rs17', 'rs18']\n",
    "        self.save_dir = os.path.join('/home/ai-cap02/workspace/data',\n",
    "                                     'apriltags')\n",
    "        rospy.init_node('save_images', anonymous=True)\n",
    "    \n",
    "    def callback(self, color, depth, rsid):\n",
    "        header = color.header\n",
    "        secs = header.stamp.secs\n",
    "        nsecs = header.stamp.nsecs \n",
    "        color = CvBridge().imgmsg_to_cv2(color, desired_encoding=color.encoding)\n",
    "        depth = CvBridge().imgmsg_to_cv2(depth, desired_encoding=depth.encoding)\n",
    "        \n",
    "        path_color = os.path.join(self.save_dir, rsid, 'color')\n",
    "        path_depth = os.path.join(self.save_dir, rsid, 'depth')\n",
    "        if not os.path.exists(path_color):\n",
    "            os.makedirs(path_color)\n",
    "        if not os.path.exists(path_depth):\n",
    "            os.makedirs(path_depth)\n",
    "        \n",
    "        file_color = os.path.join(path_color, '%s.%s.jpg' %(secs, nsecs))\n",
    "        file_depth = os.path.join(path_depth, '%s.%s.png' %(secs, nsecs))\n",
    "        \n",
    "        cv2.imwrite(file_color, color)\n",
    "        cv2.imwrite(file_depth, depth)\n",
    "        print('[Info]: %s saved!' % file_color)\n",
    "        \n",
    "\n",
    "    def run(self):\n",
    "        for rsid in self.rsidlist:\n",
    "            color_sub = message_filters.Subscriber('/' + rsid + '/color/image_rect_color', Image)\n",
    "            depth_sub = message_filters.Subscriber('/' + rsid + '/aligned_depth_to_color/image_raw', Image)\n",
    "            ts = message_filters.ApproximateTimeSynchronizer([color_sub, depth_sub], 10, 0.02)\n",
    "            ts.registerCallback(self.callback, rsid)\n",
    "            \n",
    "        rospy.spin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def showImg(img):\n",
    "    cv2.imshow('showImg', img)\n",
    "    k = cv2.waitKey()\n",
    "    if k:\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "\n",
    "        \n",
    "img_file = '/home/commaai-03/Data/color/test/rs15_0.jpg'\n",
    "img = cv2.imread(img_file, 0)\n",
    "\n",
    "h = [[(i, 0),(i, 480)] for i in range(0, 848, 13)]\n",
    "v = [[(0, i), (848, i)] for i in range(0, 480, 7)]\n",
    "\n",
    "loop = len(h) if len(h) < len(v) else len(v)\n",
    "\n",
    "for i in range(loop):\n",
    "    cv2.line(img, h[i][0], h[i][1], (0, 0, 255), 1, 1)\n",
    "    cv2.line(img, v[i][0], v[i][1], (0, 0, 255), 1, 1)\n",
    "\n",
    "showImg(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [[(i, 0),(i, 480)] for i in range(0, 848, 13)]\n",
    "v = [[(0, i), (848, i)] for i in range(0, 480, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0), (0, 480)],\n",
       " [(13, 0), (13, 480)],\n",
       " [(26, 0), (26, 480)],\n",
       " [(39, 0), (39, 480)],\n",
       " [(52, 0), (52, 480)],\n",
       " [(65, 0), (65, 480)],\n",
       " [(78, 0), (78, 480)],\n",
       " [(91, 0), (91, 480)],\n",
       " [(104, 0), (104, 480)],\n",
       " [(117, 0), (117, 480)],\n",
       " [(130, 0), (130, 480)],\n",
       " [(143, 0), (143, 480)],\n",
       " [(156, 0), (156, 480)],\n",
       " [(169, 0), (169, 480)],\n",
       " [(182, 0), (182, 480)],\n",
       " [(195, 0), (195, 480)],\n",
       " [(208, 0), (208, 480)],\n",
       " [(221, 0), (221, 480)],\n",
       " [(234, 0), (234, 480)],\n",
       " [(247, 0), (247, 480)],\n",
       " [(260, 0), (260, 480)],\n",
       " [(273, 0), (273, 480)],\n",
       " [(286, 0), (286, 480)],\n",
       " [(299, 0), (299, 480)],\n",
       " [(312, 0), (312, 480)],\n",
       " [(325, 0), (325, 480)],\n",
       " [(338, 0), (338, 480)],\n",
       " [(351, 0), (351, 480)],\n",
       " [(364, 0), (364, 480)],\n",
       " [(377, 0), (377, 480)],\n",
       " [(390, 0), (390, 480)],\n",
       " [(403, 0), (403, 480)],\n",
       " [(416, 0), (416, 480)],\n",
       " [(429, 0), (429, 480)],\n",
       " [(442, 0), (442, 480)],\n",
       " [(455, 0), (455, 480)],\n",
       " [(468, 0), (468, 480)],\n",
       " [(481, 0), (481, 480)],\n",
       " [(494, 0), (494, 480)],\n",
       " [(507, 0), (507, 480)],\n",
       " [(520, 0), (520, 480)],\n",
       " [(533, 0), (533, 480)],\n",
       " [(546, 0), (546, 480)],\n",
       " [(559, 0), (559, 480)],\n",
       " [(572, 0), (572, 480)],\n",
       " [(585, 0), (585, 480)],\n",
       " [(598, 0), (598, 480)],\n",
       " [(611, 0), (611, 480)],\n",
       " [(624, 0), (624, 480)],\n",
       " [(637, 0), (637, 480)],\n",
       " [(650, 0), (650, 480)],\n",
       " [(663, 0), (663, 480)],\n",
       " [(676, 0), (676, 480)],\n",
       " [(689, 0), (689, 480)],\n",
       " [(702, 0), (702, 480)],\n",
       " [(715, 0), (715, 480)],\n",
       " [(728, 0), (728, 480)],\n",
       " [(741, 0), (741, 480)],\n",
       " [(754, 0), (754, 480)],\n",
       " [(767, 0), (767, 480)],\n",
       " [(780, 0), (780, 480)],\n",
       " [(793, 0), (793, 480)],\n",
       " [(806, 0), (806, 480)],\n",
       " [(819, 0), (819, 480)],\n",
       " [(832, 0), (832, 480)],\n",
       " [(845, 0), (845, 480)]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

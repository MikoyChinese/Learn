{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 2\n",
    "------------\n",
    "\n",
    "Previously in `1_notmnist.ipynb`, we created a pickle with formatted datasets for training, development and testing on the [notMNIST dataset](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html).\n",
    "\n",
    "The goal of this assignment is to progressively train deeper and more accurate models using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './dataset/'\n",
    "pickle_file = os.path.join(data_root, 'noMNIST_sanit.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dict's key: dict_keys(['train_dataset', 'train_labels', 'valid_dataset', 'valid_labels', 'test_dataset', 'test_labels'])\n",
      "Train set (200000, 28, 28) Labels: (200000,)\n",
      "Valid set (8927, 28, 28) Labels: (8927,)\n",
      "Test set (8736, 28, 28) Labels: (8736,)\n"
     ]
    }
   ],
   "source": [
    "with open(pickle_file, 'rb') as f:\n",
    "    data = pickle.load(f, encoding='bytes')\n",
    "    print('Data dict\\'s key:', data.keys())\n",
    "    _train_dataset = data['train_dataset']\n",
    "    _train_labels = data['train_labels']\n",
    "    _valid_dataset = data['valid_dataset']\n",
    "    _valid_labels = data['valid_labels']\n",
    "    _test_dataset = data['test_dataset']\n",
    "    _test_labels = data['test_labels']\n",
    "    del data\n",
    "    print('Train set', _train_dataset.shape, 'Labels:', _train_labels.shape)\n",
    "    print('Valid set', _valid_dataset.shape, 'Labels:', _valid_labels.shape)\n",
    "    print('Test set', _test_dataset.shape, 'Labels:', _test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data as a flat matrix.\n",
    "- labels as float one-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size*image_size)).astype(np.float32)\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (200000, 784) Labels: (200000, 10)\n",
      "Valid set (8927, 784) Labels: (8927, 10)\n",
      "Test set (8736, 784) Labels: (8736, 10)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_labels = reformat(_train_dataset, _train_labels)\n",
    "valid_dataset, valid_labels = reformat(_valid_dataset, _valid_labels)\n",
    "test_dataset, test_labels = reformat(_test_dataset, _test_labels)\n",
    "\n",
    "print('Train set', train_dataset.shape, 'Labels:',train_labels.shape)\n",
    "print('Valid set', valid_dataset.shape, 'Labels:',valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, 'Labels:',test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a multinomial logistic regression using simple gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 10000\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data\n",
    "    # tf_train_dataset: (train_subset, 28*28)\n",
    "    # tf_train_labels: (train_subset, num_labels)\n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Variables.\n",
    "    # weights: [28*28, num_labels]\n",
    "    weights = tf.get_variable('weights', \n",
    "                              shape=[tf_train_dataset.get_shape()[-1],\n",
    "                                     tf_train_labels.get_shape()[-1]],\n",
    "                              initializer=tf.truncated_normal_initializer(0., 1.))\n",
    "    # biases: [num_labels, ]\n",
    "    biases = tf.get_variable('biases',\n",
    "                             shape=[tf_train_labels.get_shape()[-1]],\n",
    "                             initializer=tf.initializers.constant(0.0))\n",
    "    \n",
    "    # Training computation.\n",
    "    # _logits: [train_subset, num_labels]\n",
    "    _logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    _loss = tf.reduce_mean(\n",
    "                         tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                            labels=tf_train_labels,\n",
    "                            logits=_logits))\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(_loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    # Normalized exponential function: softmax\n",
    "    # softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "    train_prediction = tf.nn.softmax(_logits)\n",
    "    valid_logits = tf.matmul(tf_valid_dataset, weights) + biases\n",
    "    valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    test_logits = tf.matmul(tf_test_dataset, weights) + biases\n",
    "    test_prediction = tf.nn.softmax(test_logits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(10000), Dimension(10)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensorflow]: Initialized!\n",
      "Loss at step 100: 2.266094\n",
      "Training accuracy: 72.3%\n",
      "Validation accuracy: 69.7%\n",
      "Loss at step 200: 1.833823\n",
      "Training accuracy: 75.0%\n",
      "Validation accuracy: 72.1%\n",
      "Loss at step 300: 1.596566\n",
      "Training accuracy: 76.3%\n",
      "Validation accuracy: 72.7%\n",
      "Loss at step 400: 1.434920\n",
      "Training accuracy: 77.2%\n",
      "Validation accuracy: 73.2%\n",
      "Loss at step 500: 1.314515\n",
      "Training accuracy: 78.1%\n",
      "Validation accuracy: 73.4%\n",
      "Loss at step 600: 1.220287\n",
      "Training accuracy: 78.5%\n",
      "Validation accuracy: 73.8%\n",
      "Loss at step 700: 1.143593\n",
      "Training accuracy: 79.0%\n",
      "Validation accuracy: 73.9%\n",
      "Loss at step 800: 1.079304\n",
      "Training accuracy: 79.5%\n",
      "Validation accuracy: 74.3%\n",
      "Loss at step 900: 1.024315\n",
      "Training accuracy: 79.8%\n",
      "Validation accuracy: 74.4%\n",
      "Loss at step 1000: 0.976624\n",
      "Training accuracy: 80.2%\n",
      "Validation accuracy: 74.5%\n",
      "Test accuracy: 81.8%\n",
      "[[0.1        0.1        0.1        ... 0.1        0.1        0.1       ]\n",
      " [0.1        0.1        0.1        ... 0.1        0.1        0.97682446]\n",
      " [0.1        0.1        0.1        ... 0.1        0.1        0.1       ]\n",
      " ...\n",
      " [0.1        0.1        0.1        ... 0.1        0.1        0.1       ]\n",
      " [0.1        0.1        0.1        ... 0.1        0.9992404  0.1       ]\n",
      " [0.99982774 0.1        0.1        ... 0.1        0.1        0.1       ]]\n"
     ]
    }
   ],
   "source": [
    "steps = 1000\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    acc = np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0] * 100.\n",
    "    return acc\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # This is a one-time operation which ensures the parameters get initialized as\n",
    "    # we described in the graph: random weights for the matrix, zeros for the\n",
    "    # biases. \n",
    "    tf.global_variables_initializer().run()\n",
    "    print('[Tensorflow]: Initialized!')\n",
    "    for step in range(steps):\n",
    "        # Run the computations.\n",
    "        _, loss, predictions = session.run([optimizer, _loss, train_prediction])\n",
    "        if ((step+1) % 100 == 0):\n",
    "            print('Loss at step %d: %f' % (step+1, loss))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(\n",
    "                predictions, train_labels[:train_subset, :]))\n",
    "            \n",
    "            print('Validation accuracy: %.1f%%' % accuracy(\n",
    "                valid_prediction.eval(), valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(\n",
    "        test_prediction.eval(), test_labels))\n",
    "    # tensor.eval() == session.run(tensor)\n",
    "    print(test_prediction.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Problem\n",
    "-------\n",
    "\n",
    "Turn the logistic regression example with SGD into a 1-hidden layer neural network with rectified linear units [nn.relu()](https://www.tensorflow.org/versions/r0.7/api_docs/python/nn.html#relu) and 1024 hidden nodes. This model should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    # Input data\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size*image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32,\n",
    "                                     shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Variables.\n",
    "    # These are the parameters that we are going to be training.\n",
    "    weights = tf.get_variable('weights',\n",
    "                              shape= [tf_train_dataset.get_shape()[-1], \n",
    "                                      tf_train_labels.get_shape()[-1]],\n",
    "                              initializer=tf.initializers.truncated_normal(0., 1.))\n",
    "    biases = tf.get_variable('biases',\n",
    "                             shape= [tf_train_labels.get_shape()[-1]],\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    # Training compution.\n",
    "    _logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    _loss = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                        labels=tf_train_labels, logits=_logits))\n",
    "    \n",
    "    # Optimizer\n",
    "    opt = tf.train.GradientDescentOptimizer(0.5).minimize(_loss)\n",
    "    \n",
    "    # Prediction for training, validation, and the test data.\n",
    "    train_prediction = tf.nn.softmax(_logits)\n",
    "    valid_logits = tf.matmul(tf_valid_dataset, weights) + biases\n",
    "    valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    test_logits = tf.matmul(tf_test_dataset, weights) + biases\n",
    "    test_prediction = tf.nn.softmax(test_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8736, 784)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensorflow]: Initialized!\n",
      "Minibatch step: 500, loss: 1.15563, acc: 81.2%.\n",
      "Validation accuracy: 75.3%.\n",
      "Minibatch step: 1000, loss: 1.60892, acc: 75.8%.\n",
      "Validation accuracy: 75.9%.\n",
      "Minibatch step: 1500, loss: 1.45336, acc: 76.6%.\n",
      "Validation accuracy: 76.3%.\n",
      "Minibatch step: 2000, loss: 0.99298, acc: 77.3%.\n",
      "Validation accuracy: 77.2%.\n",
      "Minibatch step: 2500, loss: 1.30347, acc: 75.0%.\n",
      "Validation accuracy: 77.3%.\n",
      "Minibatch step: 3000, loss: 0.76087, acc: 82.0%.\n",
      "Validation accuracy: 78.2%.\n",
      "Minibatch step: 3500, loss: 1.01908, acc: 77.3%.\n",
      "Validation accuracy: 77.9%.\n",
      "Minibatch step: 4000, loss: 0.80510, acc: 80.5%.\n",
      "Validation accuracy: 78.4%.\n",
      "Minibatch step: 4500, loss: 0.59977, acc: 84.4%.\n",
      "Validation accuracy: 78.9%.\n",
      "Minibatch step: 5000, loss: 0.74360, acc: 81.2%.\n",
      "Validation accuracy: 78.9%.\n",
      "Minibatch step: 5500, loss: 1.02882, acc: 75.8%.\n",
      "Validation accuracy: 79.0%.\n",
      "Minibatch step: 6000, loss: 0.88711, acc: 75.8%.\n",
      "Validation accuracy: 79.4%.\n",
      "Minibatch step: 6500, loss: 0.90879, acc: 78.9%.\n",
      "Validation accuracy: 79.7%.\n",
      "Minibatch step: 7000, loss: 0.60443, acc: 82.8%.\n",
      "Validation accuracy: 79.8%.\n",
      "Minibatch step: 7500, loss: 1.03265, acc: 75.8%.\n",
      "Validation accuracy: 80.6%.\n",
      "Minibatch step: 8000, loss: 0.49305, acc: 85.2%.\n",
      "Validation accuracy: 79.3%.\n",
      "Minibatch step: 8500, loss: 0.60033, acc: 83.6%.\n",
      "Validation accuracy: 79.8%.\n",
      "Minibatch step: 9000, loss: 0.74407, acc: 82.8%.\n",
      "Validation accuracy: 79.9%.\n",
      "Minibatch step: 9500, loss: 0.91428, acc: 76.6%.\n",
      "Validation accuracy: 80.3%.\n",
      "Minibatch step: 10000, loss: 0.74840, acc: 78.1%.\n",
      "Validation accuracy: 80.2%.\n",
      "Minibatch step: 10500, loss: 0.75830, acc: 82.0%.\n",
      "Validation accuracy: 80.8%.\n",
      "Minibatch step: 11000, loss: 0.41464, acc: 89.1%.\n",
      "Validation accuracy: 80.3%.\n",
      "Minibatch step: 11500, loss: 0.76246, acc: 80.5%.\n",
      "Validation accuracy: 80.9%.\n",
      "Minibatch step: 12000, loss: 0.46798, acc: 86.7%.\n",
      "Validation accuracy: 80.4%.\n",
      "Minibatch step: 12500, loss: 0.59452, acc: 85.2%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 13000, loss: 0.82186, acc: 76.6%.\n",
      "Validation accuracy: 80.6%.\n",
      "Minibatch step: 13500, loss: 0.73319, acc: 82.0%.\n",
      "Validation accuracy: 80.9%.\n",
      "Minibatch step: 14000, loss: 0.75309, acc: 75.8%.\n",
      "Validation accuracy: 80.2%.\n",
      "Minibatch step: 14500, loss: 0.73256, acc: 82.8%.\n",
      "Validation accuracy: 80.4%.\n",
      "Minibatch step: 15000, loss: 0.63424, acc: 82.0%.\n",
      "Validation accuracy: 80.8%.\n",
      "Minibatch step: 15500, loss: 0.84878, acc: 76.6%.\n",
      "Validation accuracy: 80.1%.\n",
      "Minibatch step: 16000, loss: 0.64800, acc: 82.0%.\n",
      "Validation accuracy: 80.6%.\n",
      "Minibatch step: 16500, loss: 0.46117, acc: 88.3%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 17000, loss: 0.78093, acc: 85.2%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 17500, loss: 0.74429, acc: 81.2%.\n",
      "Validation accuracy: 80.8%.\n",
      "Minibatch step: 18000, loss: 0.72512, acc: 84.4%.\n",
      "Validation accuracy: 80.8%.\n",
      "Minibatch step: 18500, loss: 0.76646, acc: 78.1%.\n",
      "Validation accuracy: 80.7%.\n",
      "Minibatch step: 19000, loss: 0.67723, acc: 81.2%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 19500, loss: 0.73638, acc: 80.5%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 20000, loss: 0.68737, acc: 82.8%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 20500, loss: 0.61094, acc: 83.6%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 21000, loss: 0.60611, acc: 82.0%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 21500, loss: 0.64072, acc: 80.5%.\n",
      "Validation accuracy: 80.2%.\n",
      "Minibatch step: 22000, loss: 0.71005, acc: 79.7%.\n",
      "Validation accuracy: 80.9%.\n",
      "Minibatch step: 22500, loss: 0.55551, acc: 83.6%.\n",
      "Validation accuracy: 80.9%.\n",
      "Minibatch step: 23000, loss: 0.55834, acc: 84.4%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 23500, loss: 0.48290, acc: 84.4%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 24000, loss: 0.60796, acc: 82.8%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 24500, loss: 0.79618, acc: 76.6%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 25000, loss: 0.60617, acc: 83.6%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 25500, loss: 0.63020, acc: 87.5%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 26000, loss: 0.56269, acc: 83.6%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 26500, loss: 0.64125, acc: 85.2%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 27000, loss: 0.65255, acc: 84.4%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 27500, loss: 0.59360, acc: 80.5%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 28000, loss: 0.62572, acc: 81.2%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 28500, loss: 0.54542, acc: 86.7%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 29000, loss: 0.62112, acc: 84.4%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 29500, loss: 0.62389, acc: 82.8%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 30000, loss: 0.71607, acc: 84.4%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 30500, loss: 0.50490, acc: 85.2%.\n",
      "Validation accuracy: 80.8%.\n",
      "Minibatch step: 31000, loss: 0.64399, acc: 80.5%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 31500, loss: 0.62700, acc: 81.2%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 32000, loss: 0.60040, acc: 82.0%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 32500, loss: 0.55721, acc: 86.7%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 33000, loss: 0.98847, acc: 75.0%.\n",
      "Validation accuracy: 80.8%.\n",
      "Minibatch step: 33500, loss: 0.59461, acc: 79.7%.\n",
      "Validation accuracy: 80.9%.\n",
      "Minibatch step: 34000, loss: 0.45496, acc: 86.7%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 34500, loss: 0.59176, acc: 85.2%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 35000, loss: 0.62958, acc: 87.5%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 35500, loss: 0.82227, acc: 78.1%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 36000, loss: 0.55093, acc: 85.2%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 36500, loss: 0.64696, acc: 79.7%.\n",
      "Validation accuracy: 80.8%.\n",
      "Minibatch step: 37000, loss: 0.48761, acc: 85.9%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 37500, loss: 0.59477, acc: 85.9%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 38000, loss: 0.62322, acc: 85.2%.\n",
      "Validation accuracy: 82.0%.\n",
      "Minibatch step: 38500, loss: 0.44064, acc: 85.9%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 39000, loss: 0.48501, acc: 85.9%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 39500, loss: 0.69645, acc: 81.2%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 40000, loss: 0.66605, acc: 82.8%.\n",
      "Validation accuracy: 80.9%.\n",
      "Minibatch step: 40500, loss: 0.58815, acc: 82.0%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 41000, loss: 0.59761, acc: 83.6%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 41500, loss: 0.72025, acc: 76.6%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 42000, loss: 0.62397, acc: 84.4%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 42500, loss: 0.76456, acc: 78.1%.\n",
      "Validation accuracy: 80.5%.\n",
      "Minibatch step: 43000, loss: 0.68721, acc: 82.8%.\n",
      "Validation accuracy: 82.1%.\n",
      "Minibatch step: 43500, loss: 0.61749, acc: 82.8%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 44000, loss: 0.69815, acc: 84.4%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 44500, loss: 0.65599, acc: 80.5%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 45000, loss: 0.90784, acc: 72.7%.\n",
      "Validation accuracy: 80.6%.\n",
      "Minibatch step: 45500, loss: 0.80108, acc: 79.7%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 46000, loss: 0.56411, acc: 84.4%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 46500, loss: 0.55638, acc: 80.5%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 47000, loss: 0.63409, acc: 82.0%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 47500, loss: 0.59515, acc: 82.0%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 48000, loss: 0.56482, acc: 86.7%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 48500, loss: 0.50203, acc: 85.9%.\n",
      "Validation accuracy: 81.9%.\n",
      "Minibatch step: 49000, loss: 0.49846, acc: 85.2%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 49500, loss: 0.66356, acc: 82.0%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 50000, loss: 0.49030, acc: 87.5%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 50500, loss: 0.66787, acc: 81.2%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 51000, loss: 0.65291, acc: 82.0%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 51500, loss: 0.46374, acc: 86.7%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 52000, loss: 0.85241, acc: 78.1%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 52500, loss: 0.75410, acc: 81.2%.\n",
      "Validation accuracy: 81.4%.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch step: 53000, loss: 0.48402, acc: 87.5%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 53500, loss: 0.77000, acc: 80.5%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 54000, loss: 0.55395, acc: 83.6%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 54500, loss: 0.50613, acc: 86.7%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 55000, loss: 0.66210, acc: 80.5%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 55500, loss: 0.59907, acc: 84.4%.\n",
      "Validation accuracy: 82.0%.\n",
      "Minibatch step: 56000, loss: 0.65402, acc: 82.8%.\n",
      "Validation accuracy: 80.8%.\n",
      "Minibatch step: 56500, loss: 0.63148, acc: 78.1%.\n",
      "Validation accuracy: 79.9%.\n",
      "Minibatch step: 57000, loss: 0.70840, acc: 80.5%.\n",
      "Validation accuracy: 82.0%.\n",
      "Minibatch step: 57500, loss: 0.73944, acc: 82.0%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 58000, loss: 0.72005, acc: 80.5%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 58500, loss: 0.49274, acc: 83.6%.\n",
      "Validation accuracy: 80.9%.\n",
      "Minibatch step: 59000, loss: 0.42546, acc: 87.5%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 59500, loss: 0.51663, acc: 86.7%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 60000, loss: 0.63336, acc: 83.6%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 60500, loss: 0.49573, acc: 84.4%.\n",
      "Validation accuracy: 82.0%.\n",
      "Minibatch step: 61000, loss: 0.70259, acc: 83.6%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 61500, loss: 0.66761, acc: 83.6%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 62000, loss: 0.63229, acc: 85.9%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 62500, loss: 0.70715, acc: 79.7%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 63000, loss: 0.88590, acc: 77.3%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 63500, loss: 0.72576, acc: 83.6%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 64000, loss: 0.71116, acc: 82.8%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 64500, loss: 0.79847, acc: 77.3%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 65000, loss: 0.69095, acc: 80.5%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 65500, loss: 0.51878, acc: 82.0%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 66000, loss: 0.74251, acc: 79.7%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 66500, loss: 0.77518, acc: 79.7%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 67000, loss: 0.48911, acc: 86.7%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 67500, loss: 0.71679, acc: 79.7%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 68000, loss: 0.73462, acc: 78.1%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 68500, loss: 0.49578, acc: 86.7%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 69000, loss: 0.51492, acc: 84.4%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 69500, loss: 0.80624, acc: 78.1%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 70000, loss: 0.67824, acc: 85.2%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 70500, loss: 0.55111, acc: 84.4%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 71000, loss: 0.64896, acc: 82.8%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 71500, loss: 0.55746, acc: 82.8%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 72000, loss: 0.76127, acc: 82.8%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 72500, loss: 0.63999, acc: 85.2%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 73000, loss: 0.55842, acc: 85.9%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 73500, loss: 0.55937, acc: 86.7%.\n",
      "Validation accuracy: 80.9%.\n",
      "Minibatch step: 74000, loss: 0.67528, acc: 81.2%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 74500, loss: 0.69999, acc: 81.2%.\n",
      "Validation accuracy: 82.0%.\n",
      "Minibatch step: 75000, loss: 0.63317, acc: 82.8%.\n",
      "Validation accuracy: 80.6%.\n",
      "Minibatch step: 75500, loss: 0.71222, acc: 80.5%.\n",
      "Validation accuracy: 81.9%.\n",
      "Minibatch step: 76000, loss: 0.53009, acc: 86.7%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 76500, loss: 0.71793, acc: 82.0%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 77000, loss: 0.50843, acc: 86.7%.\n",
      "Validation accuracy: 81.9%.\n",
      "Minibatch step: 77500, loss: 0.55876, acc: 82.0%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 78000, loss: 0.68726, acc: 85.9%.\n",
      "Validation accuracy: 81.1%.\n",
      "Minibatch step: 78500, loss: 0.92107, acc: 75.8%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 79000, loss: 0.41780, acc: 87.5%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 79500, loss: 0.59201, acc: 83.6%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 80000, loss: 0.52938, acc: 87.5%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 80500, loss: 0.92020, acc: 80.5%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 81000, loss: 0.73408, acc: 78.1%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 81500, loss: 0.57969, acc: 84.4%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 82000, loss: 0.81118, acc: 81.2%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 82500, loss: 0.42129, acc: 89.1%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 83000, loss: 0.52304, acc: 85.2%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 83500, loss: 0.79169, acc: 79.7%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 84000, loss: 0.75566, acc: 75.0%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 84500, loss: 0.71591, acc: 74.2%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 85000, loss: 0.98195, acc: 79.7%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 85500, loss: 0.59608, acc: 84.4%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 86000, loss: 0.56142, acc: 83.6%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 86500, loss: 0.68288, acc: 83.6%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 87000, loss: 0.81871, acc: 84.4%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 87500, loss: 0.50896, acc: 89.1%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 88000, loss: 0.60144, acc: 85.2%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 88500, loss: 0.65818, acc: 83.6%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 89000, loss: 0.79136, acc: 74.2%.\n",
      "Validation accuracy: 80.3%.\n",
      "Minibatch step: 89500, loss: 0.51359, acc: 81.2%.\n",
      "Validation accuracy: 80.7%.\n",
      "Minibatch step: 90000, loss: 0.81571, acc: 81.2%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 90500, loss: 0.84882, acc: 79.7%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 91000, loss: 0.49548, acc: 85.9%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 91500, loss: 0.61850, acc: 85.9%.\n",
      "Validation accuracy: 81.5%.\n",
      "Minibatch step: 92000, loss: 0.53929, acc: 83.6%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 92500, loss: 0.75226, acc: 79.7%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 93000, loss: 0.72948, acc: 81.2%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 93500, loss: 0.63216, acc: 82.8%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 94000, loss: 0.60776, acc: 85.2%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 94500, loss: 0.79526, acc: 76.6%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 95000, loss: 0.71449, acc: 75.0%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 95500, loss: 0.68354, acc: 85.9%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 96000, loss: 0.57360, acc: 85.2%.\n",
      "Validation accuracy: 80.6%.\n",
      "Minibatch step: 96500, loss: 0.63029, acc: 81.2%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 97000, loss: 0.70685, acc: 81.2%.\n",
      "Validation accuracy: 81.0%.\n",
      "Minibatch step: 97500, loss: 0.75644, acc: 84.4%.\n",
      "Validation accuracy: 81.8%.\n",
      "Minibatch step: 98000, loss: 0.42835, acc: 92.2%.\n",
      "Validation accuracy: 81.4%.\n",
      "Minibatch step: 98500, loss: 0.55279, acc: 85.2%.\n",
      "Validation accuracy: 81.3%.\n",
      "Minibatch step: 99000, loss: 0.60416, acc: 82.8%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 99500, loss: 0.68368, acc: 80.5%.\n",
      "Validation accuracy: 81.6%.\n",
      "Minibatch step: 100000, loss: 0.39166, acc: 89.1%.\n",
      "Validation accuracy: 81.3%.\n",
      "Test accuracy: 87.9%.\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('[Tensorflow]: Initialized!')\n",
    "    for step in range(steps):\n",
    "        # For shuffle data.\n",
    "        offset = (step * batch_size) % (train_dataset.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {\n",
    "            tf_train_dataset: batch_data, tf_train_labels: batch_labels\n",
    "        }\n",
    "        \n",
    "        _, loss, predictions = session.run(\n",
    "                                [opt, _loss, train_prediction],\n",
    "                                feed_dict=feed_dict\n",
    "                               )\n",
    "        if ((step+1) % 500 == 0):\n",
    "            # %4.5f : 输出结果占4个占位符，保留5位小数.\n",
    "            print('Minibatch step: %d, loss: %4.5f, acc: %.1f%%.'\n",
    "                  % (step+1, loss, accuracy(predictions, batch_labels)))\n",
    "            print('Validation accuracy: %.1f%%.' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    \n",
    "    print('Test accuracy: %.1f%%.' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    # Input data\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                      shape=(batch_size, image_size*image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32,\n",
    "                                     shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Variables.\n",
    "    # These are the parameters that we are going to be training.\n",
    "    weights_1 = tf.get_variable('weights_1',\n",
    "                              shape= [tf_train_dataset.get_shape()[-1], \n",
    "                                      num_hidden_nodes],\n",
    "                              initializer=tf.initializers.truncated_normal(0., 1.))\n",
    "    biases_1 = tf.get_variable('biases_1',\n",
    "                             shape= [num_hidden_nodes],\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    weights_2 = tf.get_variable('weights_2',\n",
    "                              shape= [num_hidden_nodes, tf_train_labels.shape[-1]],\n",
    "                              initializer=tf.initializers.truncated_normal(0., 1.))\n",
    "    biases_2 = tf.get_variable('biases_2',\n",
    "                             shape= [tf_train_labels.shape[-1]],\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "    \n",
    "    # Training compution.\n",
    "    _logits = tf.matmul(lay1_train, weights_2) + biases_2\n",
    "    _loss = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                        labels=tf_train_labels, logits=_logits))\n",
    "    \n",
    "    # Optimizer\n",
    "    opt = tf.train.GradientDescentOptimizer(0.5).minimize(_loss)\n",
    "    \n",
    "    # Prediction for training, validation, and the test data.\n",
    "    train_prediction = tf.nn.softmax(_logits)\n",
    "    valid_lay1 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "    valid_logits = tf.matmul(valid_lay1, weights_2) + biases_2\n",
    "    valid_prediction = tf.nn.softmax(valid_logits)\n",
    "    test_lay1 = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "    test_logits = tf.matmul(test_lay1, weights_2) + biases_2\n",
    "    test_prediction = tf.nn.softmax(test_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tensorflow]: Initialized!\n",
      "Minibatch step: 500, loss: 15.00341, acc: 82.8%.\n",
      "Validation accuracy: 78.7%.\n",
      "Minibatch step: 1000, loss: 11.16014, acc: 80.5%.\n",
      "Validation accuracy: 76.5%.\n",
      "Minibatch step: 1500, loss: 6.39131, acc: 78.9%.\n",
      "Validation accuracy: 80.6%.\n",
      "Minibatch step: 2000, loss: 4.29619, acc: 82.0%.\n",
      "Validation accuracy: 81.2%.\n",
      "Minibatch step: 2500, loss: 6.44977, acc: 80.5%.\n",
      "Validation accuracy: 80.2%.\n",
      "Minibatch step: 3000, loss: 4.09252, acc: 82.8%.\n",
      "Validation accuracy: 81.7%.\n",
      "Minibatch step: 3500, loss: 4.67767, acc: 82.0%.\n",
      "Validation accuracy: 82.0%.\n",
      "Minibatch step: 4000, loss: 1.70067, acc: 84.4%.\n",
      "Validation accuracy: 82.2%.\n",
      "Minibatch step: 4500, loss: 1.97848, acc: 87.5%.\n",
      "Validation accuracy: 82.8%.\n",
      "Minibatch step: 5000, loss: 2.08788, acc: 82.0%.\n",
      "Validation accuracy: 82.2%.\n",
      "Minibatch step: 5500, loss: 1.80888, acc: 85.2%.\n",
      "Validation accuracy: 82.2%.\n",
      "Minibatch step: 6000, loss: 2.78531, acc: 82.8%.\n",
      "Validation accuracy: 82.1%.\n",
      "Minibatch step: 6500, loss: 1.63075, acc: 84.4%.\n",
      "Validation accuracy: 82.8%.\n",
      "Minibatch step: 7000, loss: 1.49274, acc: 85.9%.\n",
      "Validation accuracy: 82.7%.\n",
      "Minibatch step: 7500, loss: 1.53837, acc: 83.6%.\n",
      "Validation accuracy: 83.0%.\n",
      "Minibatch step: 8000, loss: 0.56425, acc: 91.4%.\n",
      "Validation accuracy: 83.8%.\n",
      "Minibatch step: 8500, loss: 1.52074, acc: 85.2%.\n",
      "Validation accuracy: 83.5%.\n",
      "Minibatch step: 9000, loss: 0.86341, acc: 89.1%.\n",
      "Validation accuracy: 83.3%.\n",
      "Minibatch step: 9500, loss: 1.06262, acc: 87.5%.\n",
      "Validation accuracy: 83.3%.\n",
      "Minibatch step: 10000, loss: 1.80147, acc: 83.6%.\n",
      "Validation accuracy: 83.6%.\n",
      "Test accuracy: 90.0%.\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('[Tensorflow]: Initialized!')\n",
    "    for step in range(steps):\n",
    "        # For shuffle data.\n",
    "        offset = (step * batch_size) % (train_dataset.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        feed_dict = {\n",
    "            tf_train_dataset: batch_data, tf_train_labels: batch_labels\n",
    "        }\n",
    "        \n",
    "        _, loss, predictions = session.run(\n",
    "                                [opt, _loss, train_prediction],\n",
    "                                feed_dict=feed_dict\n",
    "                               )\n",
    "        if ((step+1) % 500 == 0):\n",
    "            # %4.5f : 输出结果占4个占位符，保留5位小数.\n",
    "            print('Minibatch step: %d, loss: %4.5f, acc: %.1f%%.'\n",
    "                  % (step+1, loss, accuracy(predictions, batch_labels)))\n",
    "            print('Validation accuracy: %.1f%%.' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    \n",
    "    print('Test accuracy: %.1f%%.' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Mon Nov 25 13:50:46 2019\\n\\n@author: chenzhm\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 25 13:50:46 2019\n",
    "\n",
    "@author: chenzhm\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-62d8fcc3d001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numba'"
     ]
    }
   ],
   "source": [
    "import yaml, time, gc, numba\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import rospy\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from sensor_msgs.msg import PointCloud2, PointField, Image\n",
    "import message_filters\n",
    "\n",
    "from pyquaternion import Quaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f2c4d43e177b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mFrame2PointCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     def __init__(_intrinsic, camera_ids, \n\u001b[1;32m      4\u001b[0m                  camera_poses, width=512, height=424):\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f2c4d43e177b>\u001b[0m in \u001b[0;36mFrame2PointCloud\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_intrinsic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcamera_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muvzrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnumpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muvzrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numba' is not defined"
     ]
    }
   ],
   "source": [
    "class Frame2PointCloud():\n",
    "    \n",
    "    def __init__(_intrinsic, camera_ids, \n",
    "                 camera_poses, width=512, height=424):\n",
    "        self.camera_ids = camera_ids\n",
    "        self.camera_poses = camera_poses\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "        # width, height\n",
    "        self.batch_size = len(self.camera_ids)\n",
    "        self.cx_list=[]\n",
    "        self.cy_list=[]\n",
    "        self.fx_list=[]\n",
    "        self.fy_list=[]\n",
    "        for camera_id in camera_ids:\n",
    "            self.cx_list.append(_intrinsic[camera_id][2])\n",
    "            self.cy_list.append(_intrinsic[camera_id][5])\n",
    "            self.fx_list.append(_intrinsic[camera_id][0])\n",
    "            self.fy_list.append(_intrinsic[camera_id][4])\n",
    "            \n",
    "    @numba.jit\n",
    "    def project(color, depth, uvzrgb):\n",
    "        numpoints = len(uvzrgb)\n",
    "        for i in range(numpoints):\n",
    "            u,v,z,r,g,b = uvzrgb[i]\n",
    "            if depth[v, u] < z:\n",
    "                color[v, u] = (r, g, b)\n",
    "                depth[v, u] = z\n",
    "    def get_transform_matrix(self, camera_id):\n",
    "        pose = self.camera_poses['poses'][camera_id]\n",
    "        extr_q = Quaternion(pose['rotation']['w'], \n",
    "                            pose['rotation']['x'], \n",
    "                            pose['rotation']['y'], \n",
    "                            pose['rotation']['z'])\n",
    "        extr_q = extr_q.rotation_matrix\n",
    "        extr_t = np.array([pose['translation']['x'], \n",
    "                           pose['translation']['y'],\n",
    "                           pose['translation']['z']])\n",
    "        extr_t = np.reshape(extr_t, (3,1))\n",
    "        transform_matrix = np.concatenate([extr_q, extr_t], \n",
    "                                          axis=1)\n",
    "        transform_matrix = np.concatenate([transform_matrix,\n",
    "                                           [[0,0,0,1]]],\n",
    "                                          axis=0)\n",
    "        return np.float32(transform_matrix)\n",
    "    \n",
    "    def build_registration_graph(self, width, height, \n",
    "                                 batch_size, \n",
    "                                 cx, cy, fx, fy):\n",
    "        \"\"\"\n",
    "        建立点云注册、融合计算图，将多相机rgb和depth图像转化并统一为世界坐标下的点云\n",
    "         深度图像注册点云公式：\n",
    "                        z = d/1000\n",
    "                        x = (u-cx)*z/fx\n",
    "                        y = (v-cy)*z/fy\n",
    "            d = depth[v,u]\n",
    "            u:像素横坐标，u in（0，width-1）\n",
    "            v：像素纵坐标，v in（0，height-1）\n",
    "            cx，cy：像素中心，相机内参，约为width/2, height/2\n",
    "            fx，fy：焦距，相机内参\n",
    "            x,y,z:点云在相机坐标系下的坐标\n",
    "\n",
    "        args:\n",
    "            width: number. 512\n",
    "            height: number. 424\n",
    "            batch_size: number. 生成点云使用的相机数量，即图像对(color,depth)数量\n",
    "            cx, cy, fx, fy: list for camera intrinsic. length = batch_size。 各相机内参列表\n",
    "        returns:\n",
    "            color：rgb图像tensor，[batch_size, height, width, 3]\n",
    "            depth：depth图像tensor, [batch_size, height, width, 1]\n",
    "            xyzrgb：世界坐标系下的多相机融合点云tensor, [-1, 6]\n",
    "\n",
    "        \"\"\"\n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            color = tf.placeholder(tf.float32, \n",
    "                                   [batch_size, height, width, 3],\n",
    "                                   name='color_tensor')\n",
    "            depth = tf.placeholder(tf.float32, \n",
    "                                   [batch_size, height, width, 1],\n",
    "                                   name='depth_tensor')\n",
    "            u, v = tf.meshgrid(tf.range(width), tf.range(height))\n",
    "            u, v = tf.to_float(u), tf.to_float(v)\n",
    "            u = tf.reshape(u, [1, height, width, 1])\n",
    "            u = tf.tile(u, [batch_size, 1, 1, 1])   #[batch_size, height, width, 1]\n",
    "            v = tf.reshape(v, [1, height, width, 1])\n",
    "            v = tf.tile(v, [batch_size, 1, 1, 1])   #[batch_size, height, width, 1]\n",
    "            cx = tf.constant(cx, tf.float32, [batch_size, 1, 1, 1])\n",
    "            cy = tf.constant(cy, tf.float32, [batch_size, 1, 1, 1])\n",
    "            fx = tf.constant(fx, tf.float32, [batch_size, 1, 1, 1])\n",
    "            fy = tf.constant(fy, tf.float32, [batch_size, 1, 1, 1])\n",
    "\n",
    "            #注册点云\n",
    "            z = depth/1000.\n",
    "            z_fault = tf.ones_like(z)*999\n",
    "            z = tf.where(tf.equal(z, 0.), z_fault, z)\n",
    "            z = tf.where(tf.equal(tf.reduce_sum(color, axis=3, \n",
    "                                                keep_dims=True), 0.), z_fault, z)\n",
    "            x = (u-cx)*z/fx\n",
    "            y = (v-cy)*z/fy\n",
    "            w = tf.ones_like(x, tf.float32)\n",
    "            color1 = color/255.\n",
    "            xyzwrgb = tf.concat([x,y,z,w,color1], axis=-1)#[batch_size, height, width, 7]\n",
    "            xyzwrgb = tf.reshape(xyzwrgb, (batch_size,-1,7))\n",
    "\n",
    "            #转换点云至世界坐标系，transform_matrix为坐标转换矩阵\n",
    "            xyzw_list=[]\n",
    "            for i in range(batch_size):\n",
    "                transform_matrix = self.get_transform_matrix(self.camera_ids[i])\n",
    "                transform_matrix = tf.constant(transform_matrix, tf.float32)\n",
    "                xyzw0 = tf.transpose(xyzwrgb[i,:,:4], (1,0))#[4, width*height]\n",
    "                xyzw0 = tf.matmul(transform_matrix, xyzw0)\n",
    "                xyzw0 = tf.transpose(xyzw0, (1,0))\n",
    "                xyzw_list.append(xyzw0)\n",
    "            xyzw = tf.stack(xyzw_list, axis=0) #[batch_siz, width*height, 4]\n",
    "            xyzrgb = tf.concat([xyzw[...,:3], xyzwrgb[...,-3:]], axis=-1)\n",
    "            xyzrgb = tf.reshape(xyzrgb, (-1, 6))\n",
    "\n",
    "            #剔除区域外部分点云\n",
    "            condx0 = tf.greater(xyzrgb[:,0], image_xmin)\n",
    "            condx1 = tf.less(xyzrgb[:,0], image_xmax)\n",
    "            condy0 = tf.greater(xyzrgb[:,1], image_ymin)\n",
    "            condy1 = tf.less(xyzrgb[:,1], image_ymax)\n",
    "            condz0 = tf.greater(xyzrgb[:,2], image_zmin)\n",
    "            condz1 = tf.less(xyzrgb[:,2], image_zmax)\n",
    "\n",
    "            cond = tf.stack([condx0,condx1,condy0,condy1,condz0,condz1], axis=1)\n",
    "            cond = tf.reduce_all(cond, axis=1)\n",
    "            indices = tf.where(cond)\n",
    "            xyzrgb = tf.gather(xyzrgb, indices, axis=0)\n",
    "            xyzrgb = tf.squeeze(xyzrgb)#[numpoints, 6]\n",
    "\n",
    "            #顶部视角预处理数据\n",
    "            indu = tf.to_int32((xyzrgb[:,0:1] - image_xmin)*100)\n",
    "            indv = tf.to_int32((xyzrgb[:,1:2] - image_ymin)*100)\n",
    "            intz = tf.to_int32(xyzrgb[:,2:3]*1000)\n",
    "            intrgb = tf.to_int32(xyzrgb[:,-3:]*255)\n",
    "            uvzrgb = tf.concat([indu,indv,intz,intrgb],axis=1)\n",
    "            xyzrgb = tf.identity(xyzrgb, name='xyzrgb')\n",
    "            uvzrgb = tf.identity(uvzrgb, name='uvzrgb')\n",
    "        \n",
    "    def point2msg(pointArray):\n",
    "        fields = [PointField('x', 0, PointField.FLOAT32, 1),\n",
    "                  PointField('y', 4, PointField.FLOAT32, 1),\n",
    "                  PointField('z', 8, PointField.FLOAT32, 1),\n",
    "                  PointField('b', 12, PointField.FLOAT32, 1),\n",
    "                  PointField('g', 16, PointField.FLOAT32, 1),\n",
    "                  PointField('r', 20, PointField.FLOAT32, 1),\n",
    "                  ]\n",
    "        objPoints = PointCloud2()\n",
    "        objPoints.fields = fields\n",
    "        objPoints.header.frame_id = 'world'\n",
    "        objPoints.data = pointArray.tostring()\n",
    "        objPoints.point_step = 24\n",
    "        objPoints.width = 1\n",
    "        objPoints.row_step = 24\n",
    "        objPoints.height = pointArray.shape[0]\n",
    "        objPoints.is_dense = False\n",
    "        return objPoints\n",
    "    \n",
    "    def make_point_msg():\n",
    "        fields = [PointField('x', 0, PointField.FLOAT32, 1),\n",
    "                  PointField('y', 4, PointField.FLOAT32, 1),\n",
    "                  PointField('z', 8, PointField.FLOAT32, 1),\n",
    "                  PointField('b', 12, PointField.FLOAT32, 1),\n",
    "                  PointField('g', 16, PointField.FLOAT32, 1),\n",
    "                  PointField('r', 20, PointField.FLOAT32, 1),\n",
    "                  ]\n",
    "        objPoints = PointCloud2()\n",
    "        objPoints.fields = fields\n",
    "        objPoints.header.frame_id = 'world'\n",
    "        objPoints.point_step = 24\n",
    "        objPoints.width = 1\n",
    "        objPoints.row_step = 24\n",
    "        objPoints.is_dense = False\n",
    "        return objPoints\n",
    "    \n",
    "    def callback(self, *msgs):\n",
    "        t0 = time.time()\n",
    "        color_list = []\n",
    "        depth_list = []\n",
    "        stamp_list = []\n",
    "        for msg in msgs:\n",
    "            _stamp = float('%d.%d' % (msg.header.stamp.secs,\n",
    "                                      msg.header.stamp.nsecs))\n",
    "            stamp_list.append(_stamp)\n",
    "            frame = self._cv_bridge.imgmsg_to_cv2(msg, \n",
    "                                    desired_encoding=color_msg.encoding)\n",
    "            l = len(frame.shape)\n",
    "            if l == 2: # depth-->[h,w]\n",
    "                color_list.append(frame)\n",
    "            if l == 3: # rgb-->[h,w,3]\n",
    "                depth_list.append(frame)\n",
    "        stamp = str(np.mean(stamp_list)).split('.')\n",
    "        \n",
    "        color = np.stack(color_list, axis=0).reshape(self.batch_size, \n",
    "                                                     self.height,\n",
    "                                                     self.width, 3)\n",
    "        depth = np.stack(depth_list, axis=0).reshape(self.batch_size, \n",
    "                                                     self.height,\n",
    "                                                     self.width, 3)\n",
    "        t1 = time.time()\n",
    "        color_feed = np.float32(color)\n",
    "        depth_feed = np.float32(depth)\n",
    "        feed_dict = {self.color_tensor: color_feed, \n",
    "                     self.depth_tensor: depth_feed}\n",
    "        xyzrgb, uvzrgb = self.sess.run([xyzrgb_tensor,uvzrgb_tensor], \n",
    "                                  feed_dict=feed_dict)\n",
    "        t2 = time.time()\n",
    "        project_color0 = np.ones([300,450,3], np.uint8)*255\n",
    "        project_depth0 = np.ones([300,450], np.uint16)*80\n",
    "        self.project(project_color0, project_depth0, uvzrgb)\n",
    "        msg_proj_color = self._cv_bridge.cv2_to_imgmsg(cvim=project_color0,\n",
    "                                                       encoding='8UC3')\n",
    "        msg_proj_depth = self._cv_bridge.cv2_to_imgmsg(cvim=project_depth0,\n",
    "                                                       encoding='16UC1')\n",
    "        msg_proj_color.header.stamp.secs = int(stamp[0])\n",
    "        msg_proj_color.header.stamp.nsecs = int(stamp[1])\n",
    "        msg_proj_depth.header.stamp.secs = int(stamp[0])\n",
    "        msg_proj_depth.header.stamp.nsecs = int(stamp[1])\n",
    "        self.proj_color_pub.publish(msg_proj_color)\n",
    "        self.proj_depth_pub.publish(msg_proj_depth)\n",
    "        t3 = time.time()\n",
    "        \n",
    "        # Point Cloud msg\n",
    "        point_msg = self.make_point_msg()\n",
    "        point_msg.header.stamp.secs = int(stamp[0])\n",
    "        point_msg.header.stamp.nsecs = int(stamp[1])\n",
    "        point_msg.height = xyzrgb.shape[0]\n",
    "        point_msg.data = xyzrgb.tostring()\n",
    "        self.points_pub.publish(point_msg)\n",
    "        t4 = time.time()\n",
    "        \n",
    "    def run(self):\n",
    "    \n",
    "        config = tf.ConfigProto(allow_soft_placement=True, \n",
    "                                inter_op_parallelism_threads=0, \n",
    "                                intra_op_parallelism_threads=0)\n",
    "        config.gpu_options.per_process_gpu_memory_fraction=0.5\n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.build_registration_graph(self.width, \n",
    "                                      self.height, \n",
    "                                      self.batch_size,\n",
    "                                      self.cx_list, \n",
    "                                      self.cy_list,\n",
    "                                      self.fx_list, \n",
    "                                      self.fy_list)\n",
    "        self.color_tensor = self.graph.get_tensor_by_name('color_tensor:0')\n",
    "        self.depth_tensor = self.graph.get_tensor_by_name('depth_tensor:0')\n",
    "        self.xyzrgb_tensor = self.graph.get_tensor_by_name('xyzrgb:0')\n",
    "        self.uvzrgb_tensor = self.graph.get_tensor_by_name('uvzrgb:0')\n",
    "        \n",
    "        rospy.init_node('x', anonymous=True)\n",
    "        self.points_pub = rospy.Publisher('/world/merge_pointcloud',\n",
    "                                          PointCloud2, \n",
    "                                          queue_size=1)\n",
    "        self.proj_color_pub = rospy.Publisher('/world/proj_color', \n",
    "                                              Image, \n",
    "                                              queue_size=5)\n",
    "        self.proj_depth_pub = rospy.Publisher('/world/proj_depth', \n",
    "                                              Image, \n",
    "                                              queue_size=5)\n",
    "        \n",
    "        self._cv_bridge = CvBridge()\n",
    "        sub_list = []\n",
    "        for camera_id in self.camera_ids:\n",
    "            color_sub = message_filters.Subscriber('/%s/sd/image_color_rect'\n",
    "                                                   % camera_id, Image)\n",
    "            depth_sub = message_filters.Subscriber('/%s/sd/image_depth_rect'\n",
    "                                                   % camera_id, Image)\n",
    "            sub_list.append(color_sub)\n",
    "            sub_list.append(depth_sub)\n",
    "            \n",
    "        ts = message_filters.ApproximateTimeSynchronizer(sub_list, \n",
    "                                                         15,\n",
    "                                                         0.05)\n",
    "        tf.regiterCallback(self.callback)\n",
    "        rospy.loginfo('[Info]: <<<<<<<<<<--Node start-->>>>>>>>>>')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    _intrinsic = yaml.load(open('../cfg/camera_intrinsic.yaml'))\n",
    "    _camera_pose = yaml.load(open('../cfg/camera_poses.yaml'))\n",
    "    camera_id_list=['k01', 'k10','k03','k04']\n",
    "    \n",
    "    frame2point = Frame2PointCloud(_intrinsic=_intrinsic,\n",
    "                                   camera_ids=camera_id_list,\n",
    "                                   camera_poses=_camera_pose,\n",
    "                                   width=512, \n",
    "                                   height=424)\n",
    "    frame2point.run()\n",
    "    try:\n",
    "        rospy.spin()\n",
    "    except Exception as e:\n",
    "        frame2point.sess.close()\n",
    "        rospy.logerr('[Error]: Frame2PointCloud Exceptions--> %s' % e)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

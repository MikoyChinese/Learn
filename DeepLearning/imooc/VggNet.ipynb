{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_DIR = '/home/commaai-03/Data/dataset/cifar-10-python'\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.join(CIFAR_DIR, file) \n",
    "             for file in os.listdir(CIFAR_DIR)\n",
    "             if '.html' not in file]\n",
    "filenames.sort()\n",
    "meta_file = filenames[0]\n",
    "train_files = filenames[1:-1]\n",
    "test_file = [filenames[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'batch_label'\n",
      "b'labels'\n",
      "b'data'\n",
      "b'filenames'\n"
     ]
    }
   ],
   "source": [
    "_test_data = unpickle(test_file[0])\n",
    "for k, v in _test_data.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe21761c470>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_arr = _test_data[b'data'][0]\n",
    "# 32 * 32 * 3 (R,G,B)\n",
    "img_arr_reshaped = img_arr.reshape((3, 32, 32))\n",
    "img = img_arr_reshaped.transpose(1, 2, 0)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarData:\n",
    "    \n",
    "    def __init__(self, filenames, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        for filename in filenames:\n",
    "            data, labels = self.load_data(filename)\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._data = self._data / 127.5 - 1\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        print('[CIFAR-10]: Data shape-> %s' % str(self._data.shape))\n",
    "        print('[CIFAR-10]: Label shape-> %s' % str(self._labels.shape))\n",
    "        \n",
    "        self.num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "            \n",
    "    def load_data(self, filename):\n",
    "        import pickle\n",
    "        with open(filename, mode='rb') as f:\n",
    "            data = pickle.load(f, encoding='bytes')\n",
    "        return data[b'data'], data[b'labels']\n",
    "    \n",
    "    def _shuffle_data(self):\n",
    "        index = np.random.permutation(self.num_examples)\n",
    "        self._data = self._data[index]\n",
    "        self._labels = self._labels[index]\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self.num_examples:\n",
    "            rest_num_examples = self.num_examples - self._indicator\n",
    "            data_rest_part = self._data[self._indicator: self.num_examples]\n",
    "            label_rest_part = self._labels[self._indicator: self.num_examples]\n",
    "            \n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "            # For new loop, self._indicator + batch_size = self.num_examples\n",
    "            self._indicator = batch_size - rest_num_examples\n",
    "            end_indicator = self._indicator\n",
    "            data_new_part = self._data[:end_indicator]\n",
    "            label_new_part = self._labels[:end_indicator]\n",
    "            batch_data = np.concatenate((data_rest_part, data_new_part), axis=0)\n",
    "            batch_label = np.concatenate((label_rest_part, label_new_part), axis=0)\n",
    "        else:\n",
    "            batch_data = self._data[self._indicator:end_indicator]\n",
    "            batch_label = self._labels[self._indicator:end_indicator]\n",
    "            self._indicator = end_indicator\n",
    "        \n",
    "        return batch_data, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CIFAR-10]: Data shape-> (50000, 3072)\n",
      "[CIFAR-10]: Label shape-> (50000,)\n",
      "[CIFAR-10]: Data shape-> (10000, 3072)\n",
      "[CIFAR-10]: Label shape-> (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_data = CifarData(train_files, need_shuffle=True)\n",
    "test_data = CifarData(test_file, need_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0920 14:57:05.305756 140611373492032 deprecation.py:506] From /home/commaai-03/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0920 14:57:05.395446 140611373492032 deprecation.py:323] From /home/commaai-03/.local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 3072])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "x_img = tf.reshape(x, [-1, 3, 32, 32])\n",
    "x_img = tf.transpose(x_img, perm=[0, 2, 3, 1])\n",
    "\n",
    "class VggNet(tf.keras.Model):\n",
    "    \n",
    "    def __init__():\n",
    "        \n",
    "        # conv1\n",
    "        self.conv1_1 = tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=(1,1),\n",
    "                                 padding='same',\n",
    "                                 data_format='channels_last',\n",
    "                                 activation=tf.nn.relu)\n",
    "        self.conv1_2 = tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=(1,1),\n",
    "                                 padding='same',\n",
    "                                 data_format='channels_last',\n",
    "                                 activation=tf.nn.relu)\n",
    "        # Max Pooling\n",
    "        self.maxPooling1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), \n",
    "                                                     strides=(2, 2),\n",
    "                                                     data_format='channels_last')\n",
    "\n",
    "# conv1: feature_map\n",
    "conv1_1 = tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=(1,1),\n",
    "                                 padding='same',\n",
    "                                 data_format='channels_last',\n",
    "                                 activation=tf.nn.relu)(x_img)\n",
    "conv1_2 = tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=(1,1),\n",
    "                                 padding='same',\n",
    "                                 data_format='channels_last',\n",
    "                                 activation=tf.nn.relu)(conv1_1)\n",
    "\n",
    "# shape: [16, 16]\n",
    "pooling1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), \n",
    "                                     strides=(2, 2),\n",
    "                                     data_format='channels_last')(conv1_2)\n",
    "\n",
    "# conv2:\n",
    "conv2_1 = tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=(1,1),\n",
    "                                 padding='same',\n",
    "                                 data_format='channels_last',\n",
    "                                 activation=tf.nn.relu)(pooling1)\n",
    "conv2_2 = tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=(1,1),\n",
    "                                 padding='same',\n",
    "                                 data_format='channels_last',\n",
    "                                 activation=tf.nn.relu)(conv2_1)\n",
    "\n",
    "# pooling\n",
    "pooling2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), \n",
    "                                     strides=(2, 2),\n",
    "                                     data_format='channels_last')(conv2_2)\n",
    "\n",
    "# conv3:\n",
    "conv3_1 = tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=(1,1),\n",
    "                                 padding='same',\n",
    "                                 data_format='channels_last',\n",
    "                                 activation=tf.nn.relu)(pooling2)\n",
    "conv3_2 = tf.keras.layers.Conv2D(filters=32,\n",
    "                                 kernel_size=(3, 3), \n",
    "                                 strides=(1,1),\n",
    "                                 padding='same',\n",
    "                                 data_format='channels_last',\n",
    "                                 activation=tf.nn.relu)(conv3_1)\n",
    "\n",
    "# pooling\n",
    "pooling3 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), \n",
    "                                     strides=(2, 2),\n",
    "                                     data_format='channels_last')(conv3_2)\n",
    "\n",
    "# flatten\n",
    "flatten = tf.keras.layers.Flatten(data_format='channels_last')(pooling3)\n",
    "y_ = tf.keras.layers.Dense(units=10)(flatten)\n",
    "\n",
    "# loss: tf.losses.sparse_softmax_cross_entropy ->\n",
    "# tf.nn.reduce_mean(tf.nn.sparse_softma_cross_entropy_with_logits())\n",
    "_loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "\n",
    "# predict\n",
    "predict = tf.argmax(y_, 1)\n",
    "correct_prediction = tf.equal(predict, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: Step: 100, loss: 2.04581 acc: 0.30000\n",
      "[Train]: Step: 200, loss: 1.62394 acc: 0.40000\n",
      "[Train]: Step: 300, loss: 1.57597 acc: 0.45000\n",
      "[Train]: Step: 400, loss: 1.33614 acc: 0.50000\n",
      "[Train]: Step: 500, loss: 1.61541 acc: 0.50000\n",
      "[Train]: Step: 600, loss: 1.88727 acc: 0.25000\n",
      "[Train]: Step: 700, loss: 1.30549 acc: 0.50000\n",
      "[Train]: Step: 800, loss: 1.34295 acc: 0.45000\n",
      "[Train]: Step: 900, loss: 1.18364 acc: 0.50000\n",
      "[Train]: Step: 1000, loss: 1.20538 acc: 0.60000\n",
      "[Test] Step: 1000, acc: 0.50150\n",
      "[Train]: Step: 1100, loss: 1.49936 acc: 0.50000\n",
      "[Train]: Step: 1200, loss: 1.33192 acc: 0.60000\n",
      "[Train]: Step: 1300, loss: 1.40546 acc: 0.55000\n",
      "[Train]: Step: 1400, loss: 1.39623 acc: 0.50000\n",
      "[Train]: Step: 1500, loss: 1.60176 acc: 0.45000\n",
      "[Train]: Step: 1600, loss: 1.19743 acc: 0.60000\n",
      "[Train]: Step: 1700, loss: 1.23713 acc: 0.55000\n",
      "[Train]: Step: 1800, loss: 1.32455 acc: 0.55000\n",
      "[Train]: Step: 1900, loss: 1.48543 acc: 0.40000\n",
      "[Train]: Step: 2000, loss: 1.12587 acc: 0.75000\n",
      "[Test] Step: 2000, acc: 0.57790\n",
      "[Train]: Step: 2100, loss: 1.50024 acc: 0.45000\n",
      "[Train]: Step: 2200, loss: 1.40979 acc: 0.45000\n",
      "[Train]: Step: 2300, loss: 1.16904 acc: 0.55000\n",
      "[Train]: Step: 2400, loss: 0.74108 acc: 0.85000\n",
      "[Train]: Step: 2500, loss: 1.23186 acc: 0.65000\n",
      "[Train]: Step: 2600, loss: 0.73223 acc: 0.75000\n",
      "[Train]: Step: 2700, loss: 1.10404 acc: 0.50000\n",
      "[Train]: Step: 2800, loss: 0.62484 acc: 0.85000\n",
      "[Train]: Step: 2900, loss: 0.86495 acc: 0.65000\n",
      "[Train]: Step: 3000, loss: 1.05652 acc: 0.75000\n",
      "[Test] Step: 3000, acc: 0.62110\n",
      "[Train]: Step: 3100, loss: 1.07279 acc: 0.60000\n",
      "[Train]: Step: 3200, loss: 0.98312 acc: 0.65000\n",
      "[Train]: Step: 3300, loss: 0.95000 acc: 0.65000\n",
      "[Train]: Step: 3400, loss: 1.13063 acc: 0.55000\n",
      "[Train]: Step: 3500, loss: 0.95026 acc: 0.65000\n",
      "[Train]: Step: 3600, loss: 0.72252 acc: 0.75000\n",
      "[Train]: Step: 3700, loss: 1.23217 acc: 0.55000\n",
      "[Train]: Step: 3800, loss: 0.65657 acc: 0.85000\n",
      "[Train]: Step: 3900, loss: 0.72957 acc: 0.70000\n",
      "[Train]: Step: 4000, loss: 1.21829 acc: 0.55000\n",
      "[Test] Step: 4000, acc: 0.65870\n",
      "[Train]: Step: 4100, loss: 1.11617 acc: 0.55000\n",
      "[Train]: Step: 4200, loss: 0.88795 acc: 0.70000\n",
      "[Train]: Step: 4300, loss: 1.55438 acc: 0.50000\n",
      "[Train]: Step: 4400, loss: 0.75132 acc: 0.75000\n",
      "[Train]: Step: 4500, loss: 0.72165 acc: 0.75000\n",
      "[Train]: Step: 4600, loss: 0.94473 acc: 0.60000\n",
      "[Train]: Step: 4700, loss: 0.50413 acc: 0.85000\n",
      "[Train]: Step: 4800, loss: 1.12395 acc: 0.65000\n",
      "[Train]: Step: 4900, loss: 1.11262 acc: 0.70000\n",
      "[Train]: Step: 5000, loss: 0.90795 acc: 0.70000\n",
      "[Test] Step: 5000, acc: 0.68350\n",
      "[Train]: Step: 5100, loss: 0.61490 acc: 0.85000\n",
      "[Train]: Step: 5200, loss: 1.01153 acc: 0.60000\n",
      "[Train]: Step: 5300, loss: 1.12071 acc: 0.65000\n",
      "[Train]: Step: 5400, loss: 0.69173 acc: 0.85000\n",
      "[Train]: Step: 5500, loss: 0.40443 acc: 0.90000\n",
      "[Train]: Step: 5600, loss: 0.77936 acc: 0.60000\n",
      "[Train]: Step: 5700, loss: 0.75022 acc: 0.70000\n",
      "[Train]: Step: 5800, loss: 0.83009 acc: 0.75000\n",
      "[Train]: Step: 5900, loss: 0.66499 acc: 0.80000\n",
      "[Train]: Step: 6000, loss: 0.71941 acc: 0.65000\n",
      "[Test] Step: 6000, acc: 0.69870\n",
      "[Train]: Step: 6100, loss: 1.50484 acc: 0.70000\n",
      "[Train]: Step: 6200, loss: 0.62834 acc: 0.75000\n",
      "[Train]: Step: 6300, loss: 1.07270 acc: 0.60000\n",
      "[Train]: Step: 6400, loss: 0.71984 acc: 0.75000\n",
      "[Train]: Step: 6500, loss: 0.63882 acc: 0.75000\n",
      "[Train]: Step: 6600, loss: 0.92138 acc: 0.80000\n",
      "[Train]: Step: 6700, loss: 1.07680 acc: 0.60000\n",
      "[Train]: Step: 6800, loss: 0.81020 acc: 0.75000\n",
      "[Train]: Step: 6900, loss: 0.80318 acc: 0.70000\n",
      "[Train]: Step: 7000, loss: 0.51414 acc: 0.85000\n",
      "[Test] Step: 7000, acc: 0.69780\n",
      "[Train]: Step: 7100, loss: 0.76369 acc: 0.75000\n",
      "[Train]: Step: 7200, loss: 0.65235 acc: 0.75000\n",
      "[Train]: Step: 7300, loss: 0.69350 acc: 0.70000\n",
      "[Train]: Step: 7400, loss: 0.64682 acc: 0.75000\n",
      "[Train]: Step: 7500, loss: 0.57585 acc: 0.80000\n",
      "[Train]: Step: 7600, loss: 0.56117 acc: 0.80000\n",
      "[Train]: Step: 7700, loss: 0.90835 acc: 0.70000\n",
      "[Train]: Step: 7800, loss: 0.33582 acc: 0.90000\n",
      "[Train]: Step: 7900, loss: 0.73660 acc: 0.80000\n",
      "[Train]: Step: 8000, loss: 0.37450 acc: 0.95000\n",
      "[Test] Step: 8000, acc: 0.70840\n",
      "[Train]: Step: 8100, loss: 0.74177 acc: 0.75000\n",
      "[Train]: Step: 8200, loss: 0.44690 acc: 0.90000\n",
      "[Train]: Step: 8300, loss: 1.12008 acc: 0.75000\n",
      "[Train]: Step: 8400, loss: 0.87958 acc: 0.60000\n",
      "[Train]: Step: 8500, loss: 0.46767 acc: 0.75000\n",
      "[Train]: Step: 8600, loss: 0.99485 acc: 0.70000\n",
      "[Train]: Step: 8700, loss: 0.84434 acc: 0.80000\n",
      "[Train]: Step: 8800, loss: 0.56695 acc: 0.80000\n",
      "[Train]: Step: 8900, loss: 0.54206 acc: 0.80000\n",
      "[Train]: Step: 9000, loss: 0.60038 acc: 0.75000\n",
      "[Test] Step: 9000, acc: 0.71400\n",
      "[Train]: Step: 9100, loss: 0.52194 acc: 0.75000\n",
      "[Train]: Step: 9200, loss: 0.59629 acc: 0.70000\n",
      "[Train]: Step: 9300, loss: 1.17294 acc: 0.65000\n",
      "[Train]: Step: 9400, loss: 0.68638 acc: 0.75000\n",
      "[Train]: Step: 9500, loss: 0.88933 acc: 0.80000\n",
      "[Train]: Step: 9600, loss: 0.59977 acc: 0.80000\n",
      "[Train]: Step: 9700, loss: 0.57205 acc: 0.80000\n",
      "[Train]: Step: 9800, loss: 0.45630 acc: 0.85000\n",
      "[Train]: Step: 9900, loss: 0.52752 acc: 0.85000\n",
      "[Train]: Step: 10000, loss: 0.78249 acc: 0.70000\n",
      "[Test] Step: 10000, acc: 0.73320\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 20\n",
    "train_steps = 10000\n",
    "test_steps = 2000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss, acc, _ = sess.run([_loss, accuracy, train_op], \n",
    "                                feed_dict={x: batch_data, y: batch_labels})\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('[Train]: Step: %d, loss: %4.5f acc: %4.5f' \n",
    "                  % (i+1, loss, acc))\n",
    "        if (i+1) % 1000 == 0:\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run([accuracy], \n",
    "                                        feed_dict={x: test_batch_data, y: test_batch_labels})\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.mean(all_test_acc_val)\n",
    "            print('[Test] Step: %d, acc: %4.5f' % (i+1, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

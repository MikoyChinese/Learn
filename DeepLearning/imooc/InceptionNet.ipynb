{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_DIR = '/home/commaai-03/Data/dataset/cifar-10-python'\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [os.path.join(CIFAR_DIR, file) \n",
    "             for file in os.listdir(CIFAR_DIR)\n",
    "             if '.html' not in file]\n",
    "filenames.sort()\n",
    "meta_file = filenames[0]\n",
    "train_files = filenames[1:-1]\n",
    "test_file = [filenames[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'batch_label'\n",
      "b'labels'\n",
      "b'data'\n",
      "b'filenames'\n"
     ]
    }
   ],
   "source": [
    "_test_data = unpickle(test_file[0])\n",
    "for k, v in _test_data.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff2bef404e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_arr = _test_data[b'data'][0]\n",
    "# 32 * 32 * 3 (R,G,B)\n",
    "img_arr_reshaped = img_arr.reshape((3, 32, 32))\n",
    "img = img_arr_reshaped.transpose(1, 2, 0)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarData:\n",
    "    \n",
    "    def __init__(self, filenames, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        for filename in filenames:\n",
    "            data, labels = self.load_data(filename)\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._data = self._data / 127.5 - 1\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        print('[CIFAR-10]: Data shape-> %s' % str(self._data.shape))\n",
    "        print('[CIFAR-10]: Label shape-> %s' % str(self._labels.shape))\n",
    "        \n",
    "        self.num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "            \n",
    "    def load_data(self, filename):\n",
    "        import pickle\n",
    "        with open(filename, mode='rb') as f:\n",
    "            data = pickle.load(f, encoding='bytes')\n",
    "        return data[b'data'], data[b'labels']\n",
    "    \n",
    "    def _shuffle_data(self):\n",
    "        index = np.random.permutation(self.num_examples)\n",
    "        self._data = self._data[index]\n",
    "        self._labels = self._labels[index]\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self.num_examples:\n",
    "            rest_num_examples = self.num_examples - self._indicator\n",
    "            data_rest_part = self._data[self._indicator: self.num_examples]\n",
    "            label_rest_part = self._labels[self._indicator: self.num_examples]\n",
    "            \n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "            # For new loop, self._indicator + batch_size = self.num_examples\n",
    "            self._indicator = batch_size - rest_num_examples\n",
    "            end_indicator = self._indicator\n",
    "            data_new_part = self._data[:end_indicator]\n",
    "            label_new_part = self._labels[:end_indicator]\n",
    "            batch_data = np.concatenate((data_rest_part, data_new_part), axis=0)\n",
    "            batch_label = np.concatenate((label_rest_part, label_new_part), axis=0)\n",
    "        else:\n",
    "            batch_data = self._data[self._indicator:end_indicator]\n",
    "            batch_label = self._labels[self._indicator:end_indicator]\n",
    "            self._indicator = end_indicator\n",
    "        \n",
    "        return batch_data, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CIFAR-10]: Data shape-> (50000, 3072)\n",
      "[CIFAR-10]: Label shape-> (50000,)\n",
      "[CIFAR-10]: Data shape-> (10000, 3072)\n",
      "[CIFAR-10]: Label shape-> (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_data = CifarData(train_files, need_shuffle=True)\n",
    "test_data = CifarData(test_file, need_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block(x, output_channel_for_path, name):\n",
    "    '''\n",
    "    Args:\n",
    "    - x:\n",
    "    - output_channel_for_path:\n",
    "    - name:\n",
    "    '''\n",
    "    with tf.variable_scope(name):\n",
    "        conv1_1 = tf.keras.layers.Conv2D(filters=output_channel_for_path[0], \n",
    "                                         kernel_size=(1,1), \n",
    "                                         strides=(1,1),\n",
    "                                         padding='same', \n",
    "                                         activation=tf.nn.relu, name='conv1_1')(x)\n",
    "        conv3_3 = tf.keras.layers.Conv2D(filters=output_channel_for_path[1], \n",
    "                                         kernel_size=(3,3), \n",
    "                                         strides=(1,1), \n",
    "                                         padding='same', \n",
    "                                         activation=tf.nn.relu, name='conv3_3')(x)\n",
    "        conv5_5 = tf.keras.layers.Conv2D(filters=output_channel_for_path[2], \n",
    "                                         kernel_size=(5,5), \n",
    "                                         strides=(1,1), \n",
    "                                         padding='same', \n",
    "                                         activation=tf.nn.relu, name='conv5_5')(x)\n",
    "        max_pooling = tf.keras.layers.MaxPooling2D(pool_size=(2,2), \n",
    "                                                   strides=(2,2), padding='valid')(x)\n",
    "        \n",
    "        max_pooling_shape = max_pooling.get_shape().as_list()[1:]\n",
    "        input_shape = x.get_shape().as_list()[1:]\n",
    "        width_padding = (input_shape[0] - max_pooling_shape[0]) // 2\n",
    "        height_padding = (input_shape[1] - max_pooling_shape[1]) // 2\n",
    "        padded_pooling = tf.pad(tensor=max_pooling,\n",
    "                                paddings=[[0, 0], \n",
    "                                          [width_padding, width_padding],\n",
    "                                          [height_padding, height_padding],\n",
    "                                          [0, 0]])\n",
    "        concat_layer = tf.concat(\n",
    "            [conv1_1, conv3_3, conv5_5, padded_pooling], axis=3)\n",
    "        return concat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 17:22:02.337958 140682904262464 deprecation.py:506] From /home/commaai-03/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0923 17:22:02.534355 140682904262464 deprecation.py:323] From /home/commaai-03/.local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 3072])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "x_img = tf.reshape(x, [-1, 3, 32, 32])\n",
    "# x_img shape: (32, 32, 3)\n",
    "x_img = tf.transpose(x_img, perm=[0, 2, 3, 1])\n",
    "# conv1 shape: (32, 32, 32) N = (M - K + 2P)/S + 1 32 = (32 - 3 + 2*1)/1 + 1\n",
    "conv1 = tf.keras.layers.Conv2D(filters=32, \n",
    "                               kernel_size=(3, 3),\n",
    "                               padding='same',\n",
    "                               activation=tf.nn.relu, name='conv1')(x_img)\n",
    "# pooling1 shape: (16, 16, 32)\n",
    "pooling1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), \n",
    "                                        strides=(2,2), name='pool1')(conv1)\n",
    "# inception_2a shape: (16, 16, 80) 80-> conv 16*3 + pooling 32\n",
    "inception_2a = inception_block(pooling1, [16,16,16], name='inception_2a')\n",
    "# inception_2b shape: (16, 16, 128)\n",
    "inception_2b = inception_block(inception_2a, [16,16,16], name='inception_2b')\n",
    "# pooling2 shape: (8, 8, 128)\n",
    "pooling2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), \n",
    "                                        strides=(2,2), name='pool2')(inception_2b)\n",
    "# inception_3a shape: (8, 8, 176)\n",
    "inception_3a = inception_block(pooling2, [16,16,16], name='inception_3a')\n",
    "# inception_3b shape: (8, 8, 224)\n",
    "inception_3b = inception_block(inception_3a, [16,16,16], name='inception_3b')\n",
    "# pooling3 shape: (4, 4, 224)\n",
    "pooling3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), \n",
    "                                        strides=(2,2), name='pool3')(inception_3b)\n",
    "# flatten shape: (3584,)\n",
    "flatten = tf.keras.layers.Flatten()(pooling3)\n",
    "y_ = tf.keras.layers.Dense(10)(flatten)\n",
    "\n",
    "_loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "predict = tf.argmax(y_, 1)\n",
    "correct_prediction = tf.equal(predict, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: Step: 100, loss: 2.00103 acc: 0.25000\n",
      "[Train]: Step: 200, loss: 1.63289 acc: 0.35000\n",
      "[Train]: Step: 300, loss: 1.46568 acc: 0.40000\n",
      "[Train]: Step: 400, loss: 1.64273 acc: 0.40000\n",
      "[Train]: Step: 500, loss: 1.44105 acc: 0.45000\n",
      "[Train]: Step: 600, loss: 1.00346 acc: 0.75000\n",
      "[Train]: Step: 700, loss: 1.22880 acc: 0.75000\n",
      "[Train]: Step: 800, loss: 1.17306 acc: 0.65000\n",
      "[Train]: Step: 900, loss: 1.35835 acc: 0.55000\n",
      "[Train]: Step: 1000, loss: 1.37415 acc: 0.50000\n",
      "[Test] Step: 1000, acc: 0.53780\n",
      "[Train]: Step: 1100, loss: 1.29680 acc: 0.60000\n",
      "[Train]: Step: 1200, loss: 1.47732 acc: 0.45000\n",
      "[Train]: Step: 1300, loss: 1.38279 acc: 0.50000\n",
      "[Train]: Step: 1400, loss: 1.37641 acc: 0.45000\n",
      "[Train]: Step: 1500, loss: 1.01902 acc: 0.70000\n",
      "[Train]: Step: 1600, loss: 0.90187 acc: 0.70000\n",
      "[Train]: Step: 1700, loss: 1.07030 acc: 0.65000\n",
      "[Train]: Step: 1800, loss: 0.76410 acc: 0.80000\n",
      "[Train]: Step: 1900, loss: 1.22728 acc: 0.65000\n",
      "[Train]: Step: 2000, loss: 1.08240 acc: 0.55000\n",
      "[Test] Step: 2000, acc: 0.62940\n",
      "[Train]: Step: 2100, loss: 0.89593 acc: 0.75000\n",
      "[Train]: Step: 2200, loss: 0.80400 acc: 0.75000\n",
      "[Train]: Step: 2300, loss: 1.32875 acc: 0.55000\n",
      "[Train]: Step: 2400, loss: 0.94936 acc: 0.70000\n",
      "[Train]: Step: 2500, loss: 0.48702 acc: 0.85000\n",
      "[Train]: Step: 2600, loss: 0.79569 acc: 0.75000\n",
      "[Train]: Step: 2700, loss: 0.58705 acc: 0.75000\n",
      "[Train]: Step: 2800, loss: 0.59689 acc: 0.85000\n",
      "[Train]: Step: 2900, loss: 0.72629 acc: 0.70000\n",
      "[Train]: Step: 3000, loss: 1.23179 acc: 0.60000\n",
      "[Test] Step: 3000, acc: 0.64610\n",
      "[Train]: Step: 3100, loss: 0.61807 acc: 0.75000\n",
      "[Train]: Step: 3200, loss: 0.71630 acc: 0.65000\n",
      "[Train]: Step: 3300, loss: 0.68005 acc: 0.75000\n",
      "[Train]: Step: 3400, loss: 1.23119 acc: 0.50000\n",
      "[Train]: Step: 3500, loss: 0.91213 acc: 0.65000\n",
      "[Train]: Step: 3600, loss: 0.95867 acc: 0.70000\n",
      "[Train]: Step: 3700, loss: 0.74612 acc: 0.70000\n",
      "[Train]: Step: 3800, loss: 0.95280 acc: 0.75000\n",
      "[Train]: Step: 3900, loss: 0.73187 acc: 0.75000\n",
      "[Train]: Step: 4000, loss: 0.75565 acc: 0.70000\n",
      "[Test] Step: 4000, acc: 0.70340\n",
      "[Train]: Step: 4100, loss: 0.73482 acc: 0.65000\n",
      "[Train]: Step: 4200, loss: 1.06640 acc: 0.55000\n",
      "[Train]: Step: 4300, loss: 1.00909 acc: 0.65000\n",
      "[Train]: Step: 4400, loss: 0.83615 acc: 0.75000\n",
      "[Train]: Step: 4500, loss: 0.79059 acc: 0.75000\n",
      "[Train]: Step: 4600, loss: 0.86748 acc: 0.75000\n",
      "[Train]: Step: 4700, loss: 0.77944 acc: 0.65000\n",
      "[Train]: Step: 4800, loss: 0.53203 acc: 0.80000\n",
      "[Train]: Step: 4900, loss: 0.81366 acc: 0.65000\n",
      "[Train]: Step: 5000, loss: 0.54596 acc: 0.85000\n",
      "[Test] Step: 5000, acc: 0.67050\n",
      "[Train]: Step: 5100, loss: 0.65602 acc: 0.80000\n",
      "[Train]: Step: 5200, loss: 1.13176 acc: 0.55000\n",
      "[Train]: Step: 5300, loss: 1.44093 acc: 0.50000\n",
      "[Train]: Step: 5400, loss: 0.59804 acc: 0.80000\n",
      "[Train]: Step: 5500, loss: 0.99374 acc: 0.55000\n",
      "[Train]: Step: 5600, loss: 0.57739 acc: 0.80000\n",
      "[Train]: Step: 5700, loss: 0.62489 acc: 0.70000\n",
      "[Train]: Step: 5800, loss: 0.94667 acc: 0.65000\n",
      "[Train]: Step: 5900, loss: 1.07864 acc: 0.65000\n",
      "[Train]: Step: 6000, loss: 1.00882 acc: 0.65000\n",
      "[Test] Step: 6000, acc: 0.71370\n",
      "[Train]: Step: 6100, loss: 0.60848 acc: 0.80000\n",
      "[Train]: Step: 6200, loss: 0.66010 acc: 0.80000\n",
      "[Train]: Step: 6300, loss: 0.59092 acc: 0.75000\n",
      "[Train]: Step: 6400, loss: 0.32049 acc: 0.90000\n",
      "[Train]: Step: 6500, loss: 0.62850 acc: 0.65000\n",
      "[Train]: Step: 6600, loss: 0.94216 acc: 0.70000\n",
      "[Train]: Step: 6700, loss: 0.74962 acc: 0.80000\n",
      "[Train]: Step: 6800, loss: 0.74237 acc: 0.70000\n",
      "[Train]: Step: 6900, loss: 0.45119 acc: 0.85000\n",
      "[Train]: Step: 7000, loss: 0.70238 acc: 0.85000\n",
      "[Test] Step: 7000, acc: 0.71870\n",
      "[Train]: Step: 7100, loss: 1.18898 acc: 0.55000\n",
      "[Train]: Step: 7200, loss: 0.27142 acc: 0.85000\n",
      "[Train]: Step: 7300, loss: 0.56347 acc: 0.75000\n",
      "[Train]: Step: 7400, loss: 0.65773 acc: 0.75000\n",
      "[Train]: Step: 7500, loss: 0.68249 acc: 0.75000\n",
      "[Train]: Step: 7600, loss: 0.40199 acc: 0.90000\n",
      "[Train]: Step: 7700, loss: 0.76178 acc: 0.70000\n",
      "[Train]: Step: 7800, loss: 0.35644 acc: 0.95000\n",
      "[Train]: Step: 7900, loss: 0.56710 acc: 0.85000\n",
      "[Train]: Step: 8000, loss: 0.48624 acc: 0.75000\n",
      "[Test] Step: 8000, acc: 0.73350\n",
      "[Train]: Step: 8100, loss: 1.03709 acc: 0.65000\n",
      "[Train]: Step: 8200, loss: 0.40900 acc: 0.90000\n",
      "[Train]: Step: 8300, loss: 0.44459 acc: 0.85000\n",
      "[Train]: Step: 8400, loss: 0.36477 acc: 0.85000\n",
      "[Train]: Step: 8500, loss: 0.87367 acc: 0.60000\n",
      "[Train]: Step: 8600, loss: 0.30072 acc: 0.90000\n",
      "[Train]: Step: 8700, loss: 0.61829 acc: 0.85000\n",
      "[Train]: Step: 8800, loss: 0.99635 acc: 0.70000\n",
      "[Train]: Step: 8900, loss: 0.94074 acc: 0.65000\n",
      "[Train]: Step: 9000, loss: 0.82068 acc: 0.65000\n",
      "[Test] Step: 9000, acc: 0.74040\n",
      "[Train]: Step: 9100, loss: 0.44641 acc: 0.80000\n",
      "[Train]: Step: 9200, loss: 0.26858 acc: 0.95000\n",
      "[Train]: Step: 9300, loss: 0.52084 acc: 0.80000\n",
      "[Train]: Step: 9400, loss: 0.99003 acc: 0.65000\n",
      "[Train]: Step: 9500, loss: 0.28980 acc: 0.95000\n",
      "[Train]: Step: 9600, loss: 0.94313 acc: 0.65000\n",
      "[Train]: Step: 9700, loss: 0.25761 acc: 0.95000\n",
      "[Train]: Step: 9800, loss: 0.93616 acc: 0.65000\n",
      "[Train]: Step: 9900, loss: 0.55159 acc: 0.70000\n",
      "[Train]: Step: 10000, loss: 0.46081 acc: 0.85000\n",
      "[Test] Step: 10000, acc: 0.72810\n",
      "[Train]: Step: 10100, loss: 0.92611 acc: 0.75000\n",
      "[Train]: Step: 10200, loss: 0.53557 acc: 0.85000\n",
      "[Train]: Step: 10300, loss: 0.65408 acc: 0.75000\n",
      "[Train]: Step: 10400, loss: 0.78214 acc: 0.80000\n",
      "[Train]: Step: 10500, loss: 0.53138 acc: 0.85000\n",
      "[Train]: Step: 10600, loss: 0.43569 acc: 0.90000\n",
      "[Train]: Step: 10700, loss: 0.25455 acc: 0.95000\n",
      "[Train]: Step: 10800, loss: 0.25349 acc: 0.90000\n",
      "[Train]: Step: 10900, loss: 0.40718 acc: 0.85000\n",
      "[Train]: Step: 11000, loss: 0.40761 acc: 0.90000\n",
      "[Test] Step: 11000, acc: 0.75000\n",
      "[Train]: Step: 11100, loss: 0.51202 acc: 0.80000\n",
      "[Train]: Step: 11200, loss: 0.35003 acc: 0.85000\n",
      "[Train]: Step: 11300, loss: 0.94087 acc: 0.75000\n",
      "[Train]: Step: 11400, loss: 0.65241 acc: 0.70000\n",
      "[Train]: Step: 11500, loss: 0.66412 acc: 0.85000\n",
      "[Train]: Step: 11600, loss: 0.75671 acc: 0.70000\n",
      "[Train]: Step: 11700, loss: 1.19812 acc: 0.60000\n",
      "[Train]: Step: 11800, loss: 0.78848 acc: 0.80000\n",
      "[Train]: Step: 11900, loss: 0.30609 acc: 0.95000\n",
      "[Train]: Step: 12000, loss: 0.98217 acc: 0.70000\n",
      "[Test] Step: 12000, acc: 0.74920\n",
      "[Train]: Step: 12100, loss: 0.54195 acc: 0.85000\n",
      "[Train]: Step: 12200, loss: 0.54231 acc: 0.75000\n",
      "[Train]: Step: 12300, loss: 0.54577 acc: 0.80000\n",
      "[Train]: Step: 12400, loss: 0.41861 acc: 0.85000\n",
      "[Train]: Step: 12500, loss: 0.35717 acc: 0.85000\n",
      "[Train]: Step: 12600, loss: 0.37694 acc: 0.80000\n",
      "[Train]: Step: 12700, loss: 0.59222 acc: 0.80000\n",
      "[Train]: Step: 12800, loss: 0.09331 acc: 0.95000\n",
      "[Train]: Step: 12900, loss: 0.53224 acc: 0.85000\n",
      "[Train]: Step: 13000, loss: 0.38115 acc: 0.80000\n",
      "[Test] Step: 13000, acc: 0.74850\n",
      "[Train]: Step: 13100, loss: 0.65270 acc: 0.80000\n",
      "[Train]: Step: 13200, loss: 0.12701 acc: 1.00000\n",
      "[Train]: Step: 13300, loss: 0.29267 acc: 0.95000\n",
      "[Train]: Step: 13400, loss: 0.87706 acc: 0.75000\n",
      "[Train]: Step: 13500, loss: 0.50430 acc: 0.85000\n",
      "[Train]: Step: 13600, loss: 0.67096 acc: 0.80000\n",
      "[Train]: Step: 13700, loss: 0.41643 acc: 0.85000\n",
      "[Train]: Step: 13800, loss: 0.26026 acc: 0.95000\n",
      "[Train]: Step: 13900, loss: 0.61663 acc: 0.75000\n",
      "[Train]: Step: 14000, loss: 0.58099 acc: 0.85000\n",
      "[Test] Step: 14000, acc: 0.74000\n",
      "[Train]: Step: 14100, loss: 0.15541 acc: 0.95000\n",
      "[Train]: Step: 14200, loss: 0.17728 acc: 0.95000\n",
      "[Train]: Step: 14300, loss: 0.28013 acc: 0.90000\n",
      "[Train]: Step: 14400, loss: 0.34675 acc: 0.85000\n",
      "[Train]: Step: 14500, loss: 0.49233 acc: 0.90000\n",
      "[Train]: Step: 14600, loss: 0.43879 acc: 0.85000\n",
      "[Train]: Step: 14700, loss: 1.19388 acc: 0.55000\n",
      "[Train]: Step: 14800, loss: 0.99153 acc: 0.70000\n",
      "[Train]: Step: 14900, loss: 0.27098 acc: 0.90000\n",
      "[Train]: Step: 15000, loss: 0.50737 acc: 0.85000\n",
      "[Test] Step: 15000, acc: 0.75330\n",
      "[Train]: Step: 15100, loss: 0.54356 acc: 0.75000\n",
      "[Train]: Step: 15200, loss: 0.11938 acc: 0.95000\n",
      "[Train]: Step: 15300, loss: 0.36469 acc: 0.85000\n",
      "[Train]: Step: 15400, loss: 0.90184 acc: 0.80000\n",
      "[Train]: Step: 15500, loss: 0.26653 acc: 0.90000\n",
      "[Train]: Step: 15600, loss: 0.23661 acc: 0.90000\n",
      "[Train]: Step: 15700, loss: 0.25827 acc: 0.95000\n",
      "[Train]: Step: 15800, loss: 0.37318 acc: 0.80000\n",
      "[Train]: Step: 15900, loss: 0.55425 acc: 0.80000\n",
      "[Train]: Step: 16000, loss: 0.17796 acc: 0.95000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Step: 16000, acc: 0.75420\n",
      "[Train]: Step: 16100, loss: 0.40674 acc: 0.85000\n",
      "[Train]: Step: 16200, loss: 0.69450 acc: 0.65000\n",
      "[Train]: Step: 16300, loss: 0.30918 acc: 0.95000\n",
      "[Train]: Step: 16400, loss: 0.47537 acc: 0.80000\n",
      "[Train]: Step: 16500, loss: 0.34696 acc: 0.80000\n",
      "[Train]: Step: 16600, loss: 0.44248 acc: 0.80000\n",
      "[Train]: Step: 16700, loss: 0.22396 acc: 0.90000\n",
      "[Train]: Step: 16800, loss: 0.40117 acc: 0.85000\n",
      "[Train]: Step: 16900, loss: 0.24629 acc: 0.90000\n",
      "[Train]: Step: 17000, loss: 0.14469 acc: 1.00000\n",
      "[Test] Step: 17000, acc: 0.73700\n",
      "[Train]: Step: 17100, loss: 0.90757 acc: 0.70000\n",
      "[Train]: Step: 17200, loss: 0.23079 acc: 0.90000\n",
      "[Train]: Step: 17300, loss: 0.25886 acc: 0.90000\n",
      "[Train]: Step: 17400, loss: 0.54199 acc: 0.90000\n",
      "[Train]: Step: 17500, loss: 0.25524 acc: 0.95000\n",
      "[Train]: Step: 17600, loss: 0.15908 acc: 0.95000\n",
      "[Train]: Step: 17700, loss: 0.20836 acc: 0.90000\n",
      "[Train]: Step: 17800, loss: 0.68433 acc: 0.80000\n",
      "[Train]: Step: 17900, loss: 0.42008 acc: 0.80000\n",
      "[Train]: Step: 18000, loss: 0.25018 acc: 0.90000\n",
      "[Test] Step: 18000, acc: 0.74120\n",
      "[Train]: Step: 18100, loss: 0.23045 acc: 0.90000\n",
      "[Train]: Step: 18200, loss: 0.16121 acc: 0.95000\n",
      "[Train]: Step: 18300, loss: 0.42787 acc: 0.80000\n",
      "[Train]: Step: 18400, loss: 0.12989 acc: 1.00000\n",
      "[Train]: Step: 18500, loss: 0.13845 acc: 0.95000\n",
      "[Train]: Step: 18600, loss: 0.25370 acc: 0.90000\n",
      "[Train]: Step: 18700, loss: 0.49170 acc: 0.85000\n",
      "[Train]: Step: 18800, loss: 0.38125 acc: 0.90000\n",
      "[Train]: Step: 18900, loss: 0.44340 acc: 0.80000\n",
      "[Train]: Step: 19000, loss: 0.24336 acc: 0.90000\n",
      "[Test] Step: 19000, acc: 0.74410\n",
      "[Train]: Step: 19100, loss: 0.30794 acc: 0.85000\n",
      "[Train]: Step: 19200, loss: 0.32308 acc: 0.95000\n",
      "[Train]: Step: 19300, loss: 0.35361 acc: 0.85000\n",
      "[Train]: Step: 19400, loss: 0.41482 acc: 0.90000\n",
      "[Train]: Step: 19500, loss: 0.40164 acc: 0.90000\n",
      "[Train]: Step: 19600, loss: 0.30072 acc: 0.80000\n",
      "[Train]: Step: 19700, loss: 0.28844 acc: 0.90000\n",
      "[Train]: Step: 19800, loss: 0.71959 acc: 0.75000\n",
      "[Train]: Step: 19900, loss: 0.40820 acc: 0.80000\n",
      "[Train]: Step: 20000, loss: 0.41756 acc: 0.85000\n",
      "[Test] Step: 20000, acc: 0.74500\n",
      "[Train]: Step: 20100, loss: 0.30789 acc: 0.85000\n",
      "[Train]: Step: 20200, loss: 0.12671 acc: 0.95000\n",
      "[Train]: Step: 20300, loss: 0.13631 acc: 0.95000\n",
      "[Train]: Step: 20400, loss: 0.38148 acc: 0.90000\n",
      "[Train]: Step: 20500, loss: 0.21275 acc: 0.90000\n",
      "[Train]: Step: 20600, loss: 0.36446 acc: 0.90000\n",
      "[Train]: Step: 20700, loss: 0.23265 acc: 0.95000\n",
      "[Train]: Step: 20800, loss: 0.10745 acc: 1.00000\n",
      "[Train]: Step: 20900, loss: 0.44300 acc: 0.75000\n",
      "[Train]: Step: 21000, loss: 0.25951 acc: 0.90000\n",
      "[Test] Step: 21000, acc: 0.74970\n",
      "[Train]: Step: 21100, loss: 0.31711 acc: 0.85000\n",
      "[Train]: Step: 21200, loss: 0.51800 acc: 0.80000\n",
      "[Train]: Step: 21300, loss: 0.39417 acc: 0.80000\n",
      "[Train]: Step: 21400, loss: 0.41953 acc: 0.85000\n",
      "[Train]: Step: 21500, loss: 0.42536 acc: 0.95000\n",
      "[Train]: Step: 21600, loss: 0.47787 acc: 0.85000\n",
      "[Train]: Step: 21700, loss: 0.13297 acc: 1.00000\n",
      "[Train]: Step: 21800, loss: 0.59338 acc: 0.75000\n",
      "[Train]: Step: 21900, loss: 0.94789 acc: 0.80000\n",
      "[Train]: Step: 22000, loss: 0.27960 acc: 0.90000\n",
      "[Test] Step: 22000, acc: 0.74490\n",
      "[Train]: Step: 22100, loss: 0.37995 acc: 0.90000\n",
      "[Train]: Step: 22200, loss: 0.10307 acc: 0.95000\n",
      "[Train]: Step: 22300, loss: 0.32815 acc: 0.80000\n",
      "[Train]: Step: 22400, loss: 0.26178 acc: 0.95000\n",
      "[Train]: Step: 22500, loss: 0.61124 acc: 0.85000\n",
      "[Train]: Step: 22600, loss: 0.09116 acc: 0.95000\n",
      "[Train]: Step: 22700, loss: 0.26199 acc: 0.90000\n",
      "[Train]: Step: 22800, loss: 0.23729 acc: 0.90000\n",
      "[Train]: Step: 22900, loss: 0.46429 acc: 0.80000\n",
      "[Train]: Step: 23000, loss: 0.44160 acc: 0.90000\n",
      "[Test] Step: 23000, acc: 0.75340\n",
      "[Train]: Step: 23100, loss: 0.11569 acc: 0.90000\n",
      "[Train]: Step: 23200, loss: 0.29293 acc: 0.85000\n",
      "[Train]: Step: 23300, loss: 0.56938 acc: 0.90000\n",
      "[Train]: Step: 23400, loss: 0.09668 acc: 1.00000\n",
      "[Train]: Step: 23500, loss: 0.31564 acc: 0.85000\n",
      "[Train]: Step: 23600, loss: 0.43114 acc: 0.90000\n",
      "[Train]: Step: 23700, loss: 0.13330 acc: 0.90000\n",
      "[Train]: Step: 23800, loss: 0.73567 acc: 0.85000\n",
      "[Train]: Step: 23900, loss: 0.17638 acc: 0.90000\n",
      "[Train]: Step: 24000, loss: 0.16192 acc: 0.90000\n",
      "[Test] Step: 24000, acc: 0.74580\n",
      "[Train]: Step: 24100, loss: 0.25654 acc: 0.95000\n",
      "[Train]: Step: 24200, loss: 0.32512 acc: 0.85000\n",
      "[Train]: Step: 24300, loss: 0.30199 acc: 0.95000\n",
      "[Train]: Step: 24400, loss: 0.17694 acc: 0.90000\n",
      "[Train]: Step: 24500, loss: 0.22107 acc: 0.90000\n",
      "[Train]: Step: 24600, loss: 0.52299 acc: 0.80000\n",
      "[Train]: Step: 24700, loss: 0.47776 acc: 0.85000\n",
      "[Train]: Step: 24800, loss: 0.63008 acc: 0.80000\n",
      "[Train]: Step: 24900, loss: 0.29525 acc: 0.90000\n",
      "[Train]: Step: 25000, loss: 0.65756 acc: 0.80000\n",
      "[Test] Step: 25000, acc: 0.74350\n",
      "[Train]: Step: 25100, loss: 0.44417 acc: 0.80000\n",
      "[Train]: Step: 25200, loss: 0.08845 acc: 1.00000\n",
      "[Train]: Step: 25300, loss: 0.16153 acc: 0.90000\n",
      "[Train]: Step: 25400, loss: 0.09558 acc: 1.00000\n",
      "[Train]: Step: 25500, loss: 0.19601 acc: 0.95000\n",
      "[Train]: Step: 25600, loss: 0.28729 acc: 0.90000\n",
      "[Train]: Step: 25700, loss: 0.10844 acc: 1.00000\n",
      "[Train]: Step: 25800, loss: 0.11414 acc: 0.90000\n",
      "[Train]: Step: 25900, loss: 0.13974 acc: 0.95000\n",
      "[Train]: Step: 26000, loss: 0.08277 acc: 1.00000\n",
      "[Test] Step: 26000, acc: 0.74810\n",
      "[Train]: Step: 26100, loss: 0.14591 acc: 0.95000\n",
      "[Train]: Step: 26200, loss: 0.33654 acc: 0.90000\n",
      "[Train]: Step: 26300, loss: 0.49106 acc: 0.90000\n",
      "[Train]: Step: 26400, loss: 0.31265 acc: 0.85000\n",
      "[Train]: Step: 26500, loss: 0.47917 acc: 0.90000\n",
      "[Train]: Step: 26600, loss: 0.37217 acc: 0.75000\n",
      "[Train]: Step: 26700, loss: 0.13311 acc: 0.95000\n",
      "[Train]: Step: 26800, loss: 0.31346 acc: 0.95000\n",
      "[Train]: Step: 26900, loss: 0.16753 acc: 0.95000\n",
      "[Train]: Step: 27000, loss: 0.16265 acc: 1.00000\n",
      "[Test] Step: 27000, acc: 0.75010\n",
      "[Train]: Step: 27100, loss: 0.75881 acc: 0.65000\n",
      "[Train]: Step: 27200, loss: 0.38052 acc: 0.90000\n",
      "[Train]: Step: 27300, loss: 0.27669 acc: 0.85000\n",
      "[Train]: Step: 27400, loss: 0.50986 acc: 0.75000\n",
      "[Train]: Step: 27500, loss: 0.25566 acc: 0.90000\n",
      "[Train]: Step: 27600, loss: 0.01751 acc: 1.00000\n",
      "[Train]: Step: 27700, loss: 0.20036 acc: 0.90000\n",
      "[Train]: Step: 27800, loss: 0.08573 acc: 0.95000\n",
      "[Train]: Step: 27900, loss: 0.05516 acc: 1.00000\n",
      "[Train]: Step: 28000, loss: 0.32059 acc: 0.90000\n",
      "[Test] Step: 28000, acc: 0.74590\n",
      "[Train]: Step: 28100, loss: 0.07891 acc: 1.00000\n",
      "[Train]: Step: 28200, loss: 0.14824 acc: 0.95000\n",
      "[Train]: Step: 28300, loss: 0.44513 acc: 0.85000\n",
      "[Train]: Step: 28400, loss: 0.27033 acc: 0.90000\n",
      "[Train]: Step: 28500, loss: 0.56107 acc: 0.90000\n",
      "[Train]: Step: 28600, loss: 0.21207 acc: 0.95000\n",
      "[Train]: Step: 28700, loss: 0.51337 acc: 0.85000\n",
      "[Train]: Step: 28800, loss: 0.04467 acc: 1.00000\n",
      "[Train]: Step: 28900, loss: 0.17962 acc: 0.90000\n",
      "[Train]: Step: 29000, loss: 0.02776 acc: 1.00000\n",
      "[Test] Step: 29000, acc: 0.74870\n",
      "[Train]: Step: 29100, loss: 0.36088 acc: 0.85000\n",
      "[Train]: Step: 29200, loss: 0.16613 acc: 0.90000\n",
      "[Train]: Step: 29300, loss: 0.09400 acc: 0.95000\n",
      "[Train]: Step: 29400, loss: 0.61981 acc: 0.75000\n",
      "[Train]: Step: 29500, loss: 0.04137 acc: 1.00000\n",
      "[Train]: Step: 29600, loss: 0.22945 acc: 0.90000\n",
      "[Train]: Step: 29700, loss: 0.26793 acc: 0.95000\n",
      "[Train]: Step: 29800, loss: 0.00862 acc: 1.00000\n",
      "[Train]: Step: 29900, loss: 0.37700 acc: 0.90000\n",
      "[Train]: Step: 30000, loss: 0.08191 acc: 0.95000\n",
      "[Test] Step: 30000, acc: 0.74040\n",
      "[Train]: Step: 30100, loss: 0.36552 acc: 0.85000\n",
      "[Train]: Step: 30200, loss: 0.11914 acc: 0.95000\n",
      "[Train]: Step: 30300, loss: 0.10001 acc: 0.95000\n",
      "[Train]: Step: 30400, loss: 0.02398 acc: 1.00000\n",
      "[Train]: Step: 30500, loss: 0.19256 acc: 0.95000\n",
      "[Train]: Step: 30600, loss: 0.19552 acc: 0.90000\n",
      "[Train]: Step: 30700, loss: 0.06968 acc: 0.95000\n",
      "[Train]: Step: 30800, loss: 0.18783 acc: 0.95000\n",
      "[Train]: Step: 30900, loss: 0.13333 acc: 0.90000\n",
      "[Train]: Step: 31000, loss: 0.04739 acc: 1.00000\n",
      "[Test] Step: 31000, acc: 0.74700\n",
      "[Train]: Step: 31100, loss: 0.27925 acc: 0.95000\n",
      "[Train]: Step: 31200, loss: 0.08655 acc: 0.95000\n",
      "[Train]: Step: 31300, loss: 0.28080 acc: 0.85000\n",
      "[Train]: Step: 31400, loss: 0.04688 acc: 1.00000\n",
      "[Train]: Step: 31500, loss: 0.29697 acc: 0.80000\n",
      "[Train]: Step: 31600, loss: 0.11034 acc: 1.00000\n",
      "[Train]: Step: 31700, loss: 0.43375 acc: 0.85000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: Step: 31800, loss: 0.22414 acc: 0.90000\n",
      "[Train]: Step: 31900, loss: 0.05385 acc: 1.00000\n",
      "[Train]: Step: 32000, loss: 0.14478 acc: 0.90000\n",
      "[Test] Step: 32000, acc: 0.73860\n",
      "[Train]: Step: 32100, loss: 0.15327 acc: 0.95000\n",
      "[Train]: Step: 32200, loss: 0.59146 acc: 0.85000\n",
      "[Train]: Step: 32300, loss: 0.43395 acc: 0.80000\n",
      "[Train]: Step: 32400, loss: 0.15155 acc: 0.95000\n",
      "[Train]: Step: 32500, loss: 0.24064 acc: 0.90000\n",
      "[Train]: Step: 32600, loss: 0.03208 acc: 1.00000\n",
      "[Train]: Step: 32700, loss: 0.33091 acc: 0.85000\n",
      "[Train]: Step: 32800, loss: 0.09481 acc: 0.95000\n",
      "[Train]: Step: 32900, loss: 0.29586 acc: 0.85000\n",
      "[Train]: Step: 33000, loss: 0.02085 acc: 1.00000\n",
      "[Test] Step: 33000, acc: 0.75390\n",
      "[Train]: Step: 33100, loss: 0.05426 acc: 0.95000\n",
      "[Train]: Step: 33200, loss: 0.03196 acc: 1.00000\n",
      "[Train]: Step: 33300, loss: 0.28516 acc: 0.90000\n",
      "[Train]: Step: 33400, loss: 0.27448 acc: 0.95000\n",
      "[Train]: Step: 33500, loss: 0.23626 acc: 0.90000\n",
      "[Train]: Step: 33600, loss: 0.18000 acc: 0.95000\n",
      "[Train]: Step: 33700, loss: 0.43201 acc: 0.80000\n",
      "[Train]: Step: 33800, loss: 0.14653 acc: 0.85000\n",
      "[Train]: Step: 33900, loss: 0.12737 acc: 0.95000\n",
      "[Train]: Step: 34000, loss: 0.83861 acc: 0.80000\n",
      "[Test] Step: 34000, acc: 0.73040\n",
      "[Train]: Step: 34100, loss: 0.49642 acc: 0.85000\n",
      "[Train]: Step: 34200, loss: 0.06059 acc: 1.00000\n",
      "[Train]: Step: 34300, loss: 0.31780 acc: 0.90000\n",
      "[Train]: Step: 34400, loss: 0.04535 acc: 1.00000\n",
      "[Train]: Step: 34500, loss: 0.21420 acc: 0.95000\n",
      "[Train]: Step: 34600, loss: 0.05234 acc: 1.00000\n",
      "[Train]: Step: 34700, loss: 0.02191 acc: 1.00000\n",
      "[Train]: Step: 34800, loss: 0.06018 acc: 1.00000\n",
      "[Train]: Step: 34900, loss: 0.37636 acc: 0.95000\n",
      "[Train]: Step: 35000, loss: 0.12826 acc: 0.95000\n",
      "[Test] Step: 35000, acc: 0.74640\n",
      "[Train]: Step: 35100, loss: 0.07244 acc: 0.95000\n",
      "[Train]: Step: 35200, loss: 0.16229 acc: 0.90000\n",
      "[Train]: Step: 35300, loss: 0.02617 acc: 1.00000\n",
      "[Train]: Step: 35400, loss: 0.10869 acc: 0.95000\n",
      "[Train]: Step: 35500, loss: 0.22908 acc: 0.95000\n",
      "[Train]: Step: 35600, loss: 0.14671 acc: 0.95000\n",
      "[Train]: Step: 35700, loss: 0.06996 acc: 1.00000\n",
      "[Train]: Step: 35800, loss: 0.08851 acc: 0.95000\n",
      "[Train]: Step: 35900, loss: 0.20834 acc: 0.90000\n",
      "[Train]: Step: 36000, loss: 0.02155 acc: 1.00000\n",
      "[Test] Step: 36000, acc: 0.74160\n",
      "[Train]: Step: 36100, loss: 0.16825 acc: 0.95000\n",
      "[Train]: Step: 36200, loss: 0.21406 acc: 0.90000\n",
      "[Train]: Step: 36300, loss: 0.27438 acc: 0.80000\n",
      "[Train]: Step: 36400, loss: 0.12614 acc: 0.95000\n",
      "[Train]: Step: 36500, loss: 0.05463 acc: 1.00000\n",
      "[Train]: Step: 36600, loss: 0.68626 acc: 0.80000\n",
      "[Train]: Step: 36700, loss: 0.09701 acc: 0.95000\n",
      "[Train]: Step: 36800, loss: 0.08158 acc: 0.95000\n",
      "[Train]: Step: 36900, loss: 0.12160 acc: 0.95000\n",
      "[Train]: Step: 37000, loss: 0.28097 acc: 0.90000\n",
      "[Test] Step: 37000, acc: 0.74470\n",
      "[Train]: Step: 37100, loss: 0.27941 acc: 0.90000\n",
      "[Train]: Step: 37200, loss: 0.24505 acc: 0.90000\n",
      "[Train]: Step: 37300, loss: 0.26233 acc: 0.95000\n",
      "[Train]: Step: 37400, loss: 0.53357 acc: 0.75000\n",
      "[Train]: Step: 37500, loss: 1.11914 acc: 0.70000\n",
      "[Train]: Step: 37600, loss: 0.07925 acc: 1.00000\n",
      "[Train]: Step: 37700, loss: 0.15792 acc: 0.95000\n",
      "[Train]: Step: 37800, loss: 0.26960 acc: 0.85000\n",
      "[Train]: Step: 37900, loss: 0.22934 acc: 0.90000\n",
      "[Train]: Step: 38000, loss: 0.04186 acc: 1.00000\n",
      "[Test] Step: 38000, acc: 0.74110\n",
      "[Train]: Step: 38100, loss: 0.11832 acc: 0.95000\n",
      "[Train]: Step: 38200, loss: 0.05395 acc: 1.00000\n",
      "[Train]: Step: 38300, loss: 0.17769 acc: 0.90000\n",
      "[Train]: Step: 38400, loss: 0.05709 acc: 1.00000\n",
      "[Train]: Step: 38500, loss: 0.01725 acc: 1.00000\n",
      "[Train]: Step: 38600, loss: 0.16309 acc: 0.90000\n",
      "[Train]: Step: 38700, loss: 0.43126 acc: 0.80000\n",
      "[Train]: Step: 38800, loss: 0.16221 acc: 0.95000\n",
      "[Train]: Step: 38900, loss: 0.10957 acc: 0.95000\n",
      "[Train]: Step: 39000, loss: 0.22289 acc: 0.90000\n",
      "[Test] Step: 39000, acc: 0.74080\n",
      "[Train]: Step: 39100, loss: 0.21919 acc: 0.85000\n",
      "[Train]: Step: 39200, loss: 0.06676 acc: 0.95000\n",
      "[Train]: Step: 39300, loss: 0.01681 acc: 1.00000\n",
      "[Train]: Step: 39400, loss: 0.02669 acc: 1.00000\n",
      "[Train]: Step: 39500, loss: 0.01312 acc: 1.00000\n",
      "[Train]: Step: 39600, loss: 0.02952 acc: 1.00000\n",
      "[Train]: Step: 39700, loss: 0.22650 acc: 0.95000\n",
      "[Train]: Step: 39800, loss: 0.15152 acc: 0.95000\n",
      "[Train]: Step: 39900, loss: 0.16506 acc: 0.90000\n",
      "[Train]: Step: 40000, loss: 0.09588 acc: 1.00000\n",
      "[Test] Step: 40000, acc: 0.73820\n",
      "[Train]: Step: 40100, loss: 0.21634 acc: 0.90000\n",
      "[Train]: Step: 40200, loss: 0.01061 acc: 1.00000\n",
      "[Train]: Step: 40300, loss: 0.36794 acc: 0.85000\n",
      "[Train]: Step: 40400, loss: 0.02337 acc: 1.00000\n",
      "[Train]: Step: 40500, loss: 0.26572 acc: 0.95000\n",
      "[Train]: Step: 40600, loss: 0.03166 acc: 1.00000\n",
      "[Train]: Step: 40700, loss: 0.12719 acc: 0.95000\n",
      "[Train]: Step: 40800, loss: 0.02015 acc: 1.00000\n",
      "[Train]: Step: 40900, loss: 0.14286 acc: 0.90000\n",
      "[Train]: Step: 41000, loss: 0.13220 acc: 0.90000\n",
      "[Test] Step: 41000, acc: 0.74920\n",
      "[Train]: Step: 41100, loss: 0.21603 acc: 0.90000\n",
      "[Train]: Step: 41200, loss: 0.01820 acc: 1.00000\n",
      "[Train]: Step: 41300, loss: 0.02083 acc: 1.00000\n",
      "[Train]: Step: 41400, loss: 0.29762 acc: 0.90000\n",
      "[Train]: Step: 41500, loss: 0.10666 acc: 0.95000\n",
      "[Train]: Step: 41600, loss: 0.12714 acc: 0.95000\n",
      "[Train]: Step: 41700, loss: 0.13255 acc: 0.95000\n",
      "[Train]: Step: 41800, loss: 0.02033 acc: 1.00000\n",
      "[Train]: Step: 41900, loss: 0.03612 acc: 1.00000\n",
      "[Train]: Step: 42000, loss: 0.15905 acc: 0.90000\n",
      "[Test] Step: 42000, acc: 0.73610\n",
      "[Train]: Step: 42100, loss: 0.42269 acc: 0.85000\n",
      "[Train]: Step: 42200, loss: 0.23633 acc: 0.90000\n",
      "[Train]: Step: 42300, loss: 0.51058 acc: 0.80000\n",
      "[Train]: Step: 42400, loss: 0.11008 acc: 0.95000\n",
      "[Train]: Step: 42500, loss: 0.18029 acc: 0.90000\n",
      "[Train]: Step: 42600, loss: 0.06186 acc: 0.95000\n",
      "[Train]: Step: 42700, loss: 0.03074 acc: 1.00000\n",
      "[Train]: Step: 42800, loss: 0.41399 acc: 0.90000\n",
      "[Train]: Step: 42900, loss: 0.02121 acc: 1.00000\n",
      "[Train]: Step: 43000, loss: 0.12646 acc: 0.95000\n",
      "[Test] Step: 43000, acc: 0.75120\n",
      "[Train]: Step: 43100, loss: 0.29779 acc: 0.85000\n",
      "[Train]: Step: 43200, loss: 0.16282 acc: 0.95000\n",
      "[Train]: Step: 43300, loss: 0.37320 acc: 0.90000\n",
      "[Train]: Step: 43400, loss: 0.53854 acc: 0.90000\n",
      "[Train]: Step: 43500, loss: 0.01289 acc: 1.00000\n",
      "[Train]: Step: 43600, loss: 0.07432 acc: 0.95000\n",
      "[Train]: Step: 43700, loss: 0.14891 acc: 0.95000\n",
      "[Train]: Step: 43800, loss: 0.24694 acc: 0.95000\n",
      "[Train]: Step: 43900, loss: 0.10645 acc: 0.90000\n",
      "[Train]: Step: 44000, loss: 0.09137 acc: 1.00000\n",
      "[Test] Step: 44000, acc: 0.74860\n",
      "[Train]: Step: 44100, loss: 0.19363 acc: 0.90000\n",
      "[Train]: Step: 44200, loss: 0.34366 acc: 0.85000\n",
      "[Train]: Step: 44300, loss: 0.27278 acc: 0.95000\n",
      "[Train]: Step: 44400, loss: 0.17688 acc: 0.95000\n",
      "[Train]: Step: 44500, loss: 0.32351 acc: 0.85000\n",
      "[Train]: Step: 44600, loss: 0.54375 acc: 0.85000\n",
      "[Train]: Step: 44700, loss: 0.18892 acc: 0.95000\n",
      "[Train]: Step: 44800, loss: 0.28408 acc: 0.95000\n",
      "[Train]: Step: 44900, loss: 0.74301 acc: 0.85000\n",
      "[Train]: Step: 45000, loss: 0.16111 acc: 0.95000\n",
      "[Test] Step: 45000, acc: 0.73420\n",
      "[Train]: Step: 45100, loss: 0.52377 acc: 0.90000\n",
      "[Train]: Step: 45200, loss: 0.23018 acc: 0.90000\n",
      "[Train]: Step: 45300, loss: 0.07608 acc: 1.00000\n",
      "[Train]: Step: 45400, loss: 0.00413 acc: 1.00000\n",
      "[Train]: Step: 45500, loss: 0.06070 acc: 0.95000\n",
      "[Train]: Step: 45600, loss: 0.05840 acc: 1.00000\n",
      "[Train]: Step: 45700, loss: 0.05929 acc: 1.00000\n",
      "[Train]: Step: 45800, loss: 0.21903 acc: 0.90000\n",
      "[Train]: Step: 45900, loss: 0.04055 acc: 1.00000\n",
      "[Train]: Step: 46000, loss: 0.17584 acc: 0.90000\n",
      "[Test] Step: 46000, acc: 0.74060\n",
      "[Train]: Step: 46100, loss: 0.13979 acc: 0.90000\n",
      "[Train]: Step: 46200, loss: 0.24747 acc: 0.90000\n",
      "[Train]: Step: 46300, loss: 0.29646 acc: 0.90000\n",
      "[Train]: Step: 46400, loss: 0.48731 acc: 0.90000\n",
      "[Train]: Step: 46500, loss: 0.07872 acc: 0.95000\n",
      "[Train]: Step: 46600, loss: 0.22405 acc: 0.95000\n",
      "[Train]: Step: 46700, loss: 0.04474 acc: 0.95000\n",
      "[Train]: Step: 46800, loss: 0.43692 acc: 0.90000\n",
      "[Train]: Step: 46900, loss: 0.02033 acc: 1.00000\n",
      "[Train]: Step: 47000, loss: 0.08504 acc: 1.00000\n",
      "[Test] Step: 47000, acc: 0.74290\n",
      "[Train]: Step: 47100, loss: 0.23284 acc: 0.95000\n",
      "[Train]: Step: 47200, loss: 0.20765 acc: 0.90000\n",
      "[Train]: Step: 47300, loss: 0.15242 acc: 0.90000\n",
      "[Train]: Step: 47400, loss: 0.24830 acc: 0.95000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: Step: 47500, loss: 0.97310 acc: 0.85000\n",
      "[Train]: Step: 47600, loss: 0.11344 acc: 0.90000\n",
      "[Train]: Step: 47700, loss: 0.26020 acc: 0.90000\n",
      "[Train]: Step: 47800, loss: 0.14138 acc: 0.95000\n",
      "[Train]: Step: 47900, loss: 0.16294 acc: 0.95000\n",
      "[Train]: Step: 48000, loss: 0.03038 acc: 1.00000\n",
      "[Test] Step: 48000, acc: 0.74320\n",
      "[Train]: Step: 48100, loss: 0.24302 acc: 0.90000\n",
      "[Train]: Step: 48200, loss: 0.20752 acc: 0.90000\n",
      "[Train]: Step: 48300, loss: 0.00375 acc: 1.00000\n",
      "[Train]: Step: 48400, loss: 0.06774 acc: 1.00000\n",
      "[Train]: Step: 48500, loss: 0.13347 acc: 0.95000\n",
      "[Train]: Step: 48600, loss: 0.05387 acc: 1.00000\n",
      "[Train]: Step: 48700, loss: 0.11546 acc: 0.95000\n",
      "[Train]: Step: 48800, loss: 0.32343 acc: 0.95000\n",
      "[Train]: Step: 48900, loss: 0.05266 acc: 1.00000\n",
      "[Train]: Step: 49000, loss: 0.13650 acc: 0.90000\n",
      "[Test] Step: 49000, acc: 0.74020\n",
      "[Train]: Step: 49100, loss: 0.24465 acc: 0.85000\n",
      "[Train]: Step: 49200, loss: 0.14347 acc: 0.95000\n",
      "[Train]: Step: 49300, loss: 0.00727 acc: 1.00000\n",
      "[Train]: Step: 49400, loss: 0.40760 acc: 0.90000\n",
      "[Train]: Step: 49500, loss: 0.18100 acc: 0.95000\n",
      "[Train]: Step: 49600, loss: 0.01105 acc: 1.00000\n",
      "[Train]: Step: 49700, loss: 0.44281 acc: 0.90000\n",
      "[Train]: Step: 49800, loss: 0.12600 acc: 0.95000\n",
      "[Train]: Step: 49900, loss: 0.39533 acc: 0.90000\n",
      "[Train]: Step: 50000, loss: 0.02661 acc: 1.00000\n",
      "[Test] Step: 50000, acc: 0.74330\n",
      "[Train]: Step: 50100, loss: 0.12522 acc: 0.90000\n",
      "[Train]: Step: 50200, loss: 0.01375 acc: 1.00000\n",
      "[Train]: Step: 50300, loss: 0.94163 acc: 0.90000\n",
      "[Train]: Step: 50400, loss: 0.15899 acc: 0.90000\n",
      "[Train]: Step: 50500, loss: 0.00045 acc: 1.00000\n",
      "[Train]: Step: 50600, loss: 0.15856 acc: 0.90000\n",
      "[Train]: Step: 50700, loss: 0.15885 acc: 0.90000\n",
      "[Train]: Step: 50800, loss: 0.16868 acc: 0.95000\n",
      "[Train]: Step: 50900, loss: 0.05796 acc: 1.00000\n",
      "[Train]: Step: 51000, loss: 0.06681 acc: 1.00000\n",
      "[Test] Step: 51000, acc: 0.73890\n",
      "[Train]: Step: 51100, loss: 0.06437 acc: 0.95000\n",
      "[Train]: Step: 51200, loss: 0.11158 acc: 0.90000\n",
      "[Train]: Step: 51300, loss: 0.32708 acc: 0.95000\n",
      "[Train]: Step: 51400, loss: 0.00579 acc: 1.00000\n",
      "[Train]: Step: 51500, loss: 0.04942 acc: 1.00000\n",
      "[Train]: Step: 51600, loss: 0.22567 acc: 0.90000\n",
      "[Train]: Step: 51700, loss: 0.06853 acc: 0.95000\n",
      "[Train]: Step: 51800, loss: 0.19234 acc: 0.90000\n",
      "[Train]: Step: 51900, loss: 0.03233 acc: 1.00000\n",
      "[Train]: Step: 52000, loss: 0.29991 acc: 0.85000\n",
      "[Test] Step: 52000, acc: 0.74720\n",
      "[Train]: Step: 52100, loss: 0.12279 acc: 0.95000\n",
      "[Train]: Step: 52200, loss: 0.65088 acc: 0.80000\n",
      "[Train]: Step: 52300, loss: 0.09364 acc: 0.95000\n",
      "[Train]: Step: 52400, loss: 0.40133 acc: 0.90000\n",
      "[Train]: Step: 52500, loss: 0.54414 acc: 0.90000\n",
      "[Train]: Step: 52600, loss: 0.09340 acc: 0.95000\n",
      "[Train]: Step: 52700, loss: 0.14967 acc: 0.95000\n",
      "[Train]: Step: 52800, loss: 0.00521 acc: 1.00000\n",
      "[Train]: Step: 52900, loss: 0.63148 acc: 0.90000\n",
      "[Train]: Step: 53000, loss: 0.03649 acc: 1.00000\n",
      "[Test] Step: 53000, acc: 0.73410\n",
      "[Train]: Step: 53100, loss: 0.01546 acc: 1.00000\n",
      "[Train]: Step: 53200, loss: 0.16911 acc: 0.95000\n",
      "[Train]: Step: 53300, loss: 0.03161 acc: 1.00000\n",
      "[Train]: Step: 53400, loss: 0.35506 acc: 0.90000\n",
      "[Train]: Step: 53500, loss: 0.50051 acc: 0.85000\n",
      "[Train]: Step: 53600, loss: 0.02928 acc: 1.00000\n",
      "[Train]: Step: 53700, loss: 0.40612 acc: 0.80000\n",
      "[Train]: Step: 53800, loss: 0.01456 acc: 1.00000\n",
      "[Train]: Step: 53900, loss: 0.16349 acc: 0.90000\n",
      "[Train]: Step: 54000, loss: 0.03960 acc: 1.00000\n",
      "[Test] Step: 54000, acc: 0.72210\n",
      "[Train]: Step: 54100, loss: 0.11100 acc: 0.95000\n",
      "[Train]: Step: 54200, loss: 0.77130 acc: 0.80000\n",
      "[Train]: Step: 54300, loss: 0.15631 acc: 0.90000\n",
      "[Train]: Step: 54400, loss: 0.17513 acc: 0.85000\n",
      "[Train]: Step: 54500, loss: 1.25269 acc: 0.65000\n",
      "[Train]: Step: 54600, loss: 0.06005 acc: 1.00000\n",
      "[Train]: Step: 54700, loss: 0.07156 acc: 1.00000\n",
      "[Train]: Step: 54800, loss: 0.04708 acc: 1.00000\n",
      "[Train]: Step: 54900, loss: 0.03286 acc: 1.00000\n",
      "[Train]: Step: 55000, loss: 0.15564 acc: 0.95000\n",
      "[Test] Step: 55000, acc: 0.74280\n",
      "[Train]: Step: 55100, loss: 0.00650 acc: 1.00000\n",
      "[Train]: Step: 55200, loss: 0.02296 acc: 1.00000\n",
      "[Train]: Step: 55300, loss: 0.05497 acc: 1.00000\n",
      "[Train]: Step: 55400, loss: 0.07819 acc: 0.95000\n",
      "[Train]: Step: 55500, loss: 0.01556 acc: 1.00000\n",
      "[Train]: Step: 55600, loss: 0.01272 acc: 1.00000\n",
      "[Train]: Step: 55700, loss: 0.21544 acc: 0.95000\n",
      "[Train]: Step: 55800, loss: 0.09402 acc: 0.95000\n",
      "[Train]: Step: 55900, loss: 0.01670 acc: 1.00000\n",
      "[Train]: Step: 56000, loss: 0.01095 acc: 1.00000\n",
      "[Test] Step: 56000, acc: 0.74140\n",
      "[Train]: Step: 56100, loss: 0.12574 acc: 0.95000\n",
      "[Train]: Step: 56200, loss: 0.17952 acc: 0.95000\n",
      "[Train]: Step: 56300, loss: 0.03827 acc: 1.00000\n",
      "[Train]: Step: 56400, loss: 0.14712 acc: 0.90000\n",
      "[Train]: Step: 56500, loss: 0.08830 acc: 0.95000\n",
      "[Train]: Step: 56600, loss: 0.07101 acc: 0.95000\n",
      "[Train]: Step: 56700, loss: 0.36248 acc: 0.85000\n",
      "[Train]: Step: 56800, loss: 0.00813 acc: 1.00000\n",
      "[Train]: Step: 56900, loss: 0.29141 acc: 0.90000\n",
      "[Train]: Step: 57000, loss: 0.05057 acc: 1.00000\n",
      "[Test] Step: 57000, acc: 0.73380\n",
      "[Train]: Step: 57100, loss: 0.11240 acc: 0.95000\n",
      "[Train]: Step: 57200, loss: 0.32790 acc: 0.85000\n",
      "[Train]: Step: 57300, loss: 0.14742 acc: 0.95000\n",
      "[Train]: Step: 57400, loss: 0.16860 acc: 0.95000\n",
      "[Train]: Step: 57500, loss: 0.01596 acc: 1.00000\n",
      "[Train]: Step: 57600, loss: 0.05280 acc: 0.95000\n",
      "[Train]: Step: 57700, loss: 0.03521 acc: 1.00000\n",
      "[Train]: Step: 57800, loss: 0.03517 acc: 1.00000\n",
      "[Train]: Step: 57900, loss: 0.02128 acc: 1.00000\n",
      "[Train]: Step: 58000, loss: 0.14646 acc: 0.90000\n",
      "[Test] Step: 58000, acc: 0.73120\n",
      "[Train]: Step: 58100, loss: 0.29584 acc: 0.90000\n",
      "[Train]: Step: 58200, loss: 0.40480 acc: 0.95000\n",
      "[Train]: Step: 58300, loss: 0.02758 acc: 1.00000\n",
      "[Train]: Step: 58400, loss: 0.00223 acc: 1.00000\n",
      "[Train]: Step: 58500, loss: 0.03178 acc: 1.00000\n",
      "[Train]: Step: 58600, loss: 0.04812 acc: 0.95000\n",
      "[Train]: Step: 58700, loss: 0.01886 acc: 1.00000\n",
      "[Train]: Step: 58800, loss: 0.47747 acc: 0.80000\n",
      "[Train]: Step: 58900, loss: 0.45256 acc: 0.85000\n",
      "[Train]: Step: 59000, loss: 0.10398 acc: 0.95000\n",
      "[Test] Step: 59000, acc: 0.73750\n",
      "[Train]: Step: 59100, loss: 0.06605 acc: 0.95000\n",
      "[Train]: Step: 59200, loss: 0.14978 acc: 0.85000\n",
      "[Train]: Step: 59300, loss: 0.24068 acc: 0.95000\n",
      "[Train]: Step: 59400, loss: 0.05914 acc: 0.95000\n",
      "[Train]: Step: 59500, loss: 0.13321 acc: 0.95000\n",
      "[Train]: Step: 59600, loss: 0.21846 acc: 0.85000\n",
      "[Train]: Step: 59700, loss: 0.09481 acc: 0.95000\n",
      "[Train]: Step: 59800, loss: 0.27896 acc: 0.90000\n",
      "[Train]: Step: 59900, loss: 0.01334 acc: 1.00000\n",
      "[Train]: Step: 60000, loss: 0.16563 acc: 0.90000\n",
      "[Test] Step: 60000, acc: 0.73550\n",
      "[Train]: Step: 60100, loss: 0.11997 acc: 0.95000\n",
      "[Train]: Step: 60200, loss: 0.01615 acc: 1.00000\n",
      "[Train]: Step: 60300, loss: 0.05668 acc: 0.95000\n",
      "[Train]: Step: 60400, loss: 0.00319 acc: 1.00000\n",
      "[Train]: Step: 60500, loss: 0.09257 acc: 0.90000\n",
      "[Train]: Step: 60600, loss: 0.01657 acc: 1.00000\n",
      "[Train]: Step: 60700, loss: 0.07683 acc: 1.00000\n",
      "[Train]: Step: 60800, loss: 0.01912 acc: 1.00000\n",
      "[Train]: Step: 60900, loss: 0.03696 acc: 1.00000\n",
      "[Train]: Step: 61000, loss: 0.04268 acc: 0.95000\n",
      "[Test] Step: 61000, acc: 0.73180\n",
      "[Train]: Step: 61100, loss: 0.54595 acc: 0.90000\n",
      "[Train]: Step: 61200, loss: 0.44253 acc: 0.90000\n",
      "[Train]: Step: 61300, loss: 0.03482 acc: 1.00000\n",
      "[Train]: Step: 61400, loss: 0.43892 acc: 0.90000\n",
      "[Train]: Step: 61500, loss: 0.03189 acc: 1.00000\n",
      "[Train]: Step: 61600, loss: 0.06010 acc: 0.95000\n",
      "[Train]: Step: 61700, loss: 0.39081 acc: 0.85000\n",
      "[Train]: Step: 61800, loss: 0.27373 acc: 0.90000\n",
      "[Train]: Step: 61900, loss: 0.00242 acc: 1.00000\n",
      "[Train]: Step: 62000, loss: 0.00295 acc: 1.00000\n",
      "[Test] Step: 62000, acc: 0.74130\n",
      "[Train]: Step: 62100, loss: 0.05465 acc: 0.95000\n",
      "[Train]: Step: 62200, loss: 0.37659 acc: 0.85000\n",
      "[Train]: Step: 62300, loss: 0.16052 acc: 0.90000\n",
      "[Train]: Step: 62400, loss: 0.05565 acc: 1.00000\n",
      "[Train]: Step: 62500, loss: 0.15215 acc: 0.95000\n",
      "[Train]: Step: 62600, loss: 0.08235 acc: 0.95000\n",
      "[Train]: Step: 62700, loss: 0.00786 acc: 1.00000\n",
      "[Train]: Step: 62800, loss: 0.14219 acc: 0.95000\n",
      "[Train]: Step: 62900, loss: 0.08560 acc: 0.95000\n",
      "[Train]: Step: 63000, loss: 0.39048 acc: 0.85000\n",
      "[Test] Step: 63000, acc: 0.74050\n",
      "[Train]: Step: 63100, loss: 0.00103 acc: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: Step: 63200, loss: 0.10469 acc: 0.95000\n",
      "[Train]: Step: 63300, loss: 0.00556 acc: 1.00000\n",
      "[Train]: Step: 63400, loss: 0.17113 acc: 0.90000\n",
      "[Train]: Step: 63500, loss: 0.15126 acc: 0.95000\n",
      "[Train]: Step: 63600, loss: 0.04637 acc: 0.95000\n",
      "[Train]: Step: 63700, loss: 0.01406 acc: 1.00000\n",
      "[Train]: Step: 63800, loss: 0.00060 acc: 1.00000\n",
      "[Train]: Step: 63900, loss: 0.21459 acc: 0.95000\n",
      "[Train]: Step: 64000, loss: 0.32493 acc: 0.95000\n",
      "[Test] Step: 64000, acc: 0.73190\n",
      "[Train]: Step: 64100, loss: 0.06951 acc: 0.95000\n",
      "[Train]: Step: 64200, loss: 0.05182 acc: 0.95000\n",
      "[Train]: Step: 64300, loss: 0.00055 acc: 1.00000\n",
      "[Train]: Step: 64400, loss: 0.01372 acc: 1.00000\n",
      "[Train]: Step: 64500, loss: 0.07308 acc: 0.95000\n",
      "[Train]: Step: 64600, loss: 0.09286 acc: 0.95000\n",
      "[Train]: Step: 64700, loss: 0.13575 acc: 0.90000\n",
      "[Train]: Step: 64800, loss: 0.04376 acc: 0.95000\n",
      "[Train]: Step: 64900, loss: 0.00543 acc: 1.00000\n",
      "[Train]: Step: 65000, loss: 0.03476 acc: 1.00000\n",
      "[Test] Step: 65000, acc: 0.73910\n",
      "[Train]: Step: 65100, loss: 0.42266 acc: 0.90000\n",
      "[Train]: Step: 65200, loss: 0.14637 acc: 0.95000\n",
      "[Train]: Step: 65300, loss: 0.00019 acc: 1.00000\n",
      "[Train]: Step: 65400, loss: 0.11821 acc: 0.90000\n",
      "[Train]: Step: 65500, loss: 0.00489 acc: 1.00000\n",
      "[Train]: Step: 65600, loss: 0.28467 acc: 0.85000\n",
      "[Train]: Step: 65700, loss: 0.06146 acc: 0.95000\n",
      "[Train]: Step: 65800, loss: 0.52166 acc: 0.95000\n",
      "[Train]: Step: 65900, loss: 0.26197 acc: 0.95000\n",
      "[Train]: Step: 66000, loss: 0.19067 acc: 0.95000\n",
      "[Test] Step: 66000, acc: 0.73380\n",
      "[Train]: Step: 66100, loss: 0.25960 acc: 0.95000\n",
      "[Train]: Step: 66200, loss: 0.00337 acc: 1.00000\n",
      "[Train]: Step: 66300, loss: 0.29608 acc: 0.85000\n",
      "[Train]: Step: 66400, loss: 0.01805 acc: 1.00000\n",
      "[Train]: Step: 66500, loss: 0.00938 acc: 1.00000\n",
      "[Train]: Step: 66600, loss: 0.27604 acc: 0.95000\n",
      "[Train]: Step: 66700, loss: 0.26091 acc: 0.90000\n",
      "[Train]: Step: 66800, loss: 0.33879 acc: 0.90000\n",
      "[Train]: Step: 66900, loss: 0.24224 acc: 0.90000\n",
      "[Train]: Step: 67000, loss: 0.03460 acc: 1.00000\n",
      "[Test] Step: 67000, acc: 0.72870\n",
      "[Train]: Step: 67100, loss: 0.07676 acc: 0.95000\n",
      "[Train]: Step: 67200, loss: 0.00177 acc: 1.00000\n",
      "[Train]: Step: 67300, loss: 0.15010 acc: 0.90000\n",
      "[Train]: Step: 67400, loss: 0.04588 acc: 1.00000\n",
      "[Train]: Step: 67500, loss: 0.39301 acc: 0.90000\n",
      "[Train]: Step: 67600, loss: 0.03218 acc: 1.00000\n",
      "[Train]: Step: 67700, loss: 0.07275 acc: 0.95000\n",
      "[Train]: Step: 67800, loss: 0.13055 acc: 0.90000\n",
      "[Train]: Step: 67900, loss: 0.14304 acc: 0.95000\n",
      "[Train]: Step: 68000, loss: 0.10552 acc: 0.95000\n",
      "[Test] Step: 68000, acc: 0.74020\n",
      "[Train]: Step: 68100, loss: 0.00138 acc: 1.00000\n",
      "[Train]: Step: 68200, loss: 0.05505 acc: 0.95000\n",
      "[Train]: Step: 68300, loss: 0.01634 acc: 1.00000\n",
      "[Train]: Step: 68400, loss: 0.56528 acc: 0.85000\n",
      "[Train]: Step: 68500, loss: 0.05043 acc: 1.00000\n",
      "[Train]: Step: 68600, loss: 0.03369 acc: 1.00000\n",
      "[Train]: Step: 68700, loss: 0.01874 acc: 1.00000\n",
      "[Train]: Step: 68800, loss: 0.01634 acc: 1.00000\n",
      "[Train]: Step: 68900, loss: 0.00495 acc: 1.00000\n",
      "[Train]: Step: 69000, loss: 0.00142 acc: 1.00000\n",
      "[Test] Step: 69000, acc: 0.73050\n",
      "[Train]: Step: 69100, loss: 0.00360 acc: 1.00000\n",
      "[Train]: Step: 69200, loss: 0.45091 acc: 0.90000\n",
      "[Train]: Step: 69300, loss: 0.24124 acc: 0.95000\n",
      "[Train]: Step: 69400, loss: 0.04962 acc: 0.95000\n",
      "[Train]: Step: 69500, loss: 0.25860 acc: 0.85000\n",
      "[Train]: Step: 69600, loss: 0.01630 acc: 1.00000\n",
      "[Train]: Step: 69700, loss: 0.17312 acc: 0.95000\n",
      "[Train]: Step: 69800, loss: 0.21055 acc: 0.90000\n",
      "[Train]: Step: 69900, loss: 0.47951 acc: 0.90000\n",
      "[Train]: Step: 70000, loss: 0.29615 acc: 0.90000\n",
      "[Test] Step: 70000, acc: 0.73140\n",
      "[Train]: Step: 70100, loss: 0.00248 acc: 1.00000\n",
      "[Train]: Step: 70200, loss: 0.18571 acc: 0.90000\n",
      "[Train]: Step: 70300, loss: 0.13157 acc: 0.90000\n",
      "[Train]: Step: 70400, loss: 0.00535 acc: 1.00000\n",
      "[Train]: Step: 70500, loss: 0.00428 acc: 1.00000\n",
      "[Train]: Step: 70600, loss: 0.57155 acc: 0.85000\n",
      "[Train]: Step: 70700, loss: 0.00135 acc: 1.00000\n",
      "[Train]: Step: 70800, loss: 0.45856 acc: 0.90000\n",
      "[Train]: Step: 70900, loss: 0.08233 acc: 0.95000\n",
      "[Train]: Step: 71000, loss: 0.01592 acc: 1.00000\n",
      "[Test] Step: 71000, acc: 0.73800\n",
      "[Train]: Step: 71100, loss: 0.13967 acc: 0.95000\n",
      "[Train]: Step: 71200, loss: 0.15817 acc: 0.95000\n",
      "[Train]: Step: 71300, loss: 0.06063 acc: 1.00000\n",
      "[Train]: Step: 71400, loss: 0.01766 acc: 1.00000\n",
      "[Train]: Step: 71500, loss: 0.07003 acc: 0.95000\n",
      "[Train]: Step: 71600, loss: 0.09577 acc: 0.95000\n",
      "[Train]: Step: 71700, loss: 0.21939 acc: 0.90000\n",
      "[Train]: Step: 71800, loss: 0.07684 acc: 0.95000\n",
      "[Train]: Step: 71900, loss: 0.35875 acc: 0.90000\n",
      "[Train]: Step: 72000, loss: 0.10541 acc: 0.95000\n",
      "[Test] Step: 72000, acc: 0.74010\n",
      "[Train]: Step: 72100, loss: 0.02172 acc: 1.00000\n",
      "[Train]: Step: 72200, loss: 0.00856 acc: 1.00000\n",
      "[Train]: Step: 72300, loss: 0.00670 acc: 1.00000\n",
      "[Train]: Step: 72400, loss: 0.14519 acc: 0.95000\n",
      "[Train]: Step: 72500, loss: 0.18721 acc: 0.95000\n",
      "[Train]: Step: 72600, loss: 0.02960 acc: 1.00000\n",
      "[Train]: Step: 72700, loss: 0.03300 acc: 1.00000\n",
      "[Train]: Step: 72800, loss: 0.09995 acc: 0.90000\n",
      "[Train]: Step: 72900, loss: 0.03021 acc: 1.00000\n",
      "[Train]: Step: 73000, loss: 0.03345 acc: 1.00000\n",
      "[Test] Step: 73000, acc: 0.73240\n",
      "[Train]: Step: 73100, loss: 0.04300 acc: 1.00000\n",
      "[Train]: Step: 73200, loss: 0.01620 acc: 1.00000\n",
      "[Train]: Step: 73300, loss: 0.01665 acc: 1.00000\n",
      "[Train]: Step: 73400, loss: 0.00604 acc: 1.00000\n",
      "[Train]: Step: 73500, loss: 0.00986 acc: 1.00000\n",
      "[Train]: Step: 73600, loss: 0.02992 acc: 1.00000\n",
      "[Train]: Step: 73700, loss: 0.00227 acc: 1.00000\n",
      "[Train]: Step: 73800, loss: 0.01427 acc: 1.00000\n",
      "[Train]: Step: 73900, loss: 0.07388 acc: 0.95000\n",
      "[Train]: Step: 74000, loss: 0.76374 acc: 0.90000\n",
      "[Test] Step: 74000, acc: 0.73920\n",
      "[Train]: Step: 74100, loss: 0.48608 acc: 0.75000\n",
      "[Train]: Step: 74200, loss: 0.13031 acc: 0.95000\n",
      "[Train]: Step: 74300, loss: 0.19028 acc: 0.90000\n",
      "[Train]: Step: 74400, loss: 0.07382 acc: 0.95000\n",
      "[Train]: Step: 74500, loss: 0.03367 acc: 1.00000\n",
      "[Train]: Step: 74600, loss: 0.09615 acc: 0.95000\n",
      "[Train]: Step: 74700, loss: 0.02902 acc: 1.00000\n",
      "[Train]: Step: 74800, loss: 0.56293 acc: 0.85000\n",
      "[Train]: Step: 74900, loss: 0.59377 acc: 0.85000\n",
      "[Train]: Step: 75000, loss: 0.21317 acc: 0.90000\n",
      "[Test] Step: 75000, acc: 0.73760\n",
      "[Train]: Step: 75100, loss: 0.01025 acc: 1.00000\n",
      "[Train]: Step: 75200, loss: 0.63490 acc: 0.90000\n",
      "[Train]: Step: 75300, loss: 0.06527 acc: 0.95000\n",
      "[Train]: Step: 75400, loss: 0.27031 acc: 0.90000\n",
      "[Train]: Step: 75500, loss: 0.30472 acc: 0.90000\n",
      "[Train]: Step: 75600, loss: 0.05495 acc: 0.95000\n",
      "[Train]: Step: 75700, loss: 0.07964 acc: 0.95000\n",
      "[Train]: Step: 75800, loss: 0.11894 acc: 0.95000\n",
      "[Train]: Step: 75900, loss: 0.00486 acc: 1.00000\n",
      "[Train]: Step: 76000, loss: 0.14803 acc: 0.90000\n",
      "[Test] Step: 76000, acc: 0.73780\n",
      "[Train]: Step: 76100, loss: 0.20943 acc: 0.90000\n",
      "[Train]: Step: 76200, loss: 0.20926 acc: 0.90000\n",
      "[Train]: Step: 76300, loss: 0.17381 acc: 0.90000\n",
      "[Train]: Step: 76400, loss: 0.29091 acc: 0.95000\n",
      "[Train]: Step: 76500, loss: 0.03089 acc: 1.00000\n",
      "[Train]: Step: 76600, loss: 0.50051 acc: 0.95000\n",
      "[Train]: Step: 76700, loss: 0.13449 acc: 0.95000\n",
      "[Train]: Step: 76800, loss: 0.16772 acc: 0.95000\n",
      "[Train]: Step: 76900, loss: 0.05107 acc: 1.00000\n",
      "[Train]: Step: 77000, loss: 0.12198 acc: 0.95000\n",
      "[Test] Step: 77000, acc: 0.73920\n",
      "[Train]: Step: 77100, loss: 0.04836 acc: 0.95000\n",
      "[Train]: Step: 77200, loss: 0.02666 acc: 1.00000\n",
      "[Train]: Step: 77300, loss: 0.03230 acc: 1.00000\n",
      "[Train]: Step: 77400, loss: 0.00400 acc: 1.00000\n",
      "[Train]: Step: 77500, loss: 0.01297 acc: 1.00000\n",
      "[Train]: Step: 77600, loss: 0.28936 acc: 0.90000\n",
      "[Train]: Step: 77700, loss: 0.00394 acc: 1.00000\n",
      "[Train]: Step: 77800, loss: 0.32482 acc: 0.95000\n",
      "[Train]: Step: 77900, loss: 0.00501 acc: 1.00000\n",
      "[Train]: Step: 78000, loss: 0.03590 acc: 0.95000\n",
      "[Test] Step: 78000, acc: 0.73600\n",
      "[Train]: Step: 78100, loss: 0.00518 acc: 1.00000\n",
      "[Train]: Step: 78200, loss: 0.14687 acc: 0.95000\n",
      "[Train]: Step: 78300, loss: 0.09846 acc: 0.95000\n",
      "[Train]: Step: 78400, loss: 0.01555 acc: 1.00000\n",
      "[Train]: Step: 78500, loss: 0.00254 acc: 1.00000\n",
      "[Train]: Step: 78600, loss: 0.01301 acc: 1.00000\n",
      "[Train]: Step: 78700, loss: 0.05065 acc: 0.95000\n",
      "[Train]: Step: 78800, loss: 0.37772 acc: 0.95000\n",
      "[Train]: Step: 78900, loss: 0.00132 acc: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: Step: 79000, loss: 0.04575 acc: 0.95000\n",
      "[Test] Step: 79000, acc: 0.72720\n",
      "[Train]: Step: 79100, loss: 0.19977 acc: 0.90000\n",
      "[Train]: Step: 79200, loss: 0.03022 acc: 1.00000\n",
      "[Train]: Step: 79300, loss: 0.00012 acc: 1.00000\n",
      "[Train]: Step: 79400, loss: 0.01084 acc: 1.00000\n",
      "[Train]: Step: 79500, loss: 0.00914 acc: 1.00000\n",
      "[Train]: Step: 79600, loss: 0.47037 acc: 0.90000\n",
      "[Train]: Step: 79700, loss: 0.00545 acc: 1.00000\n",
      "[Train]: Step: 79800, loss: 0.11369 acc: 0.95000\n",
      "[Train]: Step: 79900, loss: 0.19971 acc: 0.90000\n",
      "[Train]: Step: 80000, loss: 0.00766 acc: 1.00000\n",
      "[Test] Step: 80000, acc: 0.73370\n",
      "[Train]: Step: 80100, loss: 0.00348 acc: 1.00000\n",
      "[Train]: Step: 80200, loss: 0.31459 acc: 0.90000\n",
      "[Train]: Step: 80300, loss: 0.00487 acc: 1.00000\n",
      "[Train]: Step: 80400, loss: 0.00457 acc: 1.00000\n",
      "[Train]: Step: 80500, loss: 0.00105 acc: 1.00000\n",
      "[Train]: Step: 80600, loss: 0.52407 acc: 0.95000\n",
      "[Train]: Step: 80700, loss: 0.23573 acc: 0.90000\n",
      "[Train]: Step: 80800, loss: 0.00357 acc: 1.00000\n",
      "[Train]: Step: 80900, loss: 0.17309 acc: 0.95000\n",
      "[Train]: Step: 81000, loss: 0.21340 acc: 0.95000\n",
      "[Test] Step: 81000, acc: 0.74130\n",
      "[Train]: Step: 81100, loss: 0.03850 acc: 1.00000\n",
      "[Train]: Step: 81200, loss: 0.00356 acc: 1.00000\n",
      "[Train]: Step: 81300, loss: 0.00004 acc: 1.00000\n",
      "[Train]: Step: 81400, loss: 0.00438 acc: 1.00000\n",
      "[Train]: Step: 81500, loss: 0.07258 acc: 0.95000\n",
      "[Train]: Step: 81600, loss: 0.00633 acc: 1.00000\n",
      "[Train]: Step: 81700, loss: 0.19605 acc: 0.90000\n",
      "[Train]: Step: 81800, loss: 0.00418 acc: 1.00000\n",
      "[Train]: Step: 81900, loss: 0.09418 acc: 0.95000\n",
      "[Train]: Step: 82000, loss: 0.05549 acc: 0.95000\n",
      "[Test] Step: 82000, acc: 0.73410\n",
      "[Train]: Step: 82100, loss: 0.02751 acc: 1.00000\n",
      "[Train]: Step: 82200, loss: 0.18307 acc: 0.90000\n",
      "[Train]: Step: 82300, loss: 0.04087 acc: 1.00000\n",
      "[Train]: Step: 82400, loss: 0.30764 acc: 0.95000\n",
      "[Train]: Step: 82500, loss: 0.12803 acc: 0.95000\n",
      "[Train]: Step: 82600, loss: 0.21152 acc: 0.90000\n",
      "[Train]: Step: 82700, loss: 0.00390 acc: 1.00000\n",
      "[Train]: Step: 82800, loss: 0.09271 acc: 0.95000\n",
      "[Train]: Step: 82900, loss: 0.00042 acc: 1.00000\n",
      "[Train]: Step: 83000, loss: 0.43620 acc: 0.95000\n",
      "[Test] Step: 83000, acc: 0.73540\n",
      "[Train]: Step: 83100, loss: 0.01571 acc: 1.00000\n",
      "[Train]: Step: 83200, loss: 0.00320 acc: 1.00000\n",
      "[Train]: Step: 83300, loss: 0.00139 acc: 1.00000\n",
      "[Train]: Step: 83400, loss: 0.02123 acc: 1.00000\n",
      "[Train]: Step: 83500, loss: 0.08356 acc: 0.95000\n",
      "[Train]: Step: 83600, loss: 0.01914 acc: 1.00000\n",
      "[Train]: Step: 83700, loss: 0.17274 acc: 0.95000\n",
      "[Train]: Step: 83800, loss: 0.17414 acc: 0.90000\n",
      "[Train]: Step: 83900, loss: 0.01674 acc: 1.00000\n",
      "[Train]: Step: 84000, loss: 0.14666 acc: 0.95000\n",
      "[Test] Step: 84000, acc: 0.72630\n",
      "[Train]: Step: 84100, loss: 0.09173 acc: 0.95000\n",
      "[Train]: Step: 84200, loss: 0.32660 acc: 0.85000\n",
      "[Train]: Step: 84300, loss: 0.13383 acc: 0.95000\n",
      "[Train]: Step: 84400, loss: 0.11835 acc: 0.95000\n",
      "[Train]: Step: 84500, loss: 0.18347 acc: 0.90000\n",
      "[Train]: Step: 84600, loss: 0.00118 acc: 1.00000\n",
      "[Train]: Step: 84700, loss: 0.37683 acc: 0.95000\n",
      "[Train]: Step: 84800, loss: 0.06316 acc: 0.95000\n",
      "[Train]: Step: 84900, loss: 0.01854 acc: 1.00000\n",
      "[Train]: Step: 85000, loss: 0.96294 acc: 0.85000\n",
      "[Test] Step: 85000, acc: 0.73120\n",
      "[Train]: Step: 85100, loss: 0.10652 acc: 0.95000\n",
      "[Train]: Step: 85200, loss: 0.05809 acc: 0.95000\n",
      "[Train]: Step: 85300, loss: 0.05450 acc: 0.95000\n",
      "[Train]: Step: 85400, loss: 0.09381 acc: 0.95000\n",
      "[Train]: Step: 85500, loss: 0.00875 acc: 1.00000\n",
      "[Train]: Step: 85600, loss: 0.24980 acc: 0.90000\n",
      "[Train]: Step: 85700, loss: 0.17722 acc: 0.90000\n",
      "[Train]: Step: 85800, loss: 0.08844 acc: 0.95000\n",
      "[Train]: Step: 85900, loss: 0.13558 acc: 0.95000\n",
      "[Train]: Step: 86000, loss: 0.00573 acc: 1.00000\n",
      "[Test] Step: 86000, acc: 0.73510\n",
      "[Train]: Step: 86100, loss: 0.13616 acc: 0.90000\n",
      "[Train]: Step: 86200, loss: 0.32905 acc: 0.90000\n",
      "[Train]: Step: 86300, loss: 0.22197 acc: 0.95000\n",
      "[Train]: Step: 86400, loss: 0.03333 acc: 1.00000\n",
      "[Train]: Step: 86500, loss: 0.00622 acc: 1.00000\n",
      "[Train]: Step: 86600, loss: 0.12662 acc: 0.95000\n",
      "[Train]: Step: 86700, loss: 0.00468 acc: 1.00000\n",
      "[Train]: Step: 86800, loss: 1.08550 acc: 0.90000\n",
      "[Train]: Step: 86900, loss: 0.15332 acc: 0.95000\n",
      "[Train]: Step: 87000, loss: 0.04069 acc: 1.00000\n",
      "[Test] Step: 87000, acc: 0.73490\n",
      "[Train]: Step: 87100, loss: 0.54359 acc: 0.90000\n",
      "[Train]: Step: 87200, loss: 0.00234 acc: 1.00000\n",
      "[Train]: Step: 87300, loss: 0.01733 acc: 1.00000\n",
      "[Train]: Step: 87400, loss: 0.00695 acc: 1.00000\n",
      "[Train]: Step: 87500, loss: 0.07605 acc: 0.95000\n",
      "[Train]: Step: 87600, loss: 0.08781 acc: 0.95000\n",
      "[Train]: Step: 87700, loss: 0.00949 acc: 1.00000\n",
      "[Train]: Step: 87800, loss: 0.02308 acc: 1.00000\n",
      "[Train]: Step: 87900, loss: 0.00805 acc: 1.00000\n",
      "[Train]: Step: 88000, loss: 0.01923 acc: 1.00000\n",
      "[Test] Step: 88000, acc: 0.73210\n",
      "[Train]: Step: 88100, loss: 0.00575 acc: 1.00000\n",
      "[Train]: Step: 88200, loss: 0.21963 acc: 0.95000\n",
      "[Train]: Step: 88300, loss: 0.11170 acc: 0.95000\n",
      "[Train]: Step: 88400, loss: 0.18921 acc: 0.95000\n",
      "[Train]: Step: 88500, loss: 0.08420 acc: 0.95000\n",
      "[Train]: Step: 88600, loss: 0.00095 acc: 1.00000\n",
      "[Train]: Step: 88700, loss: 0.40142 acc: 0.90000\n",
      "[Train]: Step: 88800, loss: 0.01627 acc: 1.00000\n",
      "[Train]: Step: 88900, loss: 0.11769 acc: 0.95000\n",
      "[Train]: Step: 89000, loss: 0.06492 acc: 1.00000\n",
      "[Test] Step: 89000, acc: 0.73310\n",
      "[Train]: Step: 89100, loss: 0.00024 acc: 1.00000\n",
      "[Train]: Step: 89200, loss: 0.01018 acc: 1.00000\n",
      "[Train]: Step: 89300, loss: 0.69593 acc: 0.85000\n",
      "[Train]: Step: 89400, loss: 0.01727 acc: 1.00000\n",
      "[Train]: Step: 89500, loss: 0.00936 acc: 1.00000\n",
      "[Train]: Step: 89600, loss: 0.14377 acc: 0.90000\n",
      "[Train]: Step: 89700, loss: 0.40187 acc: 0.90000\n",
      "[Train]: Step: 89800, loss: 0.09592 acc: 0.90000\n",
      "[Train]: Step: 89900, loss: 0.28554 acc: 0.90000\n",
      "[Train]: Step: 90000, loss: 0.10909 acc: 0.95000\n",
      "[Test] Step: 90000, acc: 0.73510\n",
      "[Train]: Step: 90100, loss: 0.00641 acc: 1.00000\n",
      "[Train]: Step: 90200, loss: 0.01393 acc: 1.00000\n",
      "[Train]: Step: 90300, loss: 0.20039 acc: 0.85000\n",
      "[Train]: Step: 90400, loss: 0.04692 acc: 0.95000\n",
      "[Train]: Step: 90500, loss: 0.17003 acc: 0.95000\n",
      "[Train]: Step: 90600, loss: 0.00852 acc: 1.00000\n",
      "[Train]: Step: 90700, loss: 0.00511 acc: 1.00000\n",
      "[Train]: Step: 90800, loss: 0.81958 acc: 0.80000\n",
      "[Train]: Step: 90900, loss: 0.04642 acc: 1.00000\n",
      "[Train]: Step: 91000, loss: 0.04608 acc: 0.95000\n",
      "[Test] Step: 91000, acc: 0.74560\n",
      "[Train]: Step: 91100, loss: 0.03953 acc: 0.95000\n",
      "[Train]: Step: 91200, loss: 0.46933 acc: 0.90000\n",
      "[Train]: Step: 91300, loss: 0.00356 acc: 1.00000\n",
      "[Train]: Step: 91400, loss: 0.33168 acc: 0.85000\n",
      "[Train]: Step: 91500, loss: 0.15938 acc: 0.95000\n",
      "[Train]: Step: 91600, loss: 0.61582 acc: 0.90000\n",
      "[Train]: Step: 91700, loss: 0.05766 acc: 0.95000\n",
      "[Train]: Step: 91800, loss: 0.00191 acc: 1.00000\n",
      "[Train]: Step: 91900, loss: 0.02924 acc: 1.00000\n",
      "[Train]: Step: 92000, loss: 0.24252 acc: 0.90000\n",
      "[Test] Step: 92000, acc: 0.72790\n",
      "[Train]: Step: 92100, loss: 0.02839 acc: 1.00000\n",
      "[Train]: Step: 92200, loss: 0.02738 acc: 1.00000\n",
      "[Train]: Step: 92300, loss: 0.01791 acc: 1.00000\n",
      "[Train]: Step: 92400, loss: 0.02279 acc: 1.00000\n",
      "[Train]: Step: 92500, loss: 0.00084 acc: 1.00000\n",
      "[Train]: Step: 92600, loss: 0.24512 acc: 0.90000\n",
      "[Train]: Step: 92700, loss: 0.31717 acc: 0.95000\n",
      "[Train]: Step: 92800, loss: 0.00027 acc: 1.00000\n",
      "[Train]: Step: 92900, loss: 0.00371 acc: 1.00000\n",
      "[Train]: Step: 93000, loss: 0.00558 acc: 1.00000\n",
      "[Test] Step: 93000, acc: 0.73000\n",
      "[Train]: Step: 93100, loss: 0.07257 acc: 0.95000\n",
      "[Train]: Step: 93200, loss: 0.10908 acc: 0.95000\n",
      "[Train]: Step: 93300, loss: 0.18814 acc: 0.95000\n",
      "[Train]: Step: 93400, loss: 0.01154 acc: 1.00000\n",
      "[Train]: Step: 93500, loss: 0.20419 acc: 0.95000\n",
      "[Train]: Step: 93600, loss: 0.19625 acc: 0.95000\n",
      "[Train]: Step: 93700, loss: 0.15701 acc: 0.90000\n",
      "[Train]: Step: 93800, loss: 0.43700 acc: 0.90000\n",
      "[Train]: Step: 93900, loss: 0.00016 acc: 1.00000\n",
      "[Train]: Step: 94000, loss: 0.01796 acc: 1.00000\n",
      "[Test] Step: 94000, acc: 0.73360\n",
      "[Train]: Step: 94100, loss: 0.18721 acc: 0.90000\n",
      "[Train]: Step: 94200, loss: 0.61966 acc: 0.90000\n",
      "[Train]: Step: 94300, loss: 0.10586 acc: 0.95000\n",
      "[Train]: Step: 94400, loss: 0.00108 acc: 1.00000\n",
      "[Train]: Step: 94500, loss: 0.24497 acc: 0.90000\n",
      "[Train]: Step: 94600, loss: 0.08436 acc: 0.95000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: Step: 94700, loss: 0.38994 acc: 0.90000\n",
      "[Train]: Step: 94800, loss: 0.12283 acc: 0.95000\n",
      "[Train]: Step: 94900, loss: 0.00320 acc: 1.00000\n",
      "[Train]: Step: 95000, loss: 0.00432 acc: 1.00000\n",
      "[Test] Step: 95000, acc: 0.73480\n",
      "[Train]: Step: 95100, loss: 0.06446 acc: 0.95000\n",
      "[Train]: Step: 95200, loss: 0.00693 acc: 1.00000\n",
      "[Train]: Step: 95300, loss: 0.08701 acc: 0.95000\n",
      "[Train]: Step: 95400, loss: 0.08516 acc: 0.95000\n",
      "[Train]: Step: 95500, loss: 0.05606 acc: 0.95000\n",
      "[Train]: Step: 95600, loss: 0.81537 acc: 0.90000\n",
      "[Train]: Step: 95700, loss: 0.19392 acc: 0.90000\n",
      "[Train]: Step: 95800, loss: 0.01501 acc: 1.00000\n",
      "[Train]: Step: 95900, loss: 0.05183 acc: 0.95000\n",
      "[Train]: Step: 96000, loss: 0.13477 acc: 0.95000\n",
      "[Test] Step: 96000, acc: 0.73560\n",
      "[Train]: Step: 96100, loss: 0.00002 acc: 1.00000\n",
      "[Train]: Step: 96200, loss: 0.36526 acc: 0.90000\n",
      "[Train]: Step: 96300, loss: 0.00528 acc: 1.00000\n",
      "[Train]: Step: 96400, loss: 0.20971 acc: 0.90000\n",
      "[Train]: Step: 96500, loss: 0.02321 acc: 1.00000\n",
      "[Train]: Step: 96600, loss: 0.06866 acc: 0.95000\n",
      "[Train]: Step: 96700, loss: 0.04163 acc: 1.00000\n",
      "[Train]: Step: 96800, loss: 0.02648 acc: 1.00000\n",
      "[Train]: Step: 96900, loss: 0.09364 acc: 0.95000\n",
      "[Train]: Step: 97000, loss: 0.12618 acc: 0.95000\n",
      "[Test] Step: 97000, acc: 0.73510\n",
      "[Train]: Step: 97100, loss: 0.03714 acc: 0.95000\n",
      "[Train]: Step: 97200, loss: 0.11712 acc: 0.95000\n",
      "[Train]: Step: 97300, loss: 0.40552 acc: 0.95000\n",
      "[Train]: Step: 97400, loss: 0.03309 acc: 1.00000\n",
      "[Train]: Step: 97500, loss: 0.25613 acc: 0.90000\n",
      "[Train]: Step: 97600, loss: 0.02239 acc: 1.00000\n",
      "[Train]: Step: 97700, loss: 0.00346 acc: 1.00000\n",
      "[Train]: Step: 97800, loss: 0.21495 acc: 0.95000\n",
      "[Train]: Step: 97900, loss: 0.02281 acc: 1.00000\n",
      "[Train]: Step: 98000, loss: 0.01228 acc: 1.00000\n",
      "[Test] Step: 98000, acc: 0.73810\n",
      "[Train]: Step: 98100, loss: 0.00048 acc: 1.00000\n",
      "[Train]: Step: 98200, loss: 0.05530 acc: 0.95000\n",
      "[Train]: Step: 98300, loss: 0.06108 acc: 0.95000\n",
      "[Train]: Step: 98400, loss: 0.02613 acc: 1.00000\n",
      "[Train]: Step: 98500, loss: 0.12483 acc: 0.95000\n",
      "[Train]: Step: 98600, loss: 0.32557 acc: 0.85000\n",
      "[Train]: Step: 98700, loss: 0.10238 acc: 0.95000\n",
      "[Train]: Step: 98800, loss: 0.00350 acc: 1.00000\n",
      "[Train]: Step: 98900, loss: 0.39319 acc: 0.90000\n",
      "[Train]: Step: 99000, loss: 0.22471 acc: 0.95000\n",
      "[Test] Step: 99000, acc: 0.74050\n",
      "[Train]: Step: 99100, loss: 0.03955 acc: 0.95000\n",
      "[Train]: Step: 99200, loss: 0.00048 acc: 1.00000\n",
      "[Train]: Step: 99300, loss: 0.38111 acc: 0.95000\n",
      "[Train]: Step: 99400, loss: 0.07359 acc: 1.00000\n",
      "[Train]: Step: 99500, loss: 0.12059 acc: 0.95000\n",
      "[Train]: Step: 99600, loss: 0.33104 acc: 0.95000\n",
      "[Train]: Step: 99700, loss: 0.06665 acc: 0.95000\n",
      "[Train]: Step: 99800, loss: 0.76762 acc: 0.90000\n",
      "[Train]: Step: 99900, loss: 0.00897 acc: 1.00000\n",
      "[Train]: Step: 100000, loss: 0.01922 acc: 1.00000\n",
      "[Test] Step: 100000, acc: 0.74090\n",
      "[Train]: Step: 100100, loss: 0.26407 acc: 0.95000\n",
      "[Train]: Step: 100200, loss: 0.01056 acc: 1.00000\n",
      "[Train]: Step: 100300, loss: 0.05551 acc: 0.95000\n",
      "[Train]: Step: 100400, loss: 0.47896 acc: 0.95000\n",
      "[Train]: Step: 100500, loss: 0.08879 acc: 0.95000\n",
      "[Train]: Step: 100600, loss: 0.46447 acc: 0.90000\n",
      "[Train]: Step: 100700, loss: 0.16555 acc: 0.90000\n",
      "[Train]: Step: 100800, loss: 0.00015 acc: 1.00000\n",
      "[Train]: Step: 100900, loss: 0.46054 acc: 0.90000\n",
      "[Train]: Step: 101000, loss: 0.68325 acc: 0.85000\n",
      "[Test] Step: 101000, acc: 0.73340\n",
      "[Train]: Step: 101100, loss: 0.03182 acc: 1.00000\n",
      "[Train]: Step: 101200, loss: 0.64066 acc: 0.90000\n",
      "[Train]: Step: 101300, loss: 0.05668 acc: 0.95000\n",
      "[Train]: Step: 101400, loss: 0.01162 acc: 1.00000\n",
      "[Train]: Step: 101500, loss: 0.01899 acc: 1.00000\n",
      "[Train]: Step: 101600, loss: 0.58388 acc: 0.85000\n",
      "[Train]: Step: 101700, loss: 0.00545 acc: 1.00000\n",
      "[Train]: Step: 101800, loss: 0.24215 acc: 0.95000\n",
      "[Train]: Step: 101900, loss: 0.13534 acc: 0.95000\n",
      "[Train]: Step: 102000, loss: 0.35051 acc: 0.90000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bef68701df8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mtest_batch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 test_acc_val = sess.run([accuracy], \n\u001b[0;32m---> 21\u001b[0;31m                                         feed_dict={x: test_batch_data, y: test_batch_labels})\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mall_test_acc_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_test_acc_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 20\n",
    "train_steps = 100000\n",
    "test_steps = 2000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss, acc, _ = sess.run([_loss, accuracy, train_op], \n",
    "                                feed_dict={x: batch_data, y: batch_labels})\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('[Train]: Step: %d, loss: %4.5f acc: %4.5f' \n",
    "                  % (i+1, loss, acc))\n",
    "        if (i+1) % 1000 == 0:\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run([accuracy], \n",
    "                                        feed_dict={x: test_batch_data, y: test_batch_labels})\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.mean(all_test_acc_val)\n",
    "            print('[Test] Step: %d, acc: %4.5f' % (i+1, test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

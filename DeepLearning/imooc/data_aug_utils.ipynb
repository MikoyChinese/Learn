{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_URL = 'https://i.loli.net/2019/09/25/cLHPez2dhrC4KDU.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_content = requests.get(IMG_URL).content\n",
    "img_reader = tf.image.decode_image(contents=b_img_content, \n",
    "                                   channels=3,\n",
    "                                   dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "img = sess.run(img_reader)\n",
    "print(img.shape)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(img)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_reader.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize\n",
    "\n",
    "# tf.image.resize_bicubic\n",
    "# tf.image.resize_area\n",
    "# tf.image.resize_nearest_neighbor\n",
    "\n",
    "#img_content = requests.get(IMG_URL).content\n",
    "img_reader = tf.image.decode_image(contents=b_img_content, \n",
    "                                   channels=3,\n",
    "                                   ) # dtype: default is tf.uint8\n",
    "print(img_reader.dtype)\n",
    "img_resize = tf.reshape(img_reader, [1, 365, 600, 3])\n",
    "\n",
    "# 最近邻插值法\n",
    "img_nearest_neighbor = tf.image.resize_nearest_neighbor(images=img_resize, \n",
    "                                     size=[730, 1200])\n",
    "# Bicubic Interpolation. 双三次插值\n",
    "img_bicubic = tf.image.resize_bicubic(images=img_resize, \n",
    "                                     size=[730, 1200])\n",
    "# 面积插值法\n",
    "img_area = tf.image.resize_area(images=img_resize, \n",
    "                                     size=[730, 1200])\n",
    "\n",
    "sess = tf.Session()\n",
    "img_nearest, img_bic, img_ar = sess.run([img_nearest_neighbor, \n",
    "                                         img_bicubic, \n",
    "                                         img_area])\n",
    "handle = lambda img: np.asarray(img.reshape((730, 1200, 3)), \n",
    "                                np.uint8)\n",
    "\n",
    "fig, axs = plt.subplots(3, figsize=(7, 12))\n",
    "fig.suptitle('Tensorflow Image Resize Methods')\n",
    "\n",
    "axs[0].set_title('Nearest Neighbor')\n",
    "axs[0].imshow(handle(img_nearest), aspect='auto')\n",
    "\n",
    "axs[1].set_title('Bicubic Interpolation')\n",
    "axs[1].imshow(handle(img_bic), aspect='auto')\n",
    "\n",
    "axs[2].set_title('Area Interpolation')\n",
    "axs[2].imshow(handle(img_ar), aspect='auto')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop\n",
    "# tf.image.pad_to_bounding_box\n",
    "# tf.image.crop_to_bunding_box\n",
    "# tf.image.random_crop\n",
    "\n",
    "#img_content = requests.get(IMG_URL).content\n",
    "img_reader = tf.image.decode_image(contents=b_img_content, \n",
    "                                   channels=3,\n",
    "                                   ) # dtype: default is tf.uint8\n",
    "print(img_reader.dtype)\n",
    "img_resize = tf.reshape(img_reader, [1, 365, 600, 3])\n",
    "\n",
    "_img_padded = tf.image.pad_to_bounding_box(img_resize, \n",
    "                                          offset_height=50,\n",
    "                                          offset_width=100,\n",
    "                                          target_height=500, \n",
    "                                          target_width=800)\n",
    "_img_cropped = tf.image.crop_to_bounding_box(img_resize, \n",
    "                                           offset_height=50,\n",
    "                                           offset_width=100,\n",
    "                                           target_height=200, \n",
    "                                           target_width=500)\n",
    "#_img_random_cropped = tf.image.random_crop(img_resize, \n",
    "#                                          size=[500, 800, 3])\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "img_padded, img_cropped = sess.run([_img_padded, \n",
    "                                    _img_cropped])\n",
    "\n",
    "handle = lambda img: np.asarray(img.reshape((500, 800, 3)), \n",
    "                                np.uint8)\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(5, 8))\n",
    "fig.suptitle('Tensorflow Image Crop Methods')\n",
    "\n",
    "axs[0].set_title('Pad to Bounding Box')\n",
    "axs[0].imshow(handle(img_padded), aspect='auto')\n",
    "\n",
    "axs[1].set_title('Crop to Bounding Box')\n",
    "axs[1].imshow(np.asarray(img_cropped.reshape(200, 500, 3), np.uint8), aspect='auto')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip\n",
    "# tf.image.flip_up_down\n",
    "# tf.image.random_flip_up_down\n",
    "# tf.image.random_filp_left_right\n",
    "\n",
    "#img_content = requests.get(IMG_URL).content\n",
    "img_reader = tf.image.decode_image(contents=b_img_content, \n",
    "                                   channels=3,\n",
    "                                   ) # dtype: default is tf.uint8\n",
    "print(img_reader.dtype)\n",
    "img_resize = tf.reshape(img_reader, [1, 365, 600, 3])\n",
    "\n",
    "_img_flipped = tf.image.flip_up_down(img_resize)\n",
    "_img_random_flip_up_down = tf.image.random_flip_up_down(img_resize)\n",
    "_img_random_flip_left_right = tf.image.random_flip_left_right(img_resize)\n",
    "\n",
    "sess = tf.Session()\n",
    "img_flipped, img_random_flip_up_down, \\\n",
    "    img_random_flip_left_right = sess.run([_img_flipped, \n",
    "                                           _img_random_flip_up_down,\n",
    "                                           _img_random_flip_left_right])\n",
    "\n",
    "handle = lambda img: np.asarray(img.reshape((365, 600, 3)), \n",
    "                                np.uint8)\n",
    "fig, axs = plt.subplots(3, figsize=(7, 12))\n",
    "fig.suptitle('Tensorflow Image Flip Methods')\n",
    "\n",
    "axs[0].set_title('Flip up adn down')\n",
    "axs[0].imshow(handle(img_flipped), aspect='auto')\n",
    "\n",
    "axs[1].set_title('Random Flip up and down')\n",
    "axs[1].imshow(handle(img_random_flip_up_down), aspect='auto')\n",
    "\n",
    "axs[2].set_title('Random Flip left and right')\n",
    "axs[2].imshow(handle(img_random_flip_left_right), aspect='auto')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brightness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brightness\n",
    "\n",
    "# tf.image.adjust_brightness\n",
    "# tf.image.random_brightness\n",
    "# tf.image.adjust_constrast\n",
    "# tf.image.random_constrast\n",
    "\n",
    "img_reader = tf.image.decode_image(contents=b_img_content, \n",
    "                                   channels=3,\n",
    "                                   ) # dtype: default is tf.uint8\n",
    "print(img_reader.dtype)\n",
    "img_resize = tf.reshape(img_reader, [1, 365, 600, 3])\n",
    "\n",
    "_img_brightness = tf.image.adjust_brightness(img_resize, 0.5)\n",
    "\n",
    "sess = tf.Session()\n",
    "img_brightness = sess.run(_img_brightness)\n",
    "handle = lambda img: np.asarray(img.reshape((365, 600, 3)), \n",
    "                                np.uint8)\n",
    "\n",
    "plt.imshow(handle(img_brightness))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
